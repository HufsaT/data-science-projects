{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Regression on California Housing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the housing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA SHAPE: (20640, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "    \n",
    "fetch_housing_data()\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "housing = load_housing_data()\n",
    "print(\"DATA SHAPE:\", housing.shape)\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build full pipeline for the data analysis following the example of the notebook.\n",
    " Hint: the main part requested to change is the algorithm used (KNN regression)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Considerations for building pipeline:\n",
    "\n",
    "- Make your notebook as compact as possible. \n",
    "- Split data into training and testing sets below.\n",
    "- Convert all categorical data to one-hot vectors below\n",
    "- Normalize all non-categorical data \n",
    "-  Perform KNN regression using a variety of values for n_neighbors (K) between 1 and 10 and both \"uniform\" and \"distance\" weights via a grid search where  *housing_labels* is the output and all other features are the input (similar to as seen in lecture two.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-119.569704</td>\n",
       "      <td>35.631861</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>537.870553</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>206855.816909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.003532</td>\n",
       "      <td>2.135952</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>421.385070</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>115395.615874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.350000</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-121.800000</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1447.750000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>2.563400</td>\n",
       "      <td>119600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.490000</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>3.534800</td>\n",
       "      <td>179700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.010000</td>\n",
       "      <td>37.710000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>3148.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>605.000000</td>\n",
       "      <td>4.743250</td>\n",
       "      <td>264725.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.310000</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>39320.000000</td>\n",
       "      <td>6445.000000</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>6082.000000</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>500001.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          longitude      latitude  housing_median_age   total_rooms  \\\n",
       "count  20640.000000  20640.000000        20640.000000  20640.000000   \n",
       "mean    -119.569704     35.631861           28.639486   2635.763081   \n",
       "std        2.003532      2.135952           12.585558   2181.615252   \n",
       "min     -124.350000     32.540000            1.000000      2.000000   \n",
       "25%     -121.800000     33.930000           18.000000   1447.750000   \n",
       "50%     -118.490000     34.260000           29.000000   2127.000000   \n",
       "75%     -118.010000     37.710000           37.000000   3148.000000   \n",
       "max     -114.310000     41.950000           52.000000  39320.000000   \n",
       "\n",
       "       total_bedrooms    population    households  median_income  \\\n",
       "count    20433.000000  20640.000000  20640.000000   20640.000000   \n",
       "mean       537.870553   1425.476744    499.539680       3.870671   \n",
       "std        421.385070   1132.462122    382.329753       1.899822   \n",
       "min          1.000000      3.000000      1.000000       0.499900   \n",
       "25%        296.000000    787.000000    280.000000       2.563400   \n",
       "50%        435.000000   1166.000000    409.000000       3.534800   \n",
       "75%        647.000000   1725.000000    605.000000       4.743250   \n",
       "max       6445.000000  35682.000000   6082.000000      15.000100   \n",
       "\n",
       "       median_house_value  \n",
       "count        20640.000000  \n",
       "mean        206855.816909  \n",
       "std         115395.615874  \n",
       "min          14999.000000  \n",
       "25%         119600.000000  \n",
       "50%         179700.000000  \n",
       "75%         264725.000000  \n",
       "max         500001.000000  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.describe()\n",
    "# housing['ocean_proximity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x1bacaeec88>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1bacb18080>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1bacc68630>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x1bacc15be0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1bacc901d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1baccbc780>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x1a1bab3d30>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1a1bff1358>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1a1bff1390>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# housing_numericals = housing.copy()\n",
    "# housing_numericals.drop('ocean_proximity', axis=1, inplace=True)\n",
    "housing.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1H OCEAN     9136\n",
       "INLAND        6551\n",
       "NEAR OCEAN    2658\n",
       "NEAR BAY      2290\n",
       "ISLAND           5\n",
       "Name: ocean_proximity, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing['ocean_proximity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# housing.info()\n",
    "# housing['ocean_proximity'].value_counts()\n",
    "# pd.plotting.scatter_matrix(housing)\n",
    "\n",
    "plt.matshow(housing.corr())\n",
    "plt.xticks(range(len(housing.columns)), housing.columns,rotation=90,fontsize=10)\n",
    "plt.yticks(range(len(housing.columns)), housing.columns,fontsize=10)\n",
    "plt.colorbar(extend='both')\n",
    "plt.show()\n",
    "# housing.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like median_income is heavily correlated to house value! Going to create a stratified test set to ensure equal representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    10875\n",
       "2     4946\n",
       "1     2457\n",
       "4     2362\n",
       "Name: income_cat, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "housing['income_cat'] = pd.cut(housing['median_income'],bins=[0,2,3,6, np.inf], labels=[1,2,3,4])\n",
    "housing['income_cat'].hist()\n",
    "housing['income_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the stratefied distribution of med_income buckets in test set to the full set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    0.526890\n",
       "2    0.239583\n",
       "1    0.119186\n",
       "4    0.114341\n",
       "Name: income_cat, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    0.526890\n",
       "2    0.239632\n",
       "1    0.119041\n",
       "4    0.114438\n",
       "Name: income_cat, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing[\"income_cat\"].value_counts() / len(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16512 entries, 7009 to 19311\n",
      "Data columns (total 10 columns):\n",
      "longitude             16512 non-null float64\n",
      "latitude              16512 non-null float64\n",
      "housing_median_age    16512 non-null float64\n",
      "total_rooms           16512 non-null float64\n",
      "total_bedrooms        16347 non-null float64\n",
      "population            16512 non-null float64\n",
      "households            16512 non-null float64\n",
      "median_income         16512 non-null float64\n",
      "median_house_value    16512 non-null float64\n",
      "ocean_proximity       16512 non-null object\n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "for x in (strat_train_set,strat_test_set):\n",
    "    x.drop('income_cat',axis=1, inplace=True)\n",
    "    \n",
    "strat_train_set.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepping our train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16512 entries, 7009 to 19311\n",
      "Data columns (total 9 columns):\n",
      "longitude             16512 non-null float64\n",
      "latitude              16512 non-null float64\n",
      "housing_median_age    16512 non-null float64\n",
      "total_rooms           16512 non-null float64\n",
      "total_bedrooms        16347 non-null float64\n",
      "population            16512 non-null float64\n",
      "households            16512 non-null float64\n",
      "median_income         16512 non-null float64\n",
      "ocean_proximity       16512 non-null object\n",
      "dtypes: float64(8), object(1)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "housing = strat_train_set.copy()\n",
    "housing.drop('median_house_value', axis=1,inplace=True)\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a nee feature: bedrooms/room ratio\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# get column index\n",
    "# rooms_ix, bedrooms_ix, population_ix, household_ix = 3, 4, 5, 6\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, df, add_bedrooms_per_room = True): # no *args or **kargs\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "        self.df = df\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X, y=None):\n",
    "        col_index = []\n",
    "        for x in ['total_rooms', 'total_bedrooms', 'population', 'households']:\n",
    "            col_index.append(self.df.columns.get_loc(x))\n",
    "\n",
    "        rooms_ix, bedrooms_ix, population_ix, household_ix  = col_index\n",
    "        \n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, household_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household,\n",
    "                         bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "      <th>rooms_per_household</th>\n",
       "      <th>population_per_household</th>\n",
       "      <th>bedrooms_per_room</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-118.07</td>\n",
       "      <td>33.97</td>\n",
       "      <td>36</td>\n",
       "      <td>1887</td>\n",
       "      <td>370</td>\n",
       "      <td>1006</td>\n",
       "      <td>329</td>\n",
       "      <td>3.1554</td>\n",
       "      <td>170700</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "      <td>5.73556</td>\n",
       "      <td>3.05775</td>\n",
       "      <td>0.196078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-117.99</td>\n",
       "      <td>33.77</td>\n",
       "      <td>15</td>\n",
       "      <td>2081</td>\n",
       "      <td>531</td>\n",
       "      <td>1617</td>\n",
       "      <td>561</td>\n",
       "      <td>3.4955</td>\n",
       "      <td>160900</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "      <td>3.70945</td>\n",
       "      <td>2.88235</td>\n",
       "      <td>0.255166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-119.63</td>\n",
       "      <td>36.64</td>\n",
       "      <td>33</td>\n",
       "      <td>1036</td>\n",
       "      <td>181</td>\n",
       "      <td>620</td>\n",
       "      <td>174</td>\n",
       "      <td>3.4107</td>\n",
       "      <td>110400</td>\n",
       "      <td>INLAND</td>\n",
       "      <td>5.95402</td>\n",
       "      <td>3.56322</td>\n",
       "      <td>0.17471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-117.89</td>\n",
       "      <td>33.74</td>\n",
       "      <td>32</td>\n",
       "      <td>660</td>\n",
       "      <td>145</td>\n",
       "      <td>959</td>\n",
       "      <td>113</td>\n",
       "      <td>3.75</td>\n",
       "      <td>159000</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "      <td>5.84071</td>\n",
       "      <td>8.48673</td>\n",
       "      <td>0.219697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-118.07</td>\n",
       "      <td>33.88</td>\n",
       "      <td>18</td>\n",
       "      <td>2436</td>\n",
       "      <td>375</td>\n",
       "      <td>1303</td>\n",
       "      <td>386</td>\n",
       "      <td>6.1968</td>\n",
       "      <td>344700</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "      <td>6.31088</td>\n",
       "      <td>3.37565</td>\n",
       "      <td>0.153941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  longitude latitude housing_median_age total_rooms total_bedrooms population  \\\n",
       "0   -118.07    33.97                 36        1887            370       1006   \n",
       "1   -117.99    33.77                 15        2081            531       1617   \n",
       "2   -119.63    36.64                 33        1036            181        620   \n",
       "3   -117.89    33.74                 32         660            145        959   \n",
       "4   -118.07    33.88                 18        2436            375       1303   \n",
       "\n",
       "  households median_income median_house_value ocean_proximity  \\\n",
       "0        329        3.1554             170700       <1H OCEAN   \n",
       "1        561        3.4955             160900       <1H OCEAN   \n",
       "2        174        3.4107             110400          INLAND   \n",
       "3        113          3.75             159000       <1H OCEAN   \n",
       "4        386        6.1968             344700       <1H OCEAN   \n",
       "\n",
       "  rooms_per_household population_per_household bedrooms_per_room  \n",
       "0             5.73556                  3.05775          0.196078  \n",
       "1             3.70945                  2.88235          0.255166  \n",
       "2             5.95402                  3.56322           0.17471  \n",
       "3             5.84071                  8.48673          0.219697  \n",
       "4             6.31088                  3.37565          0.153941  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing corr of whole dataset plus new cols\n",
    "\n",
    "# feature_adder = CombinedAttributesAdder(df=strat_train_set)\n",
    "# housing_extra_attribs = feature_adder.transform(strat_train_set.values)\n",
    "# housing_extra_attribs = pd.DataFrame(\n",
    "#     housing_extra_attribs,\n",
    "#     columns=list(strat_train_set.columns)+[\"rooms_per_household\", \"population_per_household\", \"bedrooms_per_room\"])\n",
    "# housing_extra_attribs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "median_house_value          1.000000\n",
       "median_income               0.688412\n",
       "rooms_per_household         0.151282\n",
       "total_rooms                 0.136863\n",
       "housing_median_age          0.107407\n",
       "households                  0.068238\n",
       "total_bedrooms              0.051805\n",
       "population_per_household   -0.020066\n",
       "population                 -0.023270\n",
       "longitude                  -0.044983\n",
       "latitude                   -0.144820\n",
       "bedrooms_per_room          -0.254015\n",
       "Name: median_house_value, dtype: float64"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.impute import SimpleImputer\n",
    "\n",
    "# imp_median = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "# clean_housing_extra = imp_median.fit_transform(housing_extra_attribs)\n",
    "# clean_housing_extra = pd.DataFrame(clean_housing_extra,columns=housing_extra_attribs.columns.tolist())\n",
    "# # clean_housing_extra.info()\n",
    "# house_corr = clean_housing_extra.corr()\n",
    "# house_corr['median_house_value'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try dropping less correlated columns - even though they seem to have statistical significance at p < 0.05\n",
    "# smaller_housing = housing.copy()\n",
    "# smaller_housing.drop(columns = ['longitude', 'latitude'],inplace=True)\n",
    "\n",
    "# ended up not using this trimmed dataset as it didn't result in better result in training KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build pipeline ot transform data (cat cols to onehot, handle for missing num cols, standardize num cols)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_pipeline = make_pipeline(SimpleImputer(strategy=\"median\"), CombinedAttributesAdder(df=housing),StandardScaler())\n",
    "log_pipeline = make_pipeline(FunctionTransformer(np.log1p, validate=True))\n",
    "\n",
    "housing_num = housing.select_dtypes(include=[np.number])\n",
    "num_attribs = list(housing_num)\n",
    "log_attribs = ['housing_median_age', 'total_rooms', 'population', 'households', 'median_income']\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"log\", log_pipeline, log_attribs),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prepared = full_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16512, 21)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# housing_prepared = log_pipeline.fit_transform(log_pipeline)\n",
    "housing_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # trying our smaller data set\n",
    "\n",
    "# # del housing_num, num_attribs, log_attribs, cat_attribs\n",
    "\n",
    "# num_pipeline = make_pipeline(SimpleImputer(strategy=\"median\"), CombinedAttributesAdder(df=smaller_housing, add_bedrooms_per_room=True),StandardScaler())\n",
    "# log_pipeline = make_pipeline(FunctionTransformer(np.log1p, validate=True))\n",
    "\n",
    "# housing_num = smaller_housing.select_dtypes(include=[np.number])\n",
    "# num_attribs = list(housing_num)\n",
    "# # num_attribs\n",
    "# cat_attribs = [\"ocean_proximity\"]\n",
    "# log_attribs = ['housing_median_age', 'total_rooms', 'population', 'households', 'median_income']\n",
    "\n",
    "# full_small_pipeline = ColumnTransformer([\n",
    "#         (\"num\", num_pipeline, num_attribs),\n",
    "#         (\"log\", log_pipeline, log_attribs),\n",
    "#         (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "#     ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # smaller_housing.info()\n",
    "# housing_prepared = full_small_pipeline.fit_transform(smaller_housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16512, 21)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# housing_prepared.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we try out KNN as default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48988.296502586556"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=5, metric='euclidean')\n",
    "knn.fit(housing_prepared, housing_labels)\n",
    "\n",
    "y_pred = knn.predict(housing_prepared)\n",
    "\n",
    "knn_rmse = np.sqrt(mean_squared_error(housing_labels, y_pred))\n",
    "knn_rmse\n",
    "\n",
    "# before log transform rmse: 49521.130387713514\n",
    "# after log transforming some cols: 48988.296502586556\n",
    "\n",
    "# after removing long, lat rmse: 52515.87454156765"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we take a detour into RandomForestRegressor to utilize its Feature Importnaces method (since KNN doens't have one) to try reducing num_features used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18497.906975058"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(housing_prepared, housing_labels);\n",
    "\n",
    "y_pred = rf.predict(housing_prepared)\n",
    "\n",
    "rf_pred_score = np.sqrt(mean_squared_error(housing_labels, y_pred))\n",
    "\n",
    "rf_pred_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying cross val on Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [51033.61756625 50606.76787941 49324.10931668 50526.68340013\n",
      " 50129.70007561 47689.51816919 50420.06038147 51034.90252945\n",
      " 49695.69478771 49366.8086847 ]\n",
      "Mean: 49982.78627905954\n",
      "Standard deviation: 962.494067735034\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rf_scores = cross_val_score(rf, housing_prepared, housing_labels,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "rf_scores_rmse_scores = np.sqrt(-rf_scores)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(rf_scores_rmse_scores)\n",
    "\n",
    "# Scores: [51033.61756625 50606.76787941 49324.10931668 50526.68340013\n",
    "#  50129.70007561 47689.51816919 50420.06038147 51034.90252945\n",
    "#  49695.69478771 49366.8086847 ]\n",
    "# Mean: 49982.78627905954\n",
    "# Standard deviation: 962.494067735034"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the best params for Random Forest so that we can later compare our final KNN model to this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_impurity_decrease\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_impurity_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbootstrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moob_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mccp_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "A random forest regressor.\n",
       "\n",
       "A random forest is a meta estimator that fits a number of classifying\n",
       "decision trees on various sub-samples of the dataset and uses averaging\n",
       "to improve the predictive accuracy and control over-fitting.\n",
       "The sub-sample size is always the same as the original\n",
       "input sample size but the samples are drawn with replacement if\n",
       "`bootstrap=True` (default).\n",
       "\n",
       "Read more in the :ref:`User Guide <forest>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "n_estimators : integer, optional (default=10)\n",
       "    The number of trees in the forest.\n",
       "\n",
       "    .. versionchanged:: 0.22\n",
       "       The default value of ``n_estimators`` changed from 10 to 100\n",
       "       in 0.22.\n",
       "\n",
       "criterion : string, optional (default=\"mse\")\n",
       "    The function to measure the quality of a split. Supported criteria\n",
       "    are \"mse\" for the mean squared error, which is equal to variance\n",
       "    reduction as feature selection criterion, and \"mae\" for the mean\n",
       "    absolute error.\n",
       "\n",
       "    .. versionadded:: 0.18\n",
       "       Mean Absolute Error (MAE) criterion.\n",
       "\n",
       "max_depth : integer or None, optional (default=None)\n",
       "    The maximum depth of the tree. If None, then nodes are expanded until\n",
       "    all leaves are pure or until all leaves contain less than\n",
       "    min_samples_split samples.\n",
       "\n",
       "min_samples_split : int, float, optional (default=2)\n",
       "    The minimum number of samples required to split an internal node:\n",
       "\n",
       "    - If int, then consider `min_samples_split` as the minimum number.\n",
       "    - If float, then `min_samples_split` is a fraction and\n",
       "      `ceil(min_samples_split * n_samples)` are the minimum\n",
       "      number of samples for each split.\n",
       "\n",
       "    .. versionchanged:: 0.18\n",
       "       Added float values for fractions.\n",
       "\n",
       "min_samples_leaf : int, float, optional (default=1)\n",
       "    The minimum number of samples required to be at a leaf node.\n",
       "    A split point at any depth will only be considered if it leaves at\n",
       "    least ``min_samples_leaf`` training samples in each of the left and\n",
       "    right branches.  This may have the effect of smoothing the model,\n",
       "    especially in regression.\n",
       "\n",
       "    - If int, then consider `min_samples_leaf` as the minimum number.\n",
       "    - If float, then `min_samples_leaf` is a fraction and\n",
       "      `ceil(min_samples_leaf * n_samples)` are the minimum\n",
       "      number of samples for each node.\n",
       "\n",
       "    .. versionchanged:: 0.18\n",
       "       Added float values for fractions.\n",
       "\n",
       "min_weight_fraction_leaf : float, optional (default=0.)\n",
       "    The minimum weighted fraction of the sum total of weights (of all\n",
       "    the input samples) required to be at a leaf node. Samples have\n",
       "    equal weight when sample_weight is not provided.\n",
       "\n",
       "max_features : int, float, string or None, optional (default=\"auto\")\n",
       "    The number of features to consider when looking for the best split:\n",
       "\n",
       "    - If int, then consider `max_features` features at each split.\n",
       "    - If float, then `max_features` is a fraction and\n",
       "      `int(max_features * n_features)` features are considered at each\n",
       "      split.\n",
       "    - If \"auto\", then `max_features=n_features`.\n",
       "    - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
       "    - If \"log2\", then `max_features=log2(n_features)`.\n",
       "    - If None, then `max_features=n_features`.\n",
       "\n",
       "    Note: the search for a split does not stop until at least one\n",
       "    valid partition of the node samples is found, even if it requires to\n",
       "    effectively inspect more than ``max_features`` features.\n",
       "\n",
       "max_leaf_nodes : int or None, optional (default=None)\n",
       "    Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
       "    Best nodes are defined as relative reduction in impurity.\n",
       "    If None then unlimited number of leaf nodes.\n",
       "\n",
       "min_impurity_decrease : float, optional (default=0.)\n",
       "    A node will be split if this split induces a decrease of the impurity\n",
       "    greater than or equal to this value.\n",
       "\n",
       "    The weighted impurity decrease equation is the following::\n",
       "\n",
       "        N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
       "                            - N_t_L / N_t * left_impurity)\n",
       "\n",
       "    where ``N`` is the total number of samples, ``N_t`` is the number of\n",
       "    samples at the current node, ``N_t_L`` is the number of samples in the\n",
       "    left child, and ``N_t_R`` is the number of samples in the right child.\n",
       "\n",
       "    ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
       "    if ``sample_weight`` is passed.\n",
       "\n",
       "    .. versionadded:: 0.19\n",
       "\n",
       "min_impurity_split : float, (default=1e-7)\n",
       "    Threshold for early stopping in tree growth. A node will split\n",
       "    if its impurity is above the threshold, otherwise it is a leaf.\n",
       "\n",
       "    .. deprecated:: 0.19\n",
       "       ``min_impurity_split`` has been deprecated in favor of\n",
       "       ``min_impurity_decrease`` in 0.19. The default value of\n",
       "       ``min_impurity_split`` will change from 1e-7 to 0 in 0.23 and it\n",
       "       will be removed in 0.25. Use ``min_impurity_decrease`` instead.\n",
       "\n",
       "bootstrap : boolean, optional (default=True)\n",
       "    Whether bootstrap samples are used when building trees. If False, the\n",
       "    whole datset is used to build each tree.\n",
       "\n",
       "oob_score : bool, optional (default=False)\n",
       "    whether to use out-of-bag samples to estimate\n",
       "    the R^2 on unseen data.\n",
       "\n",
       "n_jobs : int or None, optional (default=None)\n",
       "    The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,\n",
       "    :meth:`decision_path` and :meth:`apply` are all parallelized over the\n",
       "    trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
       "    context. ``-1`` means using all processors. See :term:`Glossary\n",
       "    <n_jobs>` for more details.\n",
       "\n",
       "random_state : int, RandomState instance or None, optional (default=None)\n",
       "    Controls both the randomness of the bootstrapping of the samples used\n",
       "    when building trees (if ``bootstrap=True``) and the sampling of the\n",
       "    features to consider when looking for the best split at each node\n",
       "    (if ``max_features < n_features``).\n",
       "    See :term:`Glossary <random_state>` for details.\n",
       "\n",
       "verbose : int, optional (default=0)\n",
       "    Controls the verbosity when fitting and predicting.\n",
       "\n",
       "warm_start : bool, optional (default=False)\n",
       "    When set to ``True``, reuse the solution of the previous call to fit\n",
       "    and add more estimators to the ensemble, otherwise, just fit a whole\n",
       "    new forest. See :term:`the Glossary <warm_start>`.\n",
       "\n",
       "ccp_alpha : non-negative float, optional (default=0.0)\n",
       "    Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
       "    subtree with the largest cost complexity that is smaller than\n",
       "    ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
       "    :ref:`minimal_cost_complexity_pruning` for details.\n",
       "\n",
       "    .. versionadded:: 0.22\n",
       "\n",
       "max_samples : int or float, default=None\n",
       "    If bootstrap is True, the number of samples to draw from X\n",
       "    to train each base estimator.\n",
       "\n",
       "    - If None (default), then draw `X.shape[0]` samples.\n",
       "    - If int, then draw `max_samples` samples.\n",
       "    - If float, then draw `max_samples * X.shape[0]` samples. Thus,\n",
       "      `max_samples` should be in the interval `(0, 1)`.\n",
       "\n",
       "    .. versionadded:: 0.22\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "base_estimator_ : DecisionTreeRegressor\n",
       "    The child estimator template used to create the collection of fitted\n",
       "    sub-estimators.\n",
       "\n",
       "estimators_ : list of DecisionTreeRegressor\n",
       "    The collection of fitted sub-estimators.\n",
       "\n",
       "feature_importances_ : ndarray of shape (n_features,)\n",
       "    The feature importances (the higher, the more important the feature).\n",
       "\n",
       "n_features_ : int\n",
       "    The number of features when ``fit`` is performed.\n",
       "\n",
       "n_outputs_ : int\n",
       "    The number of outputs when ``fit`` is performed.\n",
       "\n",
       "oob_score_ : float\n",
       "    Score of the training dataset obtained using an out-of-bag estimate.\n",
       "    This attribute exists only when ``oob_score`` is True.\n",
       "\n",
       "oob_prediction_ : ndarray of shape (n_samples,)\n",
       "    Prediction computed with out-of-bag estimate on the training set.\n",
       "    This attribute exists only when ``oob_score`` is True.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn.ensemble import RandomForestRegressor\n",
       ">>> from sklearn.datasets import make_regression\n",
       "\n",
       ">>> X, y = make_regression(n_features=4, n_informative=2,\n",
       "...                        random_state=0, shuffle=False)\n",
       ">>> regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
       ">>> regr.fit(X, y)\n",
       "RandomForestRegressor(max_depth=2, random_state=0)\n",
       ">>> print(regr.feature_importances_)\n",
       "[0.18146984 0.81473937 0.00145312 0.00233767]\n",
       ">>> print(regr.predict([[0, 0, 0, 0]]))\n",
       "[-8.32987858]\n",
       "\n",
       "Notes\n",
       "-----\n",
       "The default values for the parameters controlling the size of the trees\n",
       "(e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
       "unpruned trees which can potentially be very large on some data sets. To\n",
       "reduce memory consumption, the complexity and size of the trees should be\n",
       "controlled by setting those parameter values.\n",
       "\n",
       "The features are always randomly permuted at each split. Therefore,\n",
       "the best found split may vary, even with the same training data,\n",
       "``max_features=n_features`` and ``bootstrap=False``, if the improvement\n",
       "of the criterion is identical for several splits enumerated during the\n",
       "search of the best split. To obtain a deterministic behaviour during\n",
       "fitting, ``random_state`` has to be fixed.\n",
       "\n",
       "The default value ``max_features=\"auto\"`` uses ``n_features``\n",
       "rather than ``n_features / 3``. The latter was originally suggested in\n",
       "[1], whereas the former was more recently justified empirically in [2].\n",
       "\n",
       "References\n",
       "----------\n",
       "\n",
       ".. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n",
       "\n",
       ".. [2] P. Geurts, D. Ernst., and L. Wehenkel, \"Extremely randomized\n",
       "       trees\", Machine Learning, 63(1), 3-42, 2006.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "DecisionTreeRegressor, ExtraTreesRegressor\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/TensorFlow_Env/lib/python3.6/site-packages/sklearn/ensemble/_forest.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [10, 231, 452, 673, 894, 1115, 1336, 1557, 1778, 2000], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "# ?RandomForestRegressor\n",
    "# rf.get_params()\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt', 'log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 48.8min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 118.6min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed: 129.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=60, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=1557, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import randint\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "best_rf = RandomizedSearchCV(rf,param_distributions=random_grid,cv=5, n_jobs = -1, verbose=1, n_iter=100, scoring='neg_mean_squared_error', random_state=42)\n",
    "\n",
    "best_rf.fit(housing_prepared, housing_labels)\n",
    "\n",
    "# rnd_search.best_params_\n",
    "best_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   33.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   53.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1557 out of 1557 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 1557 out of 1557 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18152.72453168989"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try out the new best params\n",
    "rf_best = RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
    "                      max_depth=60, max_features='auto', min_impurity_decrease=0.0,\n",
    "                      min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                      n_estimators=1557, n_jobs=-1, oob_score=False,\n",
    "                      random_state=None, verbose=1, warm_start=False)\n",
    "\n",
    "rf_best.fit(housing_prepared, housing_labels)\n",
    "\n",
    "y_pred = rf_best.predict(housing_prepared)\n",
    "\n",
    "rfbest_score = np.sqrt(mean_squared_error(housing_labels, y_pred))\n",
    "rfbest_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   39.7s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   52.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1557 out of 1557 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 1557 out of 1557 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   49.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1557 out of 1557 | elapsed:  1.0min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 1557 out of 1557 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   31.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   50.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1557 out of 1557 | elapsed:  1.0min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 1557 out of 1557 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   47.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1557 out of 1557 | elapsed:   60.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 1557 out of 1557 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   46.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1557 out of 1557 | elapsed:   58.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 1557 out of 1557 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   29.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   46.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1557 out of 1557 | elapsed:   58.7s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 1557 out of 1557 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   28.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   45.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1557 out of 1557 | elapsed:   57.4s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 1557 out of 1557 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   29.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   50.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1557 out of 1557 | elapsed:  1.0min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 1557 out of 1557 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   46.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1557 out of 1557 | elapsed:   58.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 1557 out of 1557 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   29.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   46.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1557 out of 1557 | elapsed:   58.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 1557 out of 1557 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [50722.36523927 50260.34456903 49135.98441814 50055.00169144\n",
      " 49814.63668623 47317.86642382 50102.44634598 50420.44257002\n",
      " 49102.66109265 49039.61824602]\n",
      "Mean: 49597.13672826039\n",
      "Standard deviation: 941.2315497901909\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(rf_best, housing_prepared, housing_labels,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at feature importances to see if we can remove certain features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.24369100593939305, 'median_income'),\n",
       " (0.2305224635571421, 'bedrooms_per_room'),\n",
       " (0.1438922231388992, 'INLAND'),\n",
       " (0.1208275948134601, 'total_rooms'),\n",
       " (0.0577576756684662, 'longitude'),\n",
       " (0.05432300074820777, 'latitude'),\n",
       " (0.026645927291800174, 'housing_median_age'),\n",
       " (0.023095911629431976, 'housing_median_age'),\n",
       " (0.023079390141580242, 'households'),\n",
       " (0.022876332245257414, 'population'),\n",
       " (0.010006550812039947, 'total_bedrooms'),\n",
       " (0.007243873984726424, 'median_income'),\n",
       " (0.0071641667472998535, 'total_rooms'),\n",
       " (0.0064750073564447995, 'population'),\n",
       " (0.006466924033870593, 'rooms_per_hhold'),\n",
       " (0.005715241748040608, 'pop_per_hhold'),\n",
       " (0.005712288215653886, 'households'),\n",
       " (0.002515215104465619, 'NEAR OCEAN'),\n",
       " (0.0011019352275935083, '<1H OCEAN'),\n",
       " (0.0007193405262019268, 'NEAR BAY'),\n",
       " (0.00016793107002473912, 'ISLAND')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = rf_best.feature_importances_\n",
    "\n",
    "extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\n",
    "cat_encoder = full_pipeline.named_transformers_[\"cat\"]\n",
    "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "attributes = num_attribs + log_attribs + extra_attribs + cat_one_hot_attribs\n",
    "sorted(zip(feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16512 entries, 0 to 16511\n",
      "Data columns (total 19 columns):\n",
      "longitude             16512 non-null float64\n",
      "latitude              16512 non-null float64\n",
      "housing_median_age    16512 non-null float64\n",
      "total_rooms           16512 non-null float64\n",
      "total_bedrooms        16512 non-null float64\n",
      "population            16512 non-null float64\n",
      "households            16512 non-null float64\n",
      "median_income         16512 non-null float64\n",
      "housing_median_age    16512 non-null float64\n",
      "total_rooms           16512 non-null float64\n",
      "population            16512 non-null float64\n",
      "households            16512 non-null float64\n",
      "median_income         16512 non-null float64\n",
      "rooms_per_hhold       16512 non-null float64\n",
      "pop_per_hhold         16512 non-null float64\n",
      "bedrooms_per_room     16512 non-null float64\n",
      "<1H OCEAN             16512 non-null float64\n",
      "INLAND                16512 non-null float64\n",
      "NEAR OCEAN            16512 non-null float64\n",
      "dtypes: float64(19)\n",
      "memory usage: 2.4 MB\n"
     ]
    }
   ],
   "source": [
    "# try dropping some of the less important features\n",
    "# updte: this did not help the model! May help the test set though.\n",
    "\n",
    "housing_trim = pd.DataFrame(housing_prepared,columns=attributes)\n",
    "housing_trim.drop(columns = ['median_house_value', 'NEAR BAY', 'ISLAND'], axis=1,inplace=True)\n",
    "housing_trim_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "\n",
    "housing_trim.info()\n",
    "\n",
    "housing_trim = housing_trim.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.75060366, -0.77928422,  0.58222481, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.79051734, -0.87277027, -1.08755128, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.0277132 ,  0.46875451,  0.34368537, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.8708898 ,  0.37059416, -0.53095925, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.13032876,  0.4547316 , -1.08755128, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.65419588,  1.28208311, -1.00803813, ...,  1.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_trim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to our best Random Forest with our newly smaller feature list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   34.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   56.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1557 out of 1557 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 1557 out of 1557 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18145.06060701546"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rf_best = RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
    "                      max_depth=60, max_features='auto', min_impurity_decrease=0.0,\n",
    "                      min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                      n_estimators=1557, n_jobs=-1, oob_score=False,\n",
    "                      random_state=None, verbose=1, warm_start=False)\n",
    "\n",
    "rf_best.fit(housing_trim, housing_labels)\n",
    "\n",
    "y_pred = rf_best.predict(housing_trim)\n",
    "\n",
    "rfbest_score = np.sqrt(mean_squared_error(housing_labels, y_pred))\n",
    "rfbest_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   32.9s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   48.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1557 out of 1557 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 1557 out of 1557 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   34.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   54.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1557 out of 1557 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 1557 out of 1557 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   34.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   53.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1557 out of 1557 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 1557 out of 1557 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   32.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   51.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1557 out of 1557 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 1557 out of 1557 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   32.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   50.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1557 out of 1557 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 1557 out of 1557 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   33.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   52.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1557 out of 1557 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 1557 out of 1557 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   32.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   50.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1557 out of 1557 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 1557 out of 1557 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   32.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   57.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1557 out of 1557 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 1557 out of 1557 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   33.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   59.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1557 out of 1557 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 1557 out of 1557 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   22.1s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   46.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1557 out of 1557 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 1557 out of 1557 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [50787.20894224 50275.99754949 49237.86825859 49945.31149289\n",
      " 49862.48574818 47360.59566441 50181.42548192 50427.79352048\n",
      " 49153.12555738 49080.98234064]\n",
      "Mean: 49631.27945562298\n",
      "Standard deviation: 931.8389071787957\n"
     ]
    }
   ],
   "source": [
    "# try the trimmed dataset with CV\n",
    "\n",
    "scores = cross_val_score(rf_best, housing_trim, housing_labels,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10, n_jobs=-1)\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(tree_rmse_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the Mean score is slightly worse, there is still a possibility that the test set will perform better with this slightly noisier model. Trying to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# knn_best = KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "#                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
    "#                     weights='distance')\n",
    "# knn_best.fit(housing_prepared, housing_labels)\n",
    "\n",
    "# some_data = housing.iloc[:5]\n",
    "# some_labels = housing_labels.iloc[:5]\n",
    "# some_data_prepared = full_pipeline.transform(some_data)\n",
    "\n",
    "\n",
    "# y_pred = knn_best.predict(some_data_prepared)\n",
    "# knnbest_rmse = np.sqrt(mean_squared_error(some_labels, y_pred))\n",
    "# knnbest_rmse\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to KNN to try tweaking its params with GridSearch and RandomizedCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'leaf_size': 30,\n",
       " 'metric': 'euclidean',\n",
       " 'metric_params': None,\n",
       " 'n_jobs': None,\n",
       " 'n_neighbors': 5,\n",
       " 'p': 2,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [62427.38495922 61545.86143142 61463.20526689 59092.76559755\n",
      " 62683.89489777 58585.51800492 60411.59041866 61030.7603823\n",
      " 60843.19638083 60410.7796537 ]\n",
      "Mean: 60849.49569932447\n",
      "Standard deviation: 1238.755206785948\n"
     ]
    }
   ],
   "source": [
    "# using full dataset (not the trimmed version, for now)\n",
    "scores = cross_val_score(knn, housing_prepared, housing_labels,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 44 candidates, totalling 220 fits\n",
      "[CV] metric=minkowski, n_neighbors=5, weights=uniform ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . metric=minkowski, n_neighbors=5, weights=uniform, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=5, weights=uniform ................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . metric=minkowski, n_neighbors=5, weights=uniform, total=   0.3s\n",
      "[CV] metric=minkowski, n_neighbors=5, weights=uniform ................\n",
      "[CV] . metric=minkowski, n_neighbors=5, weights=uniform, total=   0.4s\n",
      "[CV] metric=minkowski, n_neighbors=5, weights=uniform ................\n",
      "[CV] . metric=minkowski, n_neighbors=5, weights=uniform, total=   0.4s\n",
      "[CV] metric=minkowski, n_neighbors=5, weights=uniform ................\n",
      "[CV] . metric=minkowski, n_neighbors=5, weights=uniform, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=5, weights=distance ...............\n",
      "[CV]  metric=minkowski, n_neighbors=5, weights=distance, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=5, weights=distance ...............\n",
      "[CV]  metric=minkowski, n_neighbors=5, weights=distance, total=   0.3s\n",
      "[CV] metric=minkowski, n_neighbors=5, weights=distance ...............\n",
      "[CV]  metric=minkowski, n_neighbors=5, weights=distance, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=5, weights=distance ...............\n",
      "[CV]  metric=minkowski, n_neighbors=5, weights=distance, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=5, weights=distance ...............\n",
      "[CV]  metric=minkowski, n_neighbors=5, weights=distance, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=6, weights=uniform ................\n",
      "[CV] . metric=minkowski, n_neighbors=6, weights=uniform, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=6, weights=uniform ................\n",
      "[CV] . metric=minkowski, n_neighbors=6, weights=uniform, total=   0.3s\n",
      "[CV] metric=minkowski, n_neighbors=6, weights=uniform ................\n",
      "[CV] . metric=minkowski, n_neighbors=6, weights=uniform, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=6, weights=uniform ................\n",
      "[CV] . metric=minkowski, n_neighbors=6, weights=uniform, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=6, weights=uniform ................\n",
      "[CV] . metric=minkowski, n_neighbors=6, weights=uniform, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=6, weights=distance ...............\n",
      "[CV]  metric=minkowski, n_neighbors=6, weights=distance, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=6, weights=distance ...............\n",
      "[CV]  metric=minkowski, n_neighbors=6, weights=distance, total=   0.4s\n",
      "[CV] metric=minkowski, n_neighbors=6, weights=distance ...............\n",
      "[CV]  metric=minkowski, n_neighbors=6, weights=distance, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=6, weights=distance ...............\n",
      "[CV]  metric=minkowski, n_neighbors=6, weights=distance, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=6, weights=distance ...............\n",
      "[CV]  metric=minkowski, n_neighbors=6, weights=distance, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=7, weights=uniform ................\n",
      "[CV] . metric=minkowski, n_neighbors=7, weights=uniform, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=7, weights=uniform ................\n",
      "[CV] . metric=minkowski, n_neighbors=7, weights=uniform, total=   0.4s\n",
      "[CV] metric=minkowski, n_neighbors=7, weights=uniform ................\n",
      "[CV] . metric=minkowski, n_neighbors=7, weights=uniform, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=7, weights=uniform ................\n",
      "[CV] . metric=minkowski, n_neighbors=7, weights=uniform, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=7, weights=uniform ................\n",
      "[CV] . metric=minkowski, n_neighbors=7, weights=uniform, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=7, weights=distance ...............\n",
      "[CV]  metric=minkowski, n_neighbors=7, weights=distance, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=7, weights=distance ...............\n",
      "[CV]  metric=minkowski, n_neighbors=7, weights=distance, total=   0.3s\n",
      "[CV] metric=minkowski, n_neighbors=7, weights=distance ...............\n",
      "[CV]  metric=minkowski, n_neighbors=7, weights=distance, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=7, weights=distance ...............\n",
      "[CV]  metric=minkowski, n_neighbors=7, weights=distance, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=7, weights=distance ...............\n",
      "[CV]  metric=minkowski, n_neighbors=7, weights=distance, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=8, weights=uniform ................\n",
      "[CV] . metric=minkowski, n_neighbors=8, weights=uniform, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=8, weights=uniform ................\n",
      "[CV] . metric=minkowski, n_neighbors=8, weights=uniform, total=   0.4s\n",
      "[CV] metric=minkowski, n_neighbors=8, weights=uniform ................\n",
      "[CV] . metric=minkowski, n_neighbors=8, weights=uniform, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=8, weights=uniform ................\n",
      "[CV] . metric=minkowski, n_neighbors=8, weights=uniform, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=8, weights=uniform ................\n",
      "[CV] . metric=minkowski, n_neighbors=8, weights=uniform, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=8, weights=distance ...............\n",
      "[CV]  metric=minkowski, n_neighbors=8, weights=distance, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=8, weights=distance ...............\n",
      "[CV]  metric=minkowski, n_neighbors=8, weights=distance, total=   0.4s\n",
      "[CV] metric=minkowski, n_neighbors=8, weights=distance ...............\n",
      "[CV]  metric=minkowski, n_neighbors=8, weights=distance, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=8, weights=distance ...............\n",
      "[CV]  metric=minkowski, n_neighbors=8, weights=distance, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=8, weights=distance ...............\n",
      "[CV]  metric=minkowski, n_neighbors=8, weights=distance, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=9, weights=uniform ................\n",
      "[CV] . metric=minkowski, n_neighbors=9, weights=uniform, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=9, weights=uniform ................\n",
      "[CV] . metric=minkowski, n_neighbors=9, weights=uniform, total=   0.4s\n",
      "[CV] metric=minkowski, n_neighbors=9, weights=uniform ................\n",
      "[CV] . metric=minkowski, n_neighbors=9, weights=uniform, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=9, weights=uniform ................\n",
      "[CV] . metric=minkowski, n_neighbors=9, weights=uniform, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=9, weights=uniform ................\n",
      "[CV] . metric=minkowski, n_neighbors=9, weights=uniform, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=9, weights=distance ...............\n",
      "[CV]  metric=minkowski, n_neighbors=9, weights=distance, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=9, weights=distance ...............\n",
      "[CV]  metric=minkowski, n_neighbors=9, weights=distance, total=   0.4s\n",
      "[CV] metric=minkowski, n_neighbors=9, weights=distance ...............\n",
      "[CV]  metric=minkowski, n_neighbors=9, weights=distance, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=9, weights=distance ...............\n",
      "[CV]  metric=minkowski, n_neighbors=9, weights=distance, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=9, weights=distance ...............\n",
      "[CV]  metric=minkowski, n_neighbors=9, weights=distance, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=10, weights=uniform ...............\n",
      "[CV]  metric=minkowski, n_neighbors=10, weights=uniform, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=10, weights=uniform ...............\n",
      "[CV]  metric=minkowski, n_neighbors=10, weights=uniform, total=   0.4s\n",
      "[CV] metric=minkowski, n_neighbors=10, weights=uniform ...............\n",
      "[CV]  metric=minkowski, n_neighbors=10, weights=uniform, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=10, weights=uniform ...............\n",
      "[CV]  metric=minkowski, n_neighbors=10, weights=uniform, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=10, weights=uniform ...............\n",
      "[CV]  metric=minkowski, n_neighbors=10, weights=uniform, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=10, weights=distance ..............\n",
      "[CV]  metric=minkowski, n_neighbors=10, weights=distance, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=10, weights=distance ..............\n",
      "[CV]  metric=minkowski, n_neighbors=10, weights=distance, total=   0.4s\n",
      "[CV] metric=minkowski, n_neighbors=10, weights=distance ..............\n",
      "[CV]  metric=minkowski, n_neighbors=10, weights=distance, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=10, weights=distance ..............\n",
      "[CV]  metric=minkowski, n_neighbors=10, weights=distance, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=10, weights=distance ..............\n",
      "[CV]  metric=minkowski, n_neighbors=10, weights=distance, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=11, weights=uniform ...............\n",
      "[CV]  metric=minkowski, n_neighbors=11, weights=uniform, total=   0.8s\n",
      "[CV] metric=minkowski, n_neighbors=11, weights=uniform ...............\n",
      "[CV]  metric=minkowski, n_neighbors=11, weights=uniform, total=   0.4s\n",
      "[CV] metric=minkowski, n_neighbors=11, weights=uniform ...............\n",
      "[CV]  metric=minkowski, n_neighbors=11, weights=uniform, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=11, weights=uniform ...............\n",
      "[CV]  metric=minkowski, n_neighbors=11, weights=uniform, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=11, weights=uniform ...............\n",
      "[CV]  metric=minkowski, n_neighbors=11, weights=uniform, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=11, weights=distance ..............\n",
      "[CV]  metric=minkowski, n_neighbors=11, weights=distance, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=11, weights=distance ..............\n",
      "[CV]  metric=minkowski, n_neighbors=11, weights=distance, total=   0.4s\n",
      "[CV] metric=minkowski, n_neighbors=11, weights=distance ..............\n",
      "[CV]  metric=minkowski, n_neighbors=11, weights=distance, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=11, weights=distance ..............\n",
      "[CV]  metric=minkowski, n_neighbors=11, weights=distance, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=11, weights=distance ..............\n",
      "[CV]  metric=minkowski, n_neighbors=11, weights=distance, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=12, weights=uniform ...............\n",
      "[CV]  metric=minkowski, n_neighbors=12, weights=uniform, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=12, weights=uniform ...............\n",
      "[CV]  metric=minkowski, n_neighbors=12, weights=uniform, total=   0.4s\n",
      "[CV] metric=minkowski, n_neighbors=12, weights=uniform ...............\n",
      "[CV]  metric=minkowski, n_neighbors=12, weights=uniform, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=12, weights=uniform ...............\n",
      "[CV]  metric=minkowski, n_neighbors=12, weights=uniform, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=12, weights=uniform ...............\n",
      "[CV]  metric=minkowski, n_neighbors=12, weights=uniform, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=12, weights=distance ..............\n",
      "[CV]  metric=minkowski, n_neighbors=12, weights=distance, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=12, weights=distance ..............\n",
      "[CV]  metric=minkowski, n_neighbors=12, weights=distance, total=   0.4s\n",
      "[CV] metric=minkowski, n_neighbors=12, weights=distance ..............\n",
      "[CV]  metric=minkowski, n_neighbors=12, weights=distance, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=12, weights=distance ..............\n",
      "[CV]  metric=minkowski, n_neighbors=12, weights=distance, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=12, weights=distance ..............\n",
      "[CV]  metric=minkowski, n_neighbors=12, weights=distance, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=13, weights=uniform ...............\n",
      "[CV]  metric=minkowski, n_neighbors=13, weights=uniform, total=   0.7s\n",
      "[CV] metric=minkowski, n_neighbors=13, weights=uniform ...............\n",
      "[CV]  metric=minkowski, n_neighbors=13, weights=uniform, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=13, weights=uniform ...............\n",
      "[CV]  metric=minkowski, n_neighbors=13, weights=uniform, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=13, weights=uniform ...............\n",
      "[CV]  metric=minkowski, n_neighbors=13, weights=uniform, total=   0.7s\n",
      "[CV] metric=minkowski, n_neighbors=13, weights=uniform ...............\n",
      "[CV]  metric=minkowski, n_neighbors=13, weights=uniform, total=   0.7s\n",
      "[CV] metric=minkowski, n_neighbors=13, weights=distance ..............\n",
      "[CV]  metric=minkowski, n_neighbors=13, weights=distance, total=   0.7s\n",
      "[CV] metric=minkowski, n_neighbors=13, weights=distance ..............\n",
      "[CV]  metric=minkowski, n_neighbors=13, weights=distance, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=13, weights=distance ..............\n",
      "[CV]  metric=minkowski, n_neighbors=13, weights=distance, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=13, weights=distance ..............\n",
      "[CV]  metric=minkowski, n_neighbors=13, weights=distance, total=   0.7s\n",
      "[CV] metric=minkowski, n_neighbors=13, weights=distance ..............\n",
      "[CV]  metric=minkowski, n_neighbors=13, weights=distance, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=14, weights=uniform ...............\n",
      "[CV]  metric=minkowski, n_neighbors=14, weights=uniform, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=14, weights=uniform ...............\n",
      "[CV]  metric=minkowski, n_neighbors=14, weights=uniform, total=   0.4s\n",
      "[CV] metric=minkowski, n_neighbors=14, weights=uniform ...............\n",
      "[CV]  metric=minkowski, n_neighbors=14, weights=uniform, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=14, weights=uniform ...............\n",
      "[CV]  metric=minkowski, n_neighbors=14, weights=uniform, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=14, weights=uniform ...............\n",
      "[CV]  metric=minkowski, n_neighbors=14, weights=uniform, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=14, weights=distance ..............\n",
      "[CV]  metric=minkowski, n_neighbors=14, weights=distance, total=   0.7s\n",
      "[CV] metric=minkowski, n_neighbors=14, weights=distance ..............\n",
      "[CV]  metric=minkowski, n_neighbors=14, weights=distance, total=   0.5s\n",
      "[CV] metric=minkowski, n_neighbors=14, weights=distance ..............\n",
      "[CV]  metric=minkowski, n_neighbors=14, weights=distance, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=14, weights=distance ..............\n",
      "[CV]  metric=minkowski, n_neighbors=14, weights=distance, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=14, weights=distance ..............\n",
      "[CV]  metric=minkowski, n_neighbors=14, weights=distance, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=15, weights=uniform ...............\n",
      "[CV]  metric=minkowski, n_neighbors=15, weights=uniform, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=15, weights=uniform ...............\n",
      "[CV]  metric=minkowski, n_neighbors=15, weights=uniform, total=   0.4s\n",
      "[CV] metric=minkowski, n_neighbors=15, weights=uniform ...............\n",
      "[CV]  metric=minkowski, n_neighbors=15, weights=uniform, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=15, weights=uniform ...............\n",
      "[CV]  metric=minkowski, n_neighbors=15, weights=uniform, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=15, weights=uniform ...............\n",
      "[CV]  metric=minkowski, n_neighbors=15, weights=uniform, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=15, weights=distance ..............\n",
      "[CV]  metric=minkowski, n_neighbors=15, weights=distance, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=15, weights=distance ..............\n",
      "[CV]  metric=minkowski, n_neighbors=15, weights=distance, total=   0.4s\n",
      "[CV] metric=minkowski, n_neighbors=15, weights=distance ..............\n",
      "[CV]  metric=minkowski, n_neighbors=15, weights=distance, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=15, weights=distance ..............\n",
      "[CV]  metric=minkowski, n_neighbors=15, weights=distance, total=   0.6s\n",
      "[CV] metric=minkowski, n_neighbors=15, weights=distance ..............\n",
      "[CV]  metric=minkowski, n_neighbors=15, weights=distance, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=5, weights=uniform ................\n",
      "[CV] . metric=euclidean, n_neighbors=5, weights=uniform, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=5, weights=uniform ................\n",
      "[CV] . metric=euclidean, n_neighbors=5, weights=uniform, total=   0.3s\n",
      "[CV] metric=euclidean, n_neighbors=5, weights=uniform ................\n",
      "[CV] . metric=euclidean, n_neighbors=5, weights=uniform, total=   0.4s\n",
      "[CV] metric=euclidean, n_neighbors=5, weights=uniform ................\n",
      "[CV] . metric=euclidean, n_neighbors=5, weights=uniform, total=   0.4s\n",
      "[CV] metric=euclidean, n_neighbors=5, weights=uniform ................\n",
      "[CV] . metric=euclidean, n_neighbors=5, weights=uniform, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=5, weights=distance ...............\n",
      "[CV]  metric=euclidean, n_neighbors=5, weights=distance, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=5, weights=distance ...............\n",
      "[CV]  metric=euclidean, n_neighbors=5, weights=distance, total=   0.3s\n",
      "[CV] metric=euclidean, n_neighbors=5, weights=distance ...............\n",
      "[CV]  metric=euclidean, n_neighbors=5, weights=distance, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=5, weights=distance ...............\n",
      "[CV]  metric=euclidean, n_neighbors=5, weights=distance, total=   0.4s\n",
      "[CV] metric=euclidean, n_neighbors=5, weights=distance ...............\n",
      "[CV]  metric=euclidean, n_neighbors=5, weights=distance, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=6, weights=uniform ................\n",
      "[CV] . metric=euclidean, n_neighbors=6, weights=uniform, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=6, weights=uniform ................\n",
      "[CV] . metric=euclidean, n_neighbors=6, weights=uniform, total=   0.3s\n",
      "[CV] metric=euclidean, n_neighbors=6, weights=uniform ................\n",
      "[CV] . metric=euclidean, n_neighbors=6, weights=uniform, total=   0.4s\n",
      "[CV] metric=euclidean, n_neighbors=6, weights=uniform ................\n",
      "[CV] . metric=euclidean, n_neighbors=6, weights=uniform, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=6, weights=uniform ................\n",
      "[CV] . metric=euclidean, n_neighbors=6, weights=uniform, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=6, weights=distance ...............\n",
      "[CV]  metric=euclidean, n_neighbors=6, weights=distance, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=6, weights=distance ...............\n",
      "[CV]  metric=euclidean, n_neighbors=6, weights=distance, total=   0.3s\n",
      "[CV] metric=euclidean, n_neighbors=6, weights=distance ...............\n",
      "[CV]  metric=euclidean, n_neighbors=6, weights=distance, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=6, weights=distance ...............\n",
      "[CV]  metric=euclidean, n_neighbors=6, weights=distance, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=6, weights=distance ...............\n",
      "[CV]  metric=euclidean, n_neighbors=6, weights=distance, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=7, weights=uniform ................\n",
      "[CV] . metric=euclidean, n_neighbors=7, weights=uniform, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=7, weights=uniform ................\n",
      "[CV] . metric=euclidean, n_neighbors=7, weights=uniform, total=   0.3s\n",
      "[CV] metric=euclidean, n_neighbors=7, weights=uniform ................\n",
      "[CV] . metric=euclidean, n_neighbors=7, weights=uniform, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=7, weights=uniform ................\n",
      "[CV] . metric=euclidean, n_neighbors=7, weights=uniform, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=7, weights=uniform ................\n",
      "[CV] . metric=euclidean, n_neighbors=7, weights=uniform, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=7, weights=distance ...............\n",
      "[CV]  metric=euclidean, n_neighbors=7, weights=distance, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=7, weights=distance ...............\n",
      "[CV]  metric=euclidean, n_neighbors=7, weights=distance, total=   0.3s\n",
      "[CV] metric=euclidean, n_neighbors=7, weights=distance ...............\n",
      "[CV]  metric=euclidean, n_neighbors=7, weights=distance, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=7, weights=distance ...............\n",
      "[CV]  metric=euclidean, n_neighbors=7, weights=distance, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=7, weights=distance ...............\n",
      "[CV]  metric=euclidean, n_neighbors=7, weights=distance, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=8, weights=uniform ................\n",
      "[CV] . metric=euclidean, n_neighbors=8, weights=uniform, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=8, weights=uniform ................\n",
      "[CV] . metric=euclidean, n_neighbors=8, weights=uniform, total=   0.3s\n",
      "[CV] metric=euclidean, n_neighbors=8, weights=uniform ................\n",
      "[CV] . metric=euclidean, n_neighbors=8, weights=uniform, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=8, weights=uniform ................\n",
      "[CV] . metric=euclidean, n_neighbors=8, weights=uniform, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=8, weights=uniform ................\n",
      "[CV] . metric=euclidean, n_neighbors=8, weights=uniform, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=8, weights=distance ...............\n",
      "[CV]  metric=euclidean, n_neighbors=8, weights=distance, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=8, weights=distance ...............\n",
      "[CV]  metric=euclidean, n_neighbors=8, weights=distance, total=   0.3s\n",
      "[CV] metric=euclidean, n_neighbors=8, weights=distance ...............\n",
      "[CV]  metric=euclidean, n_neighbors=8, weights=distance, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=8, weights=distance ...............\n",
      "[CV]  metric=euclidean, n_neighbors=8, weights=distance, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=8, weights=distance ...............\n",
      "[CV]  metric=euclidean, n_neighbors=8, weights=distance, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=9, weights=uniform ................\n",
      "[CV] . metric=euclidean, n_neighbors=9, weights=uniform, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=9, weights=uniform ................\n",
      "[CV] . metric=euclidean, n_neighbors=9, weights=uniform, total=   0.4s\n",
      "[CV] metric=euclidean, n_neighbors=9, weights=uniform ................\n",
      "[CV] . metric=euclidean, n_neighbors=9, weights=uniform, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=9, weights=uniform ................\n",
      "[CV] . metric=euclidean, n_neighbors=9, weights=uniform, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=9, weights=uniform ................\n",
      "[CV] . metric=euclidean, n_neighbors=9, weights=uniform, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=9, weights=distance ...............\n",
      "[CV]  metric=euclidean, n_neighbors=9, weights=distance, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=9, weights=distance ...............\n",
      "[CV]  metric=euclidean, n_neighbors=9, weights=distance, total=   0.4s\n",
      "[CV] metric=euclidean, n_neighbors=9, weights=distance ...............\n",
      "[CV]  metric=euclidean, n_neighbors=9, weights=distance, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=9, weights=distance ...............\n",
      "[CV]  metric=euclidean, n_neighbors=9, weights=distance, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=9, weights=distance ...............\n",
      "[CV]  metric=euclidean, n_neighbors=9, weights=distance, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=10, weights=uniform ...............\n",
      "[CV]  metric=euclidean, n_neighbors=10, weights=uniform, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=10, weights=uniform ...............\n",
      "[CV]  metric=euclidean, n_neighbors=10, weights=uniform, total=   0.4s\n",
      "[CV] metric=euclidean, n_neighbors=10, weights=uniform ...............\n",
      "[CV]  metric=euclidean, n_neighbors=10, weights=uniform, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=10, weights=uniform ...............\n",
      "[CV]  metric=euclidean, n_neighbors=10, weights=uniform, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=10, weights=uniform ...............\n",
      "[CV]  metric=euclidean, n_neighbors=10, weights=uniform, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=10, weights=distance ..............\n",
      "[CV]  metric=euclidean, n_neighbors=10, weights=distance, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=10, weights=distance ..............\n",
      "[CV]  metric=euclidean, n_neighbors=10, weights=distance, total=   0.4s\n",
      "[CV] metric=euclidean, n_neighbors=10, weights=distance ..............\n",
      "[CV]  metric=euclidean, n_neighbors=10, weights=distance, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=10, weights=distance ..............\n",
      "[CV]  metric=euclidean, n_neighbors=10, weights=distance, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=10, weights=distance ..............\n",
      "[CV]  metric=euclidean, n_neighbors=10, weights=distance, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=11, weights=uniform ...............\n",
      "[CV]  metric=euclidean, n_neighbors=11, weights=uniform, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=11, weights=uniform ...............\n",
      "[CV]  metric=euclidean, n_neighbors=11, weights=uniform, total=   0.4s\n",
      "[CV] metric=euclidean, n_neighbors=11, weights=uniform ...............\n",
      "[CV]  metric=euclidean, n_neighbors=11, weights=uniform, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=11, weights=uniform ...............\n",
      "[CV]  metric=euclidean, n_neighbors=11, weights=uniform, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=11, weights=uniform ...............\n",
      "[CV]  metric=euclidean, n_neighbors=11, weights=uniform, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=11, weights=distance ..............\n",
      "[CV]  metric=euclidean, n_neighbors=11, weights=distance, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=11, weights=distance ..............\n",
      "[CV]  metric=euclidean, n_neighbors=11, weights=distance, total=   0.4s\n",
      "[CV] metric=euclidean, n_neighbors=11, weights=distance ..............\n",
      "[CV]  metric=euclidean, n_neighbors=11, weights=distance, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=11, weights=distance ..............\n",
      "[CV]  metric=euclidean, n_neighbors=11, weights=distance, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=11, weights=distance ..............\n",
      "[CV]  metric=euclidean, n_neighbors=11, weights=distance, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=12, weights=uniform ...............\n",
      "[CV]  metric=euclidean, n_neighbors=12, weights=uniform, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=12, weights=uniform ...............\n",
      "[CV]  metric=euclidean, n_neighbors=12, weights=uniform, total=   0.4s\n",
      "[CV] metric=euclidean, n_neighbors=12, weights=uniform ...............\n",
      "[CV]  metric=euclidean, n_neighbors=12, weights=uniform, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=12, weights=uniform ...............\n",
      "[CV]  metric=euclidean, n_neighbors=12, weights=uniform, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=12, weights=uniform ...............\n",
      "[CV]  metric=euclidean, n_neighbors=12, weights=uniform, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=12, weights=distance ..............\n",
      "[CV]  metric=euclidean, n_neighbors=12, weights=distance, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=12, weights=distance ..............\n",
      "[CV]  metric=euclidean, n_neighbors=12, weights=distance, total=   0.4s\n",
      "[CV] metric=euclidean, n_neighbors=12, weights=distance ..............\n",
      "[CV]  metric=euclidean, n_neighbors=12, weights=distance, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=12, weights=distance ..............\n",
      "[CV]  metric=euclidean, n_neighbors=12, weights=distance, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=12, weights=distance ..............\n",
      "[CV]  metric=euclidean, n_neighbors=12, weights=distance, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=13, weights=uniform ...............\n",
      "[CV]  metric=euclidean, n_neighbors=13, weights=uniform, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=13, weights=uniform ...............\n",
      "[CV]  metric=euclidean, n_neighbors=13, weights=uniform, total=   0.4s\n",
      "[CV] metric=euclidean, n_neighbors=13, weights=uniform ...............\n",
      "[CV]  metric=euclidean, n_neighbors=13, weights=uniform, total=   0.5s\n",
      "[CV] metric=euclidean, n_neighbors=13, weights=uniform ...............\n",
      "[CV]  metric=euclidean, n_neighbors=13, weights=uniform, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=13, weights=uniform ...............\n",
      "[CV]  metric=euclidean, n_neighbors=13, weights=uniform, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=13, weights=distance ..............\n",
      "[CV]  metric=euclidean, n_neighbors=13, weights=distance, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=13, weights=distance ..............\n",
      "[CV]  metric=euclidean, n_neighbors=13, weights=distance, total=   0.4s\n",
      "[CV] metric=euclidean, n_neighbors=13, weights=distance ..............\n",
      "[CV]  metric=euclidean, n_neighbors=13, weights=distance, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=13, weights=distance ..............\n",
      "[CV]  metric=euclidean, n_neighbors=13, weights=distance, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=13, weights=distance ..............\n",
      "[CV]  metric=euclidean, n_neighbors=13, weights=distance, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=14, weights=uniform ...............\n",
      "[CV]  metric=euclidean, n_neighbors=14, weights=uniform, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=14, weights=uniform ...............\n",
      "[CV]  metric=euclidean, n_neighbors=14, weights=uniform, total=   0.4s\n",
      "[CV] metric=euclidean, n_neighbors=14, weights=uniform ...............\n",
      "[CV]  metric=euclidean, n_neighbors=14, weights=uniform, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=14, weights=uniform ...............\n",
      "[CV]  metric=euclidean, n_neighbors=14, weights=uniform, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=14, weights=uniform ...............\n",
      "[CV]  metric=euclidean, n_neighbors=14, weights=uniform, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=14, weights=distance ..............\n",
      "[CV]  metric=euclidean, n_neighbors=14, weights=distance, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=14, weights=distance ..............\n",
      "[CV]  metric=euclidean, n_neighbors=14, weights=distance, total=   0.4s\n",
      "[CV] metric=euclidean, n_neighbors=14, weights=distance ..............\n",
      "[CV]  metric=euclidean, n_neighbors=14, weights=distance, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=14, weights=distance ..............\n",
      "[CV]  metric=euclidean, n_neighbors=14, weights=distance, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=14, weights=distance ..............\n",
      "[CV]  metric=euclidean, n_neighbors=14, weights=distance, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=15, weights=uniform ...............\n",
      "[CV]  metric=euclidean, n_neighbors=15, weights=uniform, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=15, weights=uniform ...............\n",
      "[CV]  metric=euclidean, n_neighbors=15, weights=uniform, total=   0.4s\n",
      "[CV] metric=euclidean, n_neighbors=15, weights=uniform ...............\n",
      "[CV]  metric=euclidean, n_neighbors=15, weights=uniform, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=15, weights=uniform ...............\n",
      "[CV]  metric=euclidean, n_neighbors=15, weights=uniform, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=15, weights=uniform ...............\n",
      "[CV]  metric=euclidean, n_neighbors=15, weights=uniform, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=15, weights=distance ..............\n",
      "[CV]  metric=euclidean, n_neighbors=15, weights=distance, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=15, weights=distance ..............\n",
      "[CV]  metric=euclidean, n_neighbors=15, weights=distance, total=   0.4s\n",
      "[CV] metric=euclidean, n_neighbors=15, weights=distance ..............\n",
      "[CV]  metric=euclidean, n_neighbors=15, weights=distance, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=15, weights=distance ..............\n",
      "[CV]  metric=euclidean, n_neighbors=15, weights=distance, total=   0.6s\n",
      "[CV] metric=euclidean, n_neighbors=15, weights=distance ..............\n",
      "[CV]  metric=euclidean, n_neighbors=15, weights=distance, total=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 220 out of 220 | elapsed:  8.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'metric': 'minkowski', 'n_neighbors': 11, 'weights': 'distance'}"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform KNN regression using a variety of values for n_neighbors (K) between 1 and 10 \n",
    "# and both \"uniform\" and \"distance\" weights via a grid search \n",
    "# where  *housing_labels* is the output and all other features are the input \n",
    "# (similar to as seen in lecture two.)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "param_grid = [\n",
    "    # try 12 (3×4) combinations of hyperparameters\n",
    "    {'n_neighbors': [5,6,7,8,9,10,11,12,13,14,15], 'weights': ['uniform', 'distance'],\n",
    "    'metric': ['minkowski', 'euclidean']\n",
    "    },\n",
    "    # then try 6 (2×3) combinations with bootstrap set as False\n",
    "#     {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True, verbose=2)\n",
    "grid_search.fit(housing_prepared, housing_labels)\n",
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=None, n_neighbors=11, p=2,\n",
      "                    weights='distance')\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_estimator_)\n",
    "# feature_importances = grid_search.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61144.144666930835 {'metric': 'minkowski', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "60745.17066067925 {'metric': 'minkowski', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "60624.02086206421 {'metric': 'minkowski', 'n_neighbors': 6, 'weights': 'uniform'}\n",
      "60178.95903752728 {'metric': 'minkowski', 'n_neighbors': 6, 'weights': 'distance'}\n",
      "60403.78739053305 {'metric': 'minkowski', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "59909.83861155471 {'metric': 'minkowski', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "60300.86232078644 {'metric': 'minkowski', 'n_neighbors': 8, 'weights': 'uniform'}\n",
      "59778.81261312459 {'metric': 'minkowski', 'n_neighbors': 8, 'weights': 'distance'}\n",
      "60249.47589700753 {'metric': 'minkowski', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "59700.28187013157 {'metric': 'minkowski', 'n_neighbors': 9, 'weights': 'distance'}\n",
      "60238.776775255064 {'metric': 'minkowski', 'n_neighbors': 10, 'weights': 'uniform'}\n",
      "59665.82069939555 {'metric': 'minkowski', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "60241.38011652888 {'metric': 'minkowski', 'n_neighbors': 11, 'weights': 'uniform'}\n",
      "59650.894142275036 {'metric': 'minkowski', 'n_neighbors': 11, 'weights': 'distance'}\n",
      "60308.644766740115 {'metric': 'minkowski', 'n_neighbors': 12, 'weights': 'uniform'}\n",
      "59696.90337927546 {'metric': 'minkowski', 'n_neighbors': 12, 'weights': 'distance'}\n",
      "60334.78707176274 {'metric': 'minkowski', 'n_neighbors': 13, 'weights': 'uniform'}\n",
      "59705.07041686854 {'metric': 'minkowski', 'n_neighbors': 13, 'weights': 'distance'}\n",
      "60400.795590806185 {'metric': 'minkowski', 'n_neighbors': 14, 'weights': 'uniform'}\n",
      "59755.05939593196 {'metric': 'minkowski', 'n_neighbors': 14, 'weights': 'distance'}\n",
      "60427.96692969777 {'metric': 'minkowski', 'n_neighbors': 15, 'weights': 'uniform'}\n",
      "59771.81816265303 {'metric': 'minkowski', 'n_neighbors': 15, 'weights': 'distance'}\n",
      "61144.144666930835 {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "60745.17066067925 {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "60624.02086206421 {'metric': 'euclidean', 'n_neighbors': 6, 'weights': 'uniform'}\n",
      "60178.95903752728 {'metric': 'euclidean', 'n_neighbors': 6, 'weights': 'distance'}\n",
      "60403.78739053305 {'metric': 'euclidean', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "59909.83861155471 {'metric': 'euclidean', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "60300.86232078644 {'metric': 'euclidean', 'n_neighbors': 8, 'weights': 'uniform'}\n",
      "59778.81261312459 {'metric': 'euclidean', 'n_neighbors': 8, 'weights': 'distance'}\n",
      "60249.47589700753 {'metric': 'euclidean', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "59700.28187013157 {'metric': 'euclidean', 'n_neighbors': 9, 'weights': 'distance'}\n",
      "60238.776775255064 {'metric': 'euclidean', 'n_neighbors': 10, 'weights': 'uniform'}\n",
      "59665.82069939555 {'metric': 'euclidean', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "60241.38011652888 {'metric': 'euclidean', 'n_neighbors': 11, 'weights': 'uniform'}\n",
      "59650.894142275036 {'metric': 'euclidean', 'n_neighbors': 11, 'weights': 'distance'}\n",
      "60308.644766740115 {'metric': 'euclidean', 'n_neighbors': 12, 'weights': 'uniform'}\n",
      "59696.90337927546 {'metric': 'euclidean', 'n_neighbors': 12, 'weights': 'distance'}\n",
      "60334.78707176274 {'metric': 'euclidean', 'n_neighbors': 13, 'weights': 'uniform'}\n",
      "59705.07041686854 {'metric': 'euclidean', 'n_neighbors': 13, 'weights': 'distance'}\n",
      "60400.795590806185 {'metric': 'euclidean', 'n_neighbors': 14, 'weights': 'uniform'}\n",
      "59755.05939593196 {'metric': 'euclidean', 'n_neighbors': 14, 'weights': 'distance'}\n",
      "60427.96692969777 {'metric': 'euclidean', 'n_neighbors': 15, 'weights': 'uniform'}\n",
      "59771.81816265303 {'metric': 'euclidean', 'n_neighbors': 15, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "cvgrid = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvgrid[\"mean_test_score\"], cvgrid[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [62350.39873138 60494.04990595 60868.50499658 61163.35319944\n",
      " 60827.61843233]\n",
      "Mean: 61140.78505313587\n",
      "Standard deviation: 640.9603238918779\n"
     ]
    }
   ],
   "source": [
    "# test out our best params\n",
    "knnbest = KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "                    metric_params=None, n_jobs=2, n_neighbors=11, p=2,\n",
    "                    weights='distance')\n",
    "\n",
    "scores = cross_val_score(knn, housing_prepared, housing_labels,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "knn_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(knn_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=32, metric='euclidean',\n",
       "                    metric_params=None, n_jobs=None, n_neighbors=11, p=2,\n",
       "                    weights='distance')"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distribs = {\n",
    "        'n_neighbors': randint(low=5, high=20),\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'leaf_size': randint(low=30, high=40),\n",
    "        'metric': ['minkowski', 'euclidean']\n",
    "    }\n",
    "\n",
    "rnd_search = RandomizedSearchCV(knn, param_distributions=param_distribs, n_jobs=2,\n",
    "                                n_iter=100, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "rnd_search.fit(housing_prepared, housing_labels)\n",
    "\n",
    "# rnd_search.best_params_\n",
    "rnd_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60427.96692969777 {'leaf_size': 36, 'metric': 'euclidean', 'n_neighbors': 15, 'weights': 'uniform'}\n",
      "59909.83861155471 {'leaf_size': 37, 'metric': 'minkowski', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "60241.38011652888 {'leaf_size': 32, 'metric': 'minkowski', 'n_neighbors': 11, 'weights': 'uniform'}\n",
      "61438.26329050499 {'leaf_size': 37, 'metric': 'minkowski', 'n_neighbors': 4, 'weights': 'distance'}\n",
      "66205.66298388786 {'leaf_size': 37, 'metric': 'minkowski', 'n_neighbors': 2, 'weights': 'distance'}\n",
      "76182.30181880607 {'leaf_size': 35, 'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'distance'}\n",
      "60308.644766740115 {'leaf_size': 39, 'metric': 'euclidean', 'n_neighbors': 12, 'weights': 'uniform'}\n",
      "59665.82069939555 {'leaf_size': 30, 'metric': 'minkowski', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "63203.674759297166 {'leaf_size': 32, 'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "60249.47589700753 {'leaf_size': 32, 'metric': 'minkowski', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "59755.05939593196 {'leaf_size': 31, 'metric': 'euclidean', 'n_neighbors': 14, 'weights': 'distance'}\n",
      "66205.66298388786 {'leaf_size': 39, 'metric': 'minkowski', 'n_neighbors': 2, 'weights': 'distance'}\n",
      "60300.86232078644 {'leaf_size': 36, 'metric': 'euclidean', 'n_neighbors': 8, 'weights': 'uniform'}\n",
      "59898.14653960737 {'leaf_size': 32, 'metric': 'euclidean', 'n_neighbors': 17, 'weights': 'distance'}\n",
      "61438.26329050499 {'leaf_size': 31, 'metric': 'euclidean', 'n_neighbors': 4, 'weights': 'distance'}\n",
      "59665.82069939555 {'leaf_size': 35, 'metric': 'euclidean', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "60003.249122113055 {'leaf_size': 35, 'metric': 'minkowski', 'n_neighbors': 18, 'weights': 'distance'}\n",
      "61438.26329050499 {'leaf_size': 31, 'metric': 'euclidean', 'n_neighbors': 4, 'weights': 'distance'}\n",
      "60300.86232078644 {'leaf_size': 37, 'metric': 'euclidean', 'n_neighbors': 8, 'weights': 'uniform'}\n",
      "60334.78707176274 {'leaf_size': 31, 'metric': 'minkowski', 'n_neighbors': 13, 'weights': 'uniform'}\n",
      "60403.78739053305 {'leaf_size': 30, 'metric': 'minkowski', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "59696.90337927546 {'leaf_size': 37, 'metric': 'minkowski', 'n_neighbors': 12, 'weights': 'distance'}\n",
      "60241.38011652888 {'leaf_size': 37, 'metric': 'minkowski', 'n_neighbors': 11, 'weights': 'uniform'}\n",
      "63203.674759297166 {'leaf_size': 30, 'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "60745.17066067925 {'leaf_size': 30, 'metric': 'minkowski', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "59700.28187013157 {'leaf_size': 36, 'metric': 'euclidean', 'n_neighbors': 9, 'weights': 'distance'}\n",
      "59778.81261312459 {'leaf_size': 36, 'metric': 'minkowski', 'n_neighbors': 8, 'weights': 'distance'}\n",
      "60484.02354996668 {'leaf_size': 31, 'metric': 'minkowski', 'n_neighbors': 16, 'weights': 'uniform'}\n",
      "61144.144666930835 {'leaf_size': 36, 'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "63203.674759297166 {'leaf_size': 37, 'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "59771.81816265303 {'leaf_size': 32, 'metric': 'minkowski', 'n_neighbors': 15, 'weights': 'distance'}\n",
      "60745.17066067925 {'leaf_size': 32, 'metric': 'minkowski', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "60400.795590806185 {'leaf_size': 36, 'metric': 'minkowski', 'n_neighbors': 14, 'weights': 'uniform'}\n",
      "59771.81816265303 {'leaf_size': 38, 'metric': 'minkowski', 'n_neighbors': 15, 'weights': 'distance'}\n",
      "60334.78707176274 {'leaf_size': 39, 'metric': 'euclidean', 'n_neighbors': 13, 'weights': 'uniform'}\n",
      "61438.26329050499 {'leaf_size': 36, 'metric': 'minkowski', 'n_neighbors': 4, 'weights': 'distance'}\n",
      "60403.78739053305 {'leaf_size': 34, 'metric': 'minkowski', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "60403.78739053305 {'leaf_size': 33, 'metric': 'minkowski', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "66205.66298388786 {'leaf_size': 32, 'metric': 'euclidean', 'n_neighbors': 2, 'weights': 'distance'}\n",
      "60178.95903752728 {'leaf_size': 38, 'metric': 'minkowski', 'n_neighbors': 6, 'weights': 'distance'}\n",
      "59650.894142275036 {'leaf_size': 33, 'metric': 'euclidean', 'n_neighbors': 11, 'weights': 'distance'}\n",
      "59909.83861155471 {'leaf_size': 39, 'metric': 'minkowski', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "60334.78707176274 {'leaf_size': 30, 'metric': 'minkowski', 'n_neighbors': 13, 'weights': 'uniform'}\n",
      "60178.95903752728 {'leaf_size': 32, 'metric': 'minkowski', 'n_neighbors': 6, 'weights': 'distance'}\n",
      "61144.144666930835 {'leaf_size': 38, 'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "59696.90337927546 {'leaf_size': 32, 'metric': 'euclidean', 'n_neighbors': 12, 'weights': 'distance'}\n",
      "59700.28187013157 {'leaf_size': 35, 'metric': 'euclidean', 'n_neighbors': 9, 'weights': 'distance'}\n",
      "59898.14653960737 {'leaf_size': 30, 'metric': 'euclidean', 'n_neighbors': 17, 'weights': 'distance'}\n",
      "59909.83861155471 {'leaf_size': 33, 'metric': 'euclidean', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "61144.144666930835 {'leaf_size': 32, 'metric': 'minkowski', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "59898.14653960737 {'leaf_size': 37, 'metric': 'minkowski', 'n_neighbors': 17, 'weights': 'distance'}\n",
      "60745.17066067925 {'leaf_size': 31, 'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "60059.99091557974 {'leaf_size': 30, 'metric': 'minkowski', 'n_neighbors': 19, 'weights': 'distance'}\n",
      "59696.90337927546 {'leaf_size': 31, 'metric': 'minkowski', 'n_neighbors': 12, 'weights': 'distance'}\n",
      "61724.90669125751 {'leaf_size': 35, 'metric': 'euclidean', 'n_neighbors': 4, 'weights': 'uniform'}\n",
      "60580.50832587332 {'leaf_size': 37, 'metric': 'minkowski', 'n_neighbors': 17, 'weights': 'uniform'}\n",
      "60745.17066067925 {'leaf_size': 35, 'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "60241.38011652888 {'leaf_size': 31, 'metric': 'euclidean', 'n_neighbors': 11, 'weights': 'uniform'}\n",
      "60178.95903752728 {'leaf_size': 30, 'metric': 'minkowski', 'n_neighbors': 6, 'weights': 'distance'}\n",
      "61724.90669125751 {'leaf_size': 32, 'metric': 'euclidean', 'n_neighbors': 4, 'weights': 'uniform'}\n",
      "60059.99091557974 {'leaf_size': 39, 'metric': 'minkowski', 'n_neighbors': 19, 'weights': 'distance'}\n",
      "60249.47589700753 {'leaf_size': 36, 'metric': 'euclidean', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "59909.83861155471 {'leaf_size': 37, 'metric': 'euclidean', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "59650.894142275036 {'leaf_size': 37, 'metric': 'minkowski', 'n_neighbors': 11, 'weights': 'distance'}\n",
      "60698.78791960757 {'leaf_size': 38, 'metric': 'minkowski', 'n_neighbors': 18, 'weights': 'uniform'}\n",
      "59909.83861155471 {'leaf_size': 39, 'metric': 'minkowski', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "59898.14653960737 {'leaf_size': 39, 'metric': 'euclidean', 'n_neighbors': 17, 'weights': 'distance'}\n",
      "60308.644766740115 {'leaf_size': 30, 'metric': 'euclidean', 'n_neighbors': 12, 'weights': 'uniform'}\n",
      "60249.47589700753 {'leaf_size': 34, 'metric': 'euclidean', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "59816.05450025644 {'leaf_size': 32, 'metric': 'minkowski', 'n_neighbors': 16, 'weights': 'distance'}\n",
      "76182.30181880607 {'leaf_size': 32, 'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'distance'}\n",
      "59898.14653960737 {'leaf_size': 33, 'metric': 'minkowski', 'n_neighbors': 17, 'weights': 'distance'}\n",
      "59778.81261312459 {'leaf_size': 33, 'metric': 'euclidean', 'n_neighbors': 8, 'weights': 'distance'}\n",
      "63203.674759297166 {'leaf_size': 32, 'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "59755.05939593196 {'leaf_size': 31, 'metric': 'euclidean', 'n_neighbors': 14, 'weights': 'distance'}\n",
      "63025.87307349791 {'leaf_size': 31, 'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "76182.30181880607 {'leaf_size': 38, 'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'distance'}\n",
      "59816.05450025644 {'leaf_size': 30, 'metric': 'euclidean', 'n_neighbors': 16, 'weights': 'distance'}\n",
      "60300.86232078644 {'leaf_size': 37, 'metric': 'euclidean', 'n_neighbors': 8, 'weights': 'uniform'}\n",
      "76182.30181880607 {'leaf_size': 32, 'metric': 'minkowski', 'n_neighbors': 1, 'weights': 'distance'}\n",
      "59755.05939593196 {'leaf_size': 32, 'metric': 'euclidean', 'n_neighbors': 14, 'weights': 'distance'}\n",
      "60334.78707176274 {'leaf_size': 35, 'metric': 'euclidean', 'n_neighbors': 13, 'weights': 'uniform'}\n",
      "66265.38470145852 {'leaf_size': 35, 'metric': 'euclidean', 'n_neighbors': 2, 'weights': 'uniform'}\n",
      "59771.81816265303 {'leaf_size': 30, 'metric': 'euclidean', 'n_neighbors': 15, 'weights': 'distance'}\n",
      "60484.02354996668 {'leaf_size': 30, 'metric': 'minkowski', 'n_neighbors': 16, 'weights': 'uniform'}\n",
      "59898.14653960737 {'leaf_size': 33, 'metric': 'minkowski', 'n_neighbors': 17, 'weights': 'distance'}\n",
      "60400.795590806185 {'leaf_size': 30, 'metric': 'euclidean', 'n_neighbors': 14, 'weights': 'uniform'}\n",
      "60249.47589700753 {'leaf_size': 35, 'metric': 'minkowski', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "59898.14653960737 {'leaf_size': 37, 'metric': 'minkowski', 'n_neighbors': 17, 'weights': 'distance'}\n",
      "63025.87307349791 {'leaf_size': 34, 'metric': 'minkowski', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "76182.30181880607 {'leaf_size': 30, 'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'distance'}\n",
      "60698.78791960757 {'leaf_size': 32, 'metric': 'euclidean', 'n_neighbors': 18, 'weights': 'uniform'}\n",
      "63025.87307349791 {'leaf_size': 39, 'metric': 'minkowski', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "59771.81816265303 {'leaf_size': 37, 'metric': 'euclidean', 'n_neighbors': 15, 'weights': 'distance'}\n",
      "59665.82069939555 {'leaf_size': 36, 'metric': 'euclidean', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "60300.86232078644 {'leaf_size': 39, 'metric': 'minkowski', 'n_neighbors': 8, 'weights': 'uniform'}\n",
      "60484.02354996668 {'leaf_size': 38, 'metric': 'minkowski', 'n_neighbors': 16, 'weights': 'uniform'}\n",
      "63025.87307349791 {'leaf_size': 39, 'metric': 'minkowski', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "59705.07041686854 {'leaf_size': 38, 'metric': 'euclidean', 'n_neighbors': 13, 'weights': 'distance'}\n",
      "61724.90669125751 {'leaf_size': 39, 'metric': 'minkowski', 'n_neighbors': 4, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "cvres = rnd_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)\n",
    "    \n",
    "# gridsearch best score 59650.894142275036\n",
    "# random search best score 59650.894142275036"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [60689.53684657 59294.63995931 59617.39747335 59313.17164435\n",
      " 59327.77795689]\n",
      "Mean: 59648.50477609326\n",
      "Standard deviation: 533.9006923404554\n"
     ]
    }
   ],
   "source": [
    "# test out our best random params\n",
    "kbbbest_random = KNeighborsRegressor(algorithm='auto', leaf_size=33, metric='euclidean',\n",
    "                    metric_params=None, n_jobs=None, n_neighbors=11, p=2,\n",
    "                    weights='distance')\n",
    "\n",
    "\n",
    "scores = cross_val_score(kbbbest_random, housing_prepared, housing_labels,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "knn_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(knn_rmse_scores)\n",
    "\n",
    "# Mean: 59648.50477609326\n",
    "# Standard deviation: 533.9006923404554"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying out SelectKBest and SelectFromModel - they did not help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16512, 10)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.datasets import load_iris\n",
    "# from sklearn.feature_selection import SelectKBest\n",
    "# from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "# X_new = SelectKBest(mutual_info_regression, k=10).fit_transform(housing_prepared, housing_labels)\n",
    "# X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor(algorithm='auto', leaf_size=33, metric='euclidean',\n",
      "                    metric_params=None, n_jobs=None, n_neighbors=11, p=2,\n",
      "                    weights='distance')\n",
      "63953.29927527397 {'leaf_size': 36, 'metric': 'euclidean', 'n_neighbors': 15, 'weights': 'uniform'}\n",
      "63729.61617472526 {'leaf_size': 37, 'metric': 'minkowski', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "63800.33495145485 {'leaf_size': 32, 'metric': 'minkowski', 'n_neighbors': 11, 'weights': 'uniform'}\n",
      "65221.82708534894 {'leaf_size': 37, 'metric': 'minkowski', 'n_neighbors': 4, 'weights': 'distance'}\n",
      "69949.94226977209 {'leaf_size': 37, 'metric': 'minkowski', 'n_neighbors': 2, 'weights': 'distance'}\n",
      "79664.60831940325 {'leaf_size': 35, 'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'distance'}\n",
      "63846.57554858102 {'leaf_size': 39, 'metric': 'euclidean', 'n_neighbors': 12, 'weights': 'uniform'}\n",
      "63252.24370650049 {'leaf_size': 30, 'metric': 'minkowski', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "67142.71637778578 {'leaf_size': 32, 'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "63955.28058174336 {'leaf_size': 32, 'metric': 'minkowski', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "63237.288656612815 {'leaf_size': 31, 'metric': 'euclidean', 'n_neighbors': 14, 'weights': 'distance'}\n",
      "69949.94226977209 {'leaf_size': 39, 'metric': 'minkowski', 'n_neighbors': 2, 'weights': 'distance'}\n",
      "64038.28373202585 {'leaf_size': 36, 'metric': 'euclidean', 'n_neighbors': 8, 'weights': 'uniform'}\n",
      "63353.52591178061 {'leaf_size': 32, 'metric': 'euclidean', 'n_neighbors': 17, 'weights': 'distance'}\n",
      "65221.82708534894 {'leaf_size': 31, 'metric': 'euclidean', 'n_neighbors': 4, 'weights': 'distance'}\n",
      "63252.24370650049 {'leaf_size': 35, 'metric': 'euclidean', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "63396.55698316152 {'leaf_size': 35, 'metric': 'minkowski', 'n_neighbors': 18, 'weights': 'distance'}\n",
      "65221.82708534894 {'leaf_size': 31, 'metric': 'euclidean', 'n_neighbors': 4, 'weights': 'distance'}\n",
      "64038.28373202585 {'leaf_size': 37, 'metric': 'euclidean', 'n_neighbors': 8, 'weights': 'uniform'}\n",
      "63911.600485243885 {'leaf_size': 31, 'metric': 'minkowski', 'n_neighbors': 13, 'weights': 'uniform'}\n",
      "64267.539570958674 {'leaf_size': 30, 'metric': 'minkowski', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "63177.60856159737 {'leaf_size': 37, 'metric': 'minkowski', 'n_neighbors': 12, 'weights': 'distance'}\n",
      "63800.33495145485 {'leaf_size': 37, 'metric': 'minkowski', 'n_neighbors': 11, 'weights': 'uniform'}\n",
      "67142.71637778578 {'leaf_size': 30, 'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "64543.55917230826 {'leaf_size': 30, 'metric': 'minkowski', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "63344.248346033935 {'leaf_size': 36, 'metric': 'euclidean', 'n_neighbors': 9, 'weights': 'distance'}\n",
      "63469.69582570539 {'leaf_size': 36, 'metric': 'minkowski', 'n_neighbors': 8, 'weights': 'distance'}\n",
      "64009.324161534634 {'leaf_size': 31, 'metric': 'minkowski', 'n_neighbors': 16, 'weights': 'uniform'}\n",
      "65017.28314269363 {'leaf_size': 36, 'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "67142.71637778578 {'leaf_size': 37, 'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "63214.386048231776 {'leaf_size': 32, 'metric': 'minkowski', 'n_neighbors': 15, 'weights': 'distance'}\n",
      "64543.55917230826 {'leaf_size': 32, 'metric': 'minkowski', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "63967.8381757791 {'leaf_size': 36, 'metric': 'minkowski', 'n_neighbors': 14, 'weights': 'uniform'}\n",
      "63214.386048231776 {'leaf_size': 38, 'metric': 'minkowski', 'n_neighbors': 15, 'weights': 'distance'}\n",
      "63911.600485243885 {'leaf_size': 39, 'metric': 'euclidean', 'n_neighbors': 13, 'weights': 'uniform'}\n",
      "65221.82708534894 {'leaf_size': 36, 'metric': 'minkowski', 'n_neighbors': 4, 'weights': 'distance'}\n",
      "64267.539570958674 {'leaf_size': 34, 'metric': 'minkowski', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "64267.539570958674 {'leaf_size': 33, 'metric': 'minkowski', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "69949.94226977209 {'leaf_size': 32, 'metric': 'euclidean', 'n_neighbors': 2, 'weights': 'distance'}\n",
      "64064.12956629983 {'leaf_size': 38, 'metric': 'minkowski', 'n_neighbors': 6, 'weights': 'distance'}\n",
      "63163.61852664803 {'leaf_size': 33, 'metric': 'euclidean', 'n_neighbors': 11, 'weights': 'distance'}\n",
      "63729.61617472526 {'leaf_size': 39, 'metric': 'minkowski', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "63911.600485243885 {'leaf_size': 30, 'metric': 'minkowski', 'n_neighbors': 13, 'weights': 'uniform'}\n",
      "64064.12956629983 {'leaf_size': 32, 'metric': 'minkowski', 'n_neighbors': 6, 'weights': 'distance'}\n",
      "65017.28314269363 {'leaf_size': 38, 'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "63177.60856159737 {'leaf_size': 32, 'metric': 'euclidean', 'n_neighbors': 12, 'weights': 'distance'}\n",
      "63344.248346033935 {'leaf_size': 35, 'metric': 'euclidean', 'n_neighbors': 9, 'weights': 'distance'}\n",
      "63353.52591178061 {'leaf_size': 30, 'metric': 'euclidean', 'n_neighbors': 17, 'weights': 'distance'}\n",
      "63729.61617472526 {'leaf_size': 33, 'metric': 'euclidean', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "65017.28314269363 {'leaf_size': 32, 'metric': 'minkowski', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "63353.52591178061 {'leaf_size': 37, 'metric': 'minkowski', 'n_neighbors': 17, 'weights': 'distance'}\n",
      "64543.55917230826 {'leaf_size': 31, 'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "63404.62540212471 {'leaf_size': 30, 'metric': 'minkowski', 'n_neighbors': 19, 'weights': 'distance'}\n",
      "63177.60856159737 {'leaf_size': 31, 'metric': 'minkowski', 'n_neighbors': 12, 'weights': 'distance'}\n",
      "65589.34326220563 {'leaf_size': 35, 'metric': 'euclidean', 'n_neighbors': 4, 'weights': 'uniform'}\n",
      "64133.13232397854 {'leaf_size': 37, 'metric': 'minkowski', 'n_neighbors': 17, 'weights': 'uniform'}\n",
      "64543.55917230826 {'leaf_size': 35, 'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "63800.33495145485 {'leaf_size': 31, 'metric': 'euclidean', 'n_neighbors': 11, 'weights': 'uniform'}\n",
      "64064.12956629983 {'leaf_size': 30, 'metric': 'minkowski', 'n_neighbors': 6, 'weights': 'distance'}\n",
      "65589.34326220563 {'leaf_size': 32, 'metric': 'euclidean', 'n_neighbors': 4, 'weights': 'uniform'}\n",
      "63404.62540212471 {'leaf_size': 39, 'metric': 'minkowski', 'n_neighbors': 19, 'weights': 'distance'}\n",
      "63955.28058174336 {'leaf_size': 36, 'metric': 'euclidean', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "63729.61617472526 {'leaf_size': 37, 'metric': 'euclidean', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "63163.61852664803 {'leaf_size': 37, 'metric': 'minkowski', 'n_neighbors': 11, 'weights': 'distance'}\n",
      "64184.22727474099 {'leaf_size': 38, 'metric': 'minkowski', 'n_neighbors': 18, 'weights': 'uniform'}\n",
      "63729.61617472526 {'leaf_size': 39, 'metric': 'minkowski', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "63353.52591178061 {'leaf_size': 39, 'metric': 'euclidean', 'n_neighbors': 17, 'weights': 'distance'}\n",
      "63846.57554858102 {'leaf_size': 30, 'metric': 'euclidean', 'n_neighbors': 12, 'weights': 'uniform'}\n",
      "63955.28058174336 {'leaf_size': 34, 'metric': 'euclidean', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "63254.59698337728 {'leaf_size': 32, 'metric': 'minkowski', 'n_neighbors': 16, 'weights': 'distance'}\n",
      "79664.60831940325 {'leaf_size': 32, 'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'distance'}\n",
      "63353.52591178061 {'leaf_size': 33, 'metric': 'minkowski', 'n_neighbors': 17, 'weights': 'distance'}\n",
      "63469.69582570539 {'leaf_size': 33, 'metric': 'euclidean', 'n_neighbors': 8, 'weights': 'distance'}\n",
      "67142.71637778578 {'leaf_size': 32, 'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "63237.288656612815 {'leaf_size': 31, 'metric': 'euclidean', 'n_neighbors': 14, 'weights': 'distance'}\n",
      "66859.86927295648 {'leaf_size': 31, 'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "79664.60831940325 {'leaf_size': 38, 'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'distance'}\n",
      "63254.59698337728 {'leaf_size': 30, 'metric': 'euclidean', 'n_neighbors': 16, 'weights': 'distance'}\n",
      "64038.28373202585 {'leaf_size': 37, 'metric': 'euclidean', 'n_neighbors': 8, 'weights': 'uniform'}\n",
      "79664.60831940325 {'leaf_size': 32, 'metric': 'minkowski', 'n_neighbors': 1, 'weights': 'distance'}\n",
      "63237.288656612815 {'leaf_size': 32, 'metric': 'euclidean', 'n_neighbors': 14, 'weights': 'distance'}\n",
      "63911.600485243885 {'leaf_size': 35, 'metric': 'euclidean', 'n_neighbors': 13, 'weights': 'uniform'}\n",
      "70071.58335585275 {'leaf_size': 35, 'metric': 'euclidean', 'n_neighbors': 2, 'weights': 'uniform'}\n",
      "63214.386048231776 {'leaf_size': 30, 'metric': 'euclidean', 'n_neighbors': 15, 'weights': 'distance'}\n",
      "64009.324161534634 {'leaf_size': 30, 'metric': 'minkowski', 'n_neighbors': 16, 'weights': 'uniform'}\n",
      "63353.52591178061 {'leaf_size': 33, 'metric': 'minkowski', 'n_neighbors': 17, 'weights': 'distance'}\n",
      "63967.8381757791 {'leaf_size': 30, 'metric': 'euclidean', 'n_neighbors': 14, 'weights': 'uniform'}\n",
      "63955.28058174336 {'leaf_size': 35, 'metric': 'minkowski', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "63353.52591178061 {'leaf_size': 37, 'metric': 'minkowski', 'n_neighbors': 17, 'weights': 'distance'}\n",
      "66859.86927295648 {'leaf_size': 34, 'metric': 'minkowski', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "79664.60831940325 {'leaf_size': 30, 'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'distance'}\n",
      "64184.22727474099 {'leaf_size': 32, 'metric': 'euclidean', 'n_neighbors': 18, 'weights': 'uniform'}\n",
      "66859.86927295648 {'leaf_size': 39, 'metric': 'minkowski', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "63214.386048231776 {'leaf_size': 37, 'metric': 'euclidean', 'n_neighbors': 15, 'weights': 'distance'}\n",
      "63252.24370650049 {'leaf_size': 36, 'metric': 'euclidean', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "64038.28373202585 {'leaf_size': 39, 'metric': 'minkowski', 'n_neighbors': 8, 'weights': 'uniform'}\n",
      "64009.324161534634 {'leaf_size': 38, 'metric': 'minkowski', 'n_neighbors': 16, 'weights': 'uniform'}\n",
      "66859.86927295648 {'leaf_size': 39, 'metric': 'minkowski', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "63211.10640711504 {'leaf_size': 38, 'metric': 'euclidean', 'n_neighbors': 13, 'weights': 'distance'}\n",
      "65589.34326220563 {'leaf_size': 39, 'metric': 'minkowski', 'n_neighbors': 4, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "# rnd_search_best = RandomizedSearchCV(knn, param_distributions=param_distribs, n_jobs=2,\n",
    "#                                 n_iter=100, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "# rnd_search_best.fit(X_new, housing_labels)\n",
    "\n",
    "# print(rnd_search_best.best_estimator_)\n",
    "\n",
    "# cvresbest = rnd_search_best.cv_results_\n",
    "\n",
    "# for mean_score, params in zip(cvresbest[\"mean_test_score\"], cvresbest[\"params\"]):\n",
    "#     print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [63927.40081619 61891.6309268  63055.15873474 63548.29822687\n",
      " 63376.55499009]\n",
      "Mean: 63159.808738938256\n",
      "Standard deviation: 693.7329750367388\n"
     ]
    }
   ],
   "source": [
    "# bestknn = KNeighborsRegressor(algorithm='auto', leaf_size=33, metric='euclidean',\n",
    "#                     metric_params=None, n_jobs=None, n_neighbors=11, p=2,\n",
    "#                     weights='distance')\n",
    "\n",
    "# scores = cross_val_score(bestknn, X_new, housing_labels,\n",
    "#                          scoring=\"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "# knn_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "# def display_scores(scores):\n",
    "#     print(\"Scores:\", scores)\n",
    "#     print(\"Mean:\", scores.mean())\n",
    "#     print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "# display_scores(knn_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our final KNN model with the best params. Split up test set and try our best parameters on full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = strat_test_set.copy()\n",
    "x_test.drop('median_house_value', axis=1,inplace=True)\n",
    "y_test = strat_test_set[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4128, 9)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4128, 21)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = full_pipeline.transform(x_test)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a228316d8>"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAaV0lEQVR4nO3df5AX9Z3n8edrfjGoEH4IBhkUPFjPH5to/EZJmfKymiCyrrhbeouVO/FHFVU5s2Vuc5dg7q6smKTKVO0lWTeeu1TwxFxOwplkYbMgy6mpeLX+YIgmCi7FRDYygRXCoKIwzK/3/dGfr9MM35n5zjDMd4bv61HV1d2f/nR/P90D/er+dM93FBGYmVl1q6l0A8zMrPIcBmZm5jAwMzOHgZmZ4TAwMzOgrtINGK6zzz475s6dW+lmmJmNG9u2bftdRMwotWzchsHcuXNpbm6udDPMzMYNSb/pb5m7iczMzGFgZmYOAzMzw2FgZmY4DMzMDIeBmZnhMDAzM6otDHp64Ln/Dr/9RaVbYmY2plRXGBx7F7Y+Ck/eBe3vVro1ZmZjRnWFwcQpcMtqePtN+OkXwH/Yx8wMqLYwADhvIfzBffDaj+Dl71e6NWZmY0L1hQHAJ/8c5v0b2Pgl2P9PlW6NmVnFVWcY1NTCn6yChjPhyTuh82ilW2RmVlHVGQYAkz4Mf/I3sH8HPLWy0q0xM6uo6g0DgPmfhqvvhW2PwWs/rnRrzMwqprrDAODa/wazC/B390Lb7kq3xsysIhwGtfVwy6OAYN3t2WunZmZVxmEAMPX87PnBwV/DwwvhhUegp7vSrTIzGzUOg6ILb4D/8Dyc/4nsgfLqz8Bb2yvdKjOzUTFu/wbyKTH1fPjsk/Dqk/DUl+FvroGrvwDX/Geob6x068yskiKguwO62qHrWDZ0d6TpdujuhOjOehV6unLTfee7eofuzuzV9q526DwCne3QdTQb93Smet29dXu6oHEy/On/GvHdcxj0JcFHboV/dS38w3+B5/4CdvwtLPo6/N7ibLmZnXoR2Qny2HvQ8R4cO9z7O0ESoGysmmy6+xh0HMnqdh6Bjvezoas9O6EWT8bRnX1pZXRnJ/LOo+kEfDR3Yu4zXRxzCr/CpqYe6idCXWN28VnbADV1aahN4/qs7aeAw6A/Z06HP/5r+P1b4e+/CE8sg3MuhU/+R7jkj7Mfjlk1+uAkffj4ofModL7feyLteL/3RNrTlV1Fd3dmV7zdndl8Z/GK+Ojx63e8n53UYwRPfKrN/t/mx3UTshNv/RnpJHwGTJgEZ848/sRc19g7X9eYrVc3AWonQF1DVlZTD7V1afvFE3htbr441OSm69P2J2brVpBinH5ZW6FQiObm5tH5sO7O7LuMnvsW/G4nTLsg6z766LLsH4RZJUSkK9viyfRI7wm48/3sKrlY3tX3pHu0xLLiVfDRdAXdc/zQk66kOw4P7SRd25BOlMUhXfHWNmQn2Poz+owboeGsbJhQHE/KxvUTs7uBCCDShXpk7altyL5VoOHMbFvFcf1EX7wlkrZFRKHkMofBEPT0wM6/h5//Bex7BSadCx+/O/vyuw9/JOvLs9NfRPZ16EcP9Q7FK+BiX3K+H5nI1ome3mki139coh+52G9ccnw0neiPMPRuC+VOuhNzV79nHD9fU5d1vxSHmjSunZD9Oy+enCek6Qln5U7AuRN73cRsXRsTBgoDdxMNRU0NXPRH8K9vhF8/k90pPPO13uXTF8C5l8Gsy7Lx2RfCmWf7OUMl9fSceOI+egja3+k9YX8wFPuPj+VOvu25PuQjaf23s/7mk6I+XQe5roTa+lz3RLpSbvxQdhfa92Rbf0YaGqH+TGgolufqNeROzHUT/O/RSiorDCRNAb4HXEp2KXIXsBP4ITAX+Gfg30bEIUkC/hJYAhwB7oiIX6TtLAf+a9rs1yNiTSq/AngMmAhsBO6NsXzLIsH867LhvQPZXcLel2HvK/Cbf4RX/09v3YZJMG0uTJ2XdS9NmwdnTM9u548dTg/G3ut96DVxanbHMTkNk2bBWedUvD/xpHR1pH7ld3v7l7uPpa6HfFdEd3bVrJpcX2vx6rQ262vubD/xoV7H+9D+dnaiPtLW56T/dnldGrUTevuCiyfhugm9V8qNU7KT6sSppYdin3PdhOPHtfVkDzpr0sNOn4htbCqrm0jSGuC5iPiepAbgDOArQFtEPChpJTA1Ir4saQnwZ2RhcBXwlxFxlaRpQDNQIAuUbcAVKUBeAu4FXiALg4ciYtNAbapIN1G53tsP+34JB1uyr7hoewMO7YZDv8lOaCdQdqtd15idwPrWUU0WKsW+0WKXQ/Ek1zg5C5iJ0+CM4jA9O6EVH9Z98Gpams+/MVG86u08mi3/4DOK/bJpXLxqrW3IxjVpmtR33d2ZneS7O7IA6D6WBV33sVN6uAGY8KHsjxf1d7LuOzRO7j3R105wV4ZVhZPqJpI0GbgGuAMgIjqADklLgU+lamuAnwFfBpYCj6cr+xckTZE0K9XdEhFtabtbgMWSfgZMjojnU/njwM3AgGEwpp01ExZ8JhvyerrhndbsajX/gKz+jN4rxp4eOHIQDu+Fd/f1jo+9ywlXmKrJTtTt78DRNjhyKAue1q3ZFXJPZ7bOByfuut6Hece9QTExu/uoT29EfNBXrN7PhN43QvJvg3R3ZvUazsxOqsWwqGvI5ov9yR/0LecfBNaUGNT7sDLi+NcB829e9G2/HxCanZRy+h4uAA4A/1PSR8mu6O8FzomIfQARsU/SzFR/NrAnt35rKhuovLVE+QkkrQBWAJx33nllNH2MqanNfrGN8weoUwNnzciGWR8d/mcV7x58kjSzMpRzb1wHfAx4JCIuB94HBvoDAKU6RWMY5ScWRqyKiEJEFGbMmDFwq6ud5CAws7KVEwatQGtEvJjmnyQLh7dS9w9pvD9Xf05u/SZg7yDlTSXKzcxslAwaBhHxL8AeSRemouuAHcAGYHkqWw6sT9MbgNuVWQi8k7qTNgOLJE2VNBVYBGxOyw5LWpjeRLo9ty0zMxsF5b6v+GfAD9KbRG8Ad5IFyTpJdwNvAremuhvJ3iRqIXu19E6AiGiT9DVga6r3QPFhMvA5el8t3cR4fnhsZjYO+TeQzcyqxECvlvrlajMzcxiYmZnDwMzMcBiYmRkOAzMzw2FgZmY4DMzMDIeBmZnhMDAzMxwGZmaGw8DMzHAYmJkZDgMzM8NhYGZmOAzMzAyHgZmZ4TAwMzMcBmZmhsPAzMxwGJiZGWWGgaR/lvSqpFckNaeyaZK2SNqVxlNTuSQ9JKlF0q8kfSy3neWp/i5Jy3PlV6Ttt6R1NdI7amZm/RvKncEfRMRlEVFI8yuBpyNiAfB0mge4AViQhhXAI5CFB3A/cBVwJXB/MUBSnRW59RYPe4/MzGzITqabaCmwJk2vAW7OlT8emReAKZJmAdcDWyKiLSIOAVuAxWnZ5Ih4PiICeDy3LTMzGwXlhkEA/yBpm6QVqeyciNgHkMYzU/lsYE9u3dZUNlB5a4nyE0haIalZUvOBAwfKbLqZmQ2mrsx6V0fEXkkzgS2S/mmAuqX6+2MY5ScWRqwCVgEUCoWSdczMbOjKujOIiL1pvB/4CVmf/1upi4c03p+qtwJzcqs3AXsHKW8qUW5mZqNk0DCQdKakScVpYBHwGrABKL4RtBxYn6Y3ALent4oWAu+kbqTNwCJJU9OD40XA5rTssKSF6S2i23PbMjOzUVBON9E5wE/S2551wP+OiKckbQXWSbobeBO4NdXfCCwBWoAjwJ0AEdEm6WvA1lTvgYhoS9OfAx4DJgKb0mBmZqNE2Qs840+hUIjm5uZKN8PMbNyQtC336wHH8W8gm5mZw8DMzBwGZmaGw8DMzHAYmJkZDgMzM8NhYGZmOAzMzAyHgZmZ4TAwMzMcBmZmhsPAzMxwGJiZGQ4DMzPDYWBmZjgMzMwMh4GZmeEwMDMzHAZmZobDwMzMcBiYmRlDCANJtZJelvTTND9P0ouSdkn6oaSGVD4hzbek5XNz27gvle+UdH2ufHEqa5G0cuR2z8zMyjGUO4N7gddz898Evh0RC4BDwN2p/G7gUETMB76d6iHpYmAZcAmwGPgfKWBqgYeBG4CLgdtSXTMzGyVlhYGkJuAPge+leQHXAk+mKmuAm9P00jRPWn5dqr8UWBsRxyJiN9ACXJmGloh4IyI6gLWprpmZjZJy7wy+A3wJ6Enz04G3I6IrzbcCs9P0bGAPQFr+Tqr/QXmfdforP4GkFZKaJTUfOHCgzKabmdlgBg0DSTcC+yNiW764RNUYZNlQy08sjFgVEYWIKMyYMWOAVpuZ2VDUlVHnauAmSUuARmAy2Z3CFEl16eq/Cdib6rcCc4BWSXXAh4C2XHlRfp3+ys3MbBQMemcQEfdFRFNEzCV7APxMRHwWeBa4JVVbDqxP0xvSPGn5MxERqXxZettoHrAAeAnYCixIbyc1pM/YMCJ7Z2ZmZSnnzqA/XwbWSvo68DKwOpWvBr4vqYXsjmAZQERsl7QO2AF0AfdERDeApM8Dm4Fa4NGI2H4S7TIzO2U6OztpbW2lvb290k3pV2NjI01NTdTX15e9jrKL9vGnUChEc3NzpZthZlVm9+7dTJo0ienTp5O9KDm2RAQHDx7k8OHDzJs377hlkrZFRKHUev4NZDOzIWhvbx+zQQAgienTpw/5zsVhYGY2RGM1CIqG0z6HgZnZOPTUU09x4YUXMn/+fB588MGT3p7DwMxsnOnu7uaee+5h06ZN7NixgyeeeIIdO3ac1DYdBmZm48xLL73E/PnzueCCC2hoaGDZsmWsX79+8BUHcDKvlpqZVbWv/t12dux9d0S3efG5k7n/jy4ZsM5vf/tb5szp/V3dpqYmXnzxxZP6XN8ZmJmNM6V+JeBkH2r7zsDMbJgGu4I/VZqamtizp/f7PVtbWzn33HNPapu+MzAzG2c+/vGPs2vXLnbv3k1HRwdr167lpptuOqlt+s7AzGycqaur47vf/S7XX3893d3d3HXXXVxyycndpTgMzMzGoSVLlrBkyZIR2567iczMzGFgZmYOAzMzw2FgZmY4DMzMDIeBmZnhMDAzG3fuuusuZs6cyaWXXjpi23QYmJmNM3fccQdPPfXUiG7TYWBmNs5cc801TJs2bUS36d9ANjMbrk0r4V9eHdltfvj34YaT/8tlQzXonYGkRkkvSfqlpO2SvprK50l6UdIuST+U1JDKJ6T5lrR8bm5b96XynZKuz5UvTmUtklaO/G6amdlAyrkzOAZcGxHvSaoH/p+kTcCfA9+OiLWS/hq4G3gkjQ9FxHxJy4BvAn8q6WJgGXAJcC7wfyX9XvqMh4HPAK3AVkkbIuLk/oabmdmpVoEr+FNl0DuDyLyXZuvTEMC1wJOpfA1wc5pemuZJy69T9lcXlgJrI+JYROwGWoAr09ASEW9ERAewNtU1M7NRUtYDZEm1kl4B9gNbgF8Db0dEV6rSCsxO07OBPQBp+TvA9Hx5n3X6Ky/VjhWSmiU1HzhwoJymm5mddm677TY+8YlPsHPnTpqamli9evVJb7OsB8gR0Q1cJmkK8BPgolLV0rjU316LAcpLBdKJf9Mta8cqYBVAoVAoWcfM7HT3xBNPjPg2h/RqaUS8DfwMWAhMkVQMkyZgb5puBeYApOUfAtry5X3W6a/czMxGSTlvE81IdwRImgh8GngdeBa4JVVbDqxP0xvSPGn5M5H99eYNwLL0ttE8YAHwErAVWJDeTmoge8i8YSR2zszMylNON9EsYI2kWrLwWBcRP5W0A1gr6evAy0Cx02o18H1JLWR3BMsAImK7pHXADqALuCd1PyHp88BmoBZ4NCK2j9gempnZoAYNg4j4FXB5ifI3yN4E6lveDtzaz7a+AXyjRPlGYGMZ7TUzq7iIIHtJcmzKOmOGxl9HYWY2BI2NjRw8eHBYJ9zREBEcPHiQxsbGIa3nr6MwMxuCpqYmWltbGcuvtzc2NtLU1DSkdRwGZmZDUF9fz7x58yrdjBHnbiIzM3MYmJmZw8DMzHAYmJkZDgMzM8NhYGZmOAzMzAyHgZmZ4TAwMzMcBmZmhsPAzMxwGJiZGQ4DMzPDYWBmZjgMzMwMh4GZmeEwMDMzyggDSXMkPSvpdUnbJd2byqdJ2iJpVxpPTeWS9JCkFkm/kvSx3LaWp/q7JC3PlV8h6dW0zkMay39p2szsNFTOnUEX8MWIuAhYCNwj6WJgJfB0RCwAnk7zADcAC9KwAngEsvAA7geuAq4E7i8GSKqzIrfe4pPfNTMzK9egYRAR+yLiF2n6MPA6MBtYCqxJ1dYAN6fppcDjkXkBmCJpFnA9sCUi2iLiELAFWJyWTY6I5yMigMdz2zIzs1EwpGcGkuYClwMvAudExD7IAgOYmarNBvbkVmtNZQOVt5YoNzOzUVJ2GEg6C/gR8IWIeHegqiXKYhjlpdqwQlKzpOYDBw4M1mQzMytTWWEgqZ4sCH4QET9OxW+lLh7SeH8qbwXm5FZvAvYOUt5UovwEEbEqIgoRUZgxY0Y5TTczszKU8zaRgNXA6xHxrdyiDUDxjaDlwPpc+e3praKFwDupG2kzsEjS1PTgeBGwOS07LGlh+qzbc9syM7NRUFdGnauBfw+8KumVVPYV4EFgnaS7gTeBW9OyjcASoAU4AtwJEBFtkr4GbE31HoiItjT9OeAxYCKwKQ1mZjZKlL3AM/4UCoVobm6udDPMzMYNSdsiolBqmX8D2czMHAZmZuYwMDMzHAZmZobDwMzMcBiYmRkOAzMzw2FgZmY4DMzMDIeBmZnhMDAzMxwGZmaGw8DMzHAYmJkZDgMzM8NhYGZmOAzMzAyHgZmZ4TAwMzMcBmZmhsPAzMwoIwwkPSppv6TXcmXTJG2RtCuNp6ZySXpIUoukX0n6WG6d5an+LknLc+VXSHo1rfOQJI30TpqZ2cDKuTN4DFjcp2wl8HRELACeTvMANwAL0rACeASy8ADuB64CrgTuLwZIqrMit17fzzIzs1Ns0DCIiJ8DbX2KlwJr0vQa4OZc+eOReQGYImkWcD2wJSLaIuIQsAVYnJZNjojnIyKAx3PbMjOzUTLcZwbnRMQ+gDSemcpnA3ty9VpT2UDlrSXKS5K0QlKzpOYDBw4Ms+lmZtbXSD9ALtXfH8MoLykiVkVEISIKM2bMGGYTzcysr+GGwVupi4c03p/KW4E5uXpNwN5ByptKlJuZ2SgabhhsAIpvBC0H1ufKb09vFS0E3kndSJuBRZKmpgfHi4DNadlhSQvTW0S357ZlZmajpG6wCpKeAD4FnC2pleytoAeBdZLuBt4Ebk3VNwJLgBbgCHAnQES0SfoasDXVeyAiig+lP0f2xtJEYFMazMxsFCl7iWf8KRQK0dzcXOlmmJmNG5K2RUSh1DL/BrKZmTkMzMzMYWBmZjgMzMwMh4GZmeEwMDMzHAZmZobDwMzMcBiYmRkOAzMzw2FgZmY4DMzMDIeBmZnhMDAzMxwGZmaGw8DMzHAYmJkZDgMzM8NhYGZmOAzMzAyHgZmZMYbCQNJiSTsltUhaWen2mJlVkzERBpJqgYeBG4CLgdskXVzZVpmZVY+6SjcguRJoiYg3ACStBZYCO0b6g278q+do7+wpuSwiSpcP54MGWKm/Rf19/jA/hv42FwOsNdQmDKPJY2I/h7qtgdownGMw0B71vz/D+JQBGjec/Rnqz27A2mN4P/vf1uj83AZa6eyzGvjH+64bzlYHNFbCYDawJzffClzVt5KkFcAKgPPOO29YHzR/xll0dg9wpDWk4gFJ/a/V35IBVhnytgZqw4AfM8Q2aIAV+tuf4R3PobdhWMdzGAdn5H9u/a0z9A8a+Lj1t85wfkLD+fwKH89hfNBw/u+M5M/tzIbaIW+rHGMlDErt9gln7IhYBawCKBQKwwrc7yy7fDirmZmd1sbEMwOyO4E5ufkmYG+F2mJmVnXGShhsBRZImiepAVgGbKhwm8zMqsaY6CaKiC5Jnwc2A7XAoxGxvcLNMjOrGmMiDAAiYiOwsdLtMDOrRmOlm8jMzCrIYWBmZg4DMzNzGJiZGaDhfDXAWCDpAPCbYa5+NvC7EWzOeFTtx6Da9x98DKD6jsH5ETGj1IJxGwYnQ1JzRBQq3Y5KqvZjUO37Dz4G4GOQ524iMzNzGJiZWfWGwapKN2AMqPZjUO37Dz4G4GPwgap8ZmBmZser1jsDMzPLcRiYmVl1hYGkxZJ2SmqRtLLS7RkNkh6VtF/Sa7myaZK2SNqVxlMr2cZTTdIcSc9Kel3Sdkn3pvKqOQ6SGiW9JOmX6Rh8NZXPk/RiOgY/TF8hf9qSVCvpZUk/TfNVtf8DqZowkFQLPAzcAFwM3Cbp4sq2alQ8BizuU7YSeDoiFgBPp/nTWRfwxYi4CFgI3JN+9tV0HI4B10bER4HLgMWSFgLfBL6djsEh4O4KtnE03Au8npuvtv3vV9WEAXAl0BIRb0REB7AWWFrhNp1yEfFzoK1P8VJgTZpeA9w8qo0aZRGxLyJ+kaYPk50MZlNFxyEy76XZ+jQEcC3wZCo/rY+BpCbgD4HvpXlRRfs/mGoKg9nAntx8ayqrRudExD7ITpTAzAq3Z9RImgtcDrxIlR2H1EXyCrAf2AL8Gng7IrpSldP9/8R3gC8BPWl+OtW1/wOqpjBQiTK/V1tFJJ0F/Aj4QkS8W+n2jLaI6I6Iy8j+xviVwEWlqo1uq0aHpBuB/RGxLV9couppuf/lGDN/6WwUtAJzcvNNwN4KtaXS3pI0KyL2SZpFdqV4WpNUTxYEP4iIH6fiqjsOABHxtqSfkT0/mSKpLl0dn87/J64GbpK0BGgEJpPdKVTL/g+qmu4MtgIL0tsDDcAyYEOF21QpG4DlaXo5sL6CbTnlUt/wauD1iPhWblHVHAdJMyRNSdMTgU+TPTt5FrglVTttj0FE3BcRTRExl+z//jMR8VmqZP/LUVW/gZyuCr4D1AKPRsQ3KtykU07SE8CnyL6q9y3gfuBvgXXAecCbwK0R0fch82lD0ieB54BX6e0v/grZc4OqOA6SPkL2gLSW7CJwXUQ8IOkCspcppgEvA/8uIo5VrqWnnqRPAf8pIm6sxv3vT1WFgZmZlVZN3URmZtYPh4GZmTkMzMzMYWBmZjgMzMwMh4GZmeEwMDMz4P8DfCYnbeNgSyoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for kicks, let's just visualize this.\n",
    "rmse_list = []\n",
    "for k in range(2,50):\n",
    "    knn_looped = KNeighborsRegressor(algorithm='auto', metric='euclidean', n_neighbors=k, p=2,\n",
    "                    weights='distance')\n",
    "    knn_looped.fit(housing_prepared, housing_labels)\n",
    "    y_pred = knn_looped.predict(x_test)\n",
    "    rmse_list.append((k,np.sqrt(mean_squared_error(y_test, y_pred))))\n",
    "\n",
    "score_df = pd.DataFrame(rmse_list)\n",
    "score_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the best model to test X and predicting Y on FULL dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=33, metric='euclidean',\n",
       "                    metric_params=None, n_jobs=None, n_neighbors=11, p=2,\n",
       "                    weights='distance')"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kbbbest_random.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60133.81312286888"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = kbbbest_random.predict(x_test)\n",
    "predict_score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "predict_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try the dataset with fewer featues an see if we get a better rmse score on the trimmed set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrim_test = pd.DataFrame(x_test,columns=attributes)\n",
    "xtrim_test.drop(columns = ['NEAR BAY', 'ISLAND'], axis=1,inplace=True)\n",
    "\n",
    "xtrim_test = xtrim_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60119.812452597354"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kbbbest_random.fit(housing_trim, housing_labels)\n",
    "y_pred = kbbbest_random.predict(xtrim_test)\n",
    "predict_score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "predict_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I guess that's a little better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   34.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   57.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1557 out of 1557 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 1557 out of 1557 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49329.55077139079"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's also just try our best RandomForest model on the test set.\n",
    "\n",
    "rf_best.fit(housing_trim, housing_labels)\n",
    "y_pred = rf_best.predict(xtrim_test)\n",
    "rfbest_score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "rfbest_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's much better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "For what values of n_neighbors and weight does KNeighborsRegressor perform the best? Does it perform as well on the housing data as the linear regressor from the lectures? Why do you think this is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>According to GridSearch and RandomSearch, k = 11 is the best parameter for the lowest rmse score. It does not seem to matter whether we use Euclidean distnace or not (which I was surprised by).\n",
    "\n",
    "I also chose to log-transform some of the numerical data to bring it to normal distribution. This seems to have helped the training data score improve a little (49521.13 from 48988.30). \n",
    "\n",
    "Sicne Feature_Importances doesn't apply to KNNRegressor, I first used correlation instead to see if I could remove redundant features. CHecking the correlation matrix, I ran significance testing on the lowest-correlating variables in the trianing set and realized they were all significant at p-value less than 0.05. I went ahead and tested removing a couple of them anyway (for science!), and realized the model got worse in training. I've hidden a lot of this meandering in the notebook.\n",
    "\n",
    "However, I tried out a RandomForestRegressor to gain access to Feature_importances method, and was able to improve the model by then removing a couple of low-ranking features. The KNN model then returned a small improvement in the final test set, but perhaps going back and removing more features could help. Interstingly, this model performed worse in training when given fewer features, but better in testing.\n",
    "\n",
    "I think this model doesn't perform much better than the models in the sample notebook. I'm not sure if it's because KNNRegressor is limited in how well it can do this task, or if I haven't feature-engineered enough! RandomForest, however, turned out a much better result.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read appending B\n",
    "\n",
    "- Reflect on your last data project, read appendix B. Then, write down a few of the checklist items that your last data project could have used. If you have not yet done a data project, then write down a few of the items that you found most interesting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I find ensemble models interesting, as well as using things like Voting to find the best result. I have not used this in a real-life scenario yet. I think it'd be a really interesting skill to be able to manipulate multiple models to produce the best outcome. \n",
    "Deployement is anotehr area I'm unfamiliar with. Would be extremely useful to learn how to monitor the health of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit your notebook\n",
    "\n",
    "Submit your solution to Quercus\n",
    "Make sure you rename your notebook to    \n",
    "W2_UTORid.ipynb    \n",
    "Example W2_adfasd01.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
