{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox for RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/htahir/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/htahir/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/ipykernel_launcher.py:42: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.*` instead of `tqdm._tqdm_notebook.*`\n"
     ]
    }
   ],
   "source": [
    "# imports here\n",
    "\n",
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "    IS_COLAB = True\n",
    "except Exception:\n",
    "    IS_COLAB = False\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "%load_ext tensorboard\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
    "if IS_COLAB:\n",
    "    print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple RNN on a Generated Time Series for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series(batch_size, n_steps):\n",
    "    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
    "    time = np.linspace(0, 1, n_steps)\n",
    "    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10))  #   wave 1\n",
    "    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20)) # + wave 2\n",
    "    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5)   # + noise\n",
    "    return series[..., np.newaxis].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_steps = 50\n",
    "series = generate_time_series(10000, n_steps + 1)\n",
    "X_train, y_train = series[:7000, :n_steps], series[:7000, -1]\n",
    "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
    "X_test, y_test = series[9000:, :n_steps], series[9000:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 50, 1), (2000, 50, 1))"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape, X_valid.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_series(series, y=None, y_pred=None, x_label=\"$t$\", y_label=\"$x(t)$\"):\n",
    "    plt.plot(series, \".-\")\n",
    "    if y is not None:\n",
    "        plt.plot(n_steps, y, \"bx\", markersize=10)\n",
    "    if y_pred is not None:\n",
    "        plt.plot(n_steps, y_pred, \"ro\")\n",
    "    plt.grid(True)\n",
    "    if x_label:\n",
    "        plt.xlabel(x_label, fontsize=16)\n",
    "    if y_label:\n",
    "        plt.ylabel(y_label, fontsize=16, rotation=0)\n",
    "    plt.hlines(0, 0, 100, linewidth=1)\n",
    "    plt.axis([0, n_steps + 1, -1, 1])\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, sharey=True, figsize=(12, 4))\n",
    "for col in range(3):\n",
    "    plt.sca(axes[col])\n",
    "    plot_series(X_valid[col, :, 0], y_valid[col, 0],\n",
    "                y_label=(\"$x(t)$\" if col==0 else None))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(loss, val_loss):\n",
    "    plt.plot(np.arange(len(loss)) + 0.5, loss, \"b.-\", label=\"Training loss\")\n",
    "    plt.plot(np.arange(len(val_loss)) + 1, val_loss, \"r.-\", label=\"Validation loss\")\n",
    "    plt.gca().xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
    "    plt.axis([1, 20, 0, 0.05])\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2529655 , -0.24267727, -0.08966523,  0.03061226,  0.2830733 ,\n",
       "        0.5034291 ,  0.68315464,  0.71714944,  0.66348517,  0.48309696,\n",
       "        0.30284724,  0.2052048 ,  0.08450623,  0.06641599,  0.1681185 ,\n",
       "        0.07499525,  0.0133126 , -0.13783354, -0.32550123, -0.5050951 ,\n",
       "       -0.67722857, -0.6717539 , -0.6011696 , -0.41138572, -0.30830762,\n",
       "       -0.11499406, -0.06724501, -0.05520922,  0.01836902,  0.00735723,\n",
       "        0.02836169,  0.15125608,  0.42631206,  0.6072168 ,  0.64625293,\n",
       "        0.7213324 ,  0.627726  ,  0.41340816,  0.19029261,  0.06508268,\n",
       "       -0.0734548 , -0.13179466, -0.05701557, -0.03560268, -0.08019745,\n",
       "       -0.22776155, -0.41371432, -0.62975067, -0.7007588 , -0.6759614 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid[1, :,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "#     tf.keras.callbacks.EarlyStopping(monitor='val_last_time_step_mse', patience=3, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_last_time_step_mse', factor=0.5, patience=2, min_lr=0.00001)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020211367"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = X_valid[:, -1]\n",
    "np.mean(keras.losses.mean_squared_error(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 50, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (SimpleRNN)            (None, None, 20)          440       \n",
      "_________________________________________________________________\n",
      "simple_rnn_32 (SimpleRNN)    (None, None, 32)          1696      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, None, 1)           33        \n",
      "=================================================================\n",
      "Total params: 2,169\n",
      "Trainable params: 2,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build simple RNN model\n",
    "\n",
    "ffwd_model = keras.models.Sequential([\n",
    "#     keras.layers.Flatten(input_shape=[50,1], name='input'),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1], name='input'),\n",
    "#     keras.layers.Dense(32, activation='relu', name='hidden_1'),\n",
    "#     keras.layers.Dense(32, activation='relu', name='hidden_2'),\n",
    "    keras.layers.SimpleRNN(32, return_sequences=True),\n",
    "    keras.layers.Dense(1, name='output')\n",
    "])\n",
    "ffwd_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.1548 - val_loss: 0.1505\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 7s 966us/sample - loss: 0.1418 - val_loss: 0.1390\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 7s 966us/sample - loss: 0.1273 - val_loss: 0.1192\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 7s 986us/sample - loss: 0.1070 - val_loss: 0.1004\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 7s 963us/sample - loss: 0.0960 - val_loss: 0.0943\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 7s 977us/sample - loss: 0.0897 - val_loss: 0.0888\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 6s 924us/sample - loss: 0.0874 - val_loss: 0.0861\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 7s 973us/sample - loss: 0.0845 - val_loss: 0.0852\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 7s 973us/sample - loss: 0.0822 - val_loss: 0.0829\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 7s 953us/sample - loss: 0.0812 - val_loss: 0.0811\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 7s 930us/sample - loss: 0.0806 - val_loss: 0.0815\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 7s 936us/sample - loss: 0.0796 - val_loss: 0.0816\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 7s 965us/sample - loss: 0.0785 - val_loss: 0.0780\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 7s 952us/sample - loss: 0.0774 - val_loss: 0.0773\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 7s 936us/sample - loss: 0.0764 - val_loss: 0.0773\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 6s 927us/sample - loss: 0.0768 - val_loss: 0.0805\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 7s 942us/sample - loss: 0.0763 - val_loss: 0.0770\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 7s 930us/sample - loss: 0.0749 - val_loss: 0.0770\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 7s 931us/sample - loss: 0.0747 - val_loss: 0.0757\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 6s 928us/sample - loss: 0.0744 - val_loss: 0.0746\n"
     ]
    }
   ],
   "source": [
    "ffwd_model.compile(loss='mse', optimizer='adam')\n",
    "history = ffwd_model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss: 0.0025 - val_loss: 0.0030 with 2 layers\n",
    "# loss: 0.0026 - val_loss: 0.0034 with 7 layers\n",
    "# loss: 0.0744 - val_loss: 0.0746 with RNN 2 layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying an LSTM on same regression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_time_step_mse(Y_true, Y_pred):\n",
    "    return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, None, 32)          4352      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 32)          8320      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, None, 32)          8320      \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, None, 1)           33        \n",
      "=================================================================\n",
      "Total params: 21,025\n",
      "Trainable params: 21,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(32, return_sequences=True, input_shape=[None,1]),\n",
    "    keras.layers.LSTM(32, return_sequences=True),\n",
    "    keras.layers.LSTM(32, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(1))\n",
    "])\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 23s 3ms/sample - loss: 0.1439 - last_time_step_mse: 0.1417 - val_loss: 0.1487 - val_last_time_step_mse: 0.1435\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 16s 2ms/sample - loss: 0.1437 - last_time_step_mse: 0.1403 - val_loss: 0.1480 - val_last_time_step_mse: 0.1413\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 16s 2ms/sample - loss: 0.1422 - last_time_step_mse: 0.1373 - val_loss: 0.1499 - val_last_time_step_mse: 0.1429\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.1422 - last_time_step_mse: 0.1396 - val_loss: 0.1463 - val_last_time_step_mse: 0.1372\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.1392 - last_time_step_mse: 0.1334 - val_loss: 0.1442 - val_last_time_step_mse: 0.1425\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.1193 - last_time_step_mse: 0.0998 - val_loss: 0.1033 - val_last_time_step_mse: 0.0713\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0903 - last_time_step_mse: 0.0477 - val_loss: 0.0884 - val_last_time_step_mse: 0.0451\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0804 - last_time_step_mse: 0.0362 - val_loss: 0.0791 - val_last_time_step_mse: 0.0267\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0756 - last_time_step_mse: 0.0315 - val_loss: 0.0742 - val_last_time_step_mse: 0.0260\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0729 - last_time_step_mse: 0.0286 - val_loss: 0.0734 - val_last_time_step_mse: 0.0307\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0719 - last_time_step_mse: 0.0277 - val_loss: 0.0742 - val_last_time_step_mse: 0.0283\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0688 - last_time_step_mse: 0.0238 - val_loss: 0.0733 - val_last_time_step_mse: 0.0211\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0685 - last_time_step_mse: 0.0232 - val_loss: 0.0717 - val_last_time_step_mse: 0.0218\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0677 - last_time_step_mse: 0.0224 - val_loss: 0.0715 - val_last_time_step_mse: 0.0201\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0676 - last_time_step_mse: 0.0226 - val_loss: 0.0698 - val_last_time_step_mse: 0.0205\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0673 - last_time_step_mse: 0.0226 - val_loss: 0.0689 - val_last_time_step_mse: 0.0220\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0659 - last_time_step_mse: 0.0207 - val_loss: 0.0687 - val_last_time_step_mse: 0.0192\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0658 - last_time_step_mse: 0.0205 - val_loss: 0.0678 - val_last_time_step_mse: 0.0198\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0656 - last_time_step_mse: 0.0204 - val_loss: 0.0678 - val_last_time_step_mse: 0.0205\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0650 - last_time_step_mse: 0.0195 - val_loss: 0.0674 - val_last_time_step_mse: 0.0191\n"
     ]
    }
   ],
   "source": [
    "lstm_model.compile(loss='mse', optimizer='adam',  metrics=[last_time_step_mse])\n",
    "history = lstm_model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=20, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last run loss: 0.1432 - last_time_step_mse: 0.1398 - val_loss: 0.1492\n",
    "# without earlystopping: loss: 0.0650 - last_time_step_mse: 0.0195 - val_loss: 0.0674 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# history.history.keys()\n",
    "plot_learning_curves(history.history[\"last_time_step_mse\"], history.history[\"val_last_time_step_mse\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try binary classification dataset with LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a (terrible) binary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 96  47]\n",
      "  [127  57]\n",
      "  [133  29]\n",
      "  [218 100]]\n",
      "\n",
      " [[135 316]\n",
      "  [126  66]\n",
      "  [154  22]\n",
      "  [185  22]]]\n",
      "[[[0]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]]\n",
      "\n",
      " [[1]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]]]\n"
     ]
    }
   ],
   "source": [
    "freq1, freq2, offsets1, offsets2 = np.random.randint(15, size=(4, 2, 4, 2))\n",
    "series = (freq2 * (offsets1 + 10)) + (freq1 + offsets2)\n",
    "targets = np.where(np.sum(series, axis=2)//4<100,0,1)\n",
    "targets =targets[...,np.newaxis]\n",
    "print(series)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a binary dataset with a 0/1 target class. Importantly, we will give this dataset multiple features per time step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to also log our models to Tensorboard this time. Use function below to create directories for our model logs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log to Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./some_name/run_2020_05_01-21_18_16'"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_run_logdir(folder_name):\n",
    "    root_logdir = os.path.join(os.curdir, folder_name)\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "def prep_run():\n",
    "    keras.backend.clear_session()\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "run_name = get_run_logdir('some_name')\n",
    "run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a binary dataset\n",
    "\n",
    "def generate_binary_sequences(batch_size, n_steps, n_features):\n",
    "    freq1, freq2, offsets1, offsets2 = np.random.randint(15, size=(4, batch_size, n_steps, n_features))\n",
    "    series = (freq2 * (offsets1 + 10)) + (freq1 + offsets2)\n",
    "    targets = np.where(np.sum(series, axis=2)//4<700,0,1)\n",
    "    targets =targets[...,np.newaxis]\n",
    "    return series.astype(int), targets.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 100, 1)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = 1000\n",
    "n_steps = 100\n",
    "features = 20\n",
    "train_count = 700\n",
    "val_idx = 900 # starting val set from what index\n",
    "\n",
    "dataset, targets = generate_binary_sequences(samples, n_steps, features)\n",
    "# targets = generate_binary_target(samples, n_steps)\n",
    "\n",
    "x_train, y_train = dataset[:train_count], targets[:train_count]\n",
    "x_val, y_val = dataset[train_count:val_idx], targets[train_count:val_idx]\n",
    "x_test, y_test = dataset[val_idx:], targets[val_idx:]\n",
    "\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 100, 20)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some bias in our dataset - so we're going to adjust our output layer with the bias_initializer attribute. It may not help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos %: [34.7] neg %: [65.3]\n"
     ]
    }
   ],
   "source": [
    "# find the bias in dataset classes:\n",
    "neg, pos = np.bincount(targets[:,:,0].flatten())\n",
    "total = targets[:,:,0].flatten().shape\n",
    "# output counts of classes.\n",
    "print('pos %: {} neg %: {}'.format(pos/total*100,neg/total*100))\n",
    "initial_bias = np.log([pos/neg])\n",
    "initial_bias = tf.keras.initializers.Constant(initial_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try our fake dataset on binary LSTM model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit our model. We're using LSTM with a dropout layer. And because the input contains multiple features per timestep, we're going to use the TimeDistributed layer wrapped around the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"binary_lstm_test\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, None, 20)          3280      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 20)          3280      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, None, 20)          3280      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 20)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, None, 1)           21        \n",
      "=================================================================\n",
      "Total params: 9,861\n",
      "Trainable params: 9,861\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "binary_model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(20,return_sequences=True, input_shape=(None,features)),\n",
    "    keras.layers.LSTM(20, return_sequences=True),\n",
    "    keras.layers.LSTM(20, return_sequences=True),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(1, activation='sigmoid', bias_initializer=initial_bias))\n",
    "])\n",
    "binary_model._name='binary_lstm_test'\n",
    "binary_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./test_lstm_logs/run_2020_04_22-15_45_03\n",
      "Train on 700 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "700/700 [==============================] - 10s 14ms/sample - loss: 0.6470 - binary_crossentropy: 0.6470 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.6531 - val_loss: 0.6419 - val_binary_crossentropy: 0.6419 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6588\n",
      "Epoch 2/10\n",
      "700/700 [==============================] - 3s 5ms/sample - loss: 0.6459 - binary_crossentropy: 0.6459 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.6531 - val_loss: 0.6420 - val_binary_crossentropy: 0.6420 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6588\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - 3s 5ms/sample - loss: 0.6455 - binary_crossentropy: 0.6455 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.6531 - val_loss: 0.6417 - val_binary_crossentropy: 0.6417 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6588\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - 3s 5ms/sample - loss: 0.6452 - binary_crossentropy: 0.6452 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.6531 - val_loss: 0.6416 - val_binary_crossentropy: 0.6416 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6588\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - 3s 5ms/sample - loss: 0.6453 - binary_crossentropy: 0.6453 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.6531 - val_loss: 0.6415 - val_binary_crossentropy: 0.6415 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6588\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - 3s 5ms/sample - loss: 0.6450 - binary_crossentropy: 0.6450 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.6531 - val_loss: 0.6413 - val_binary_crossentropy: 0.6413 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6588\n",
      "Epoch 7/10\n",
      "700/700 [==============================] - 3s 4ms/sample - loss: 0.6449 - binary_crossentropy: 0.6449 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.6531 - val_loss: 0.6412 - val_binary_crossentropy: 0.6412 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6588\n",
      "Epoch 8/10\n",
      "700/700 [==============================] - 3s 4ms/sample - loss: 0.6445 - binary_crossentropy: 0.6445 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.6531 - val_loss: 0.6410 - val_binary_crossentropy: 0.6410 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6588\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - 3s 4ms/sample - loss: 0.6443 - binary_crossentropy: 0.6443 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.6531 - val_loss: 0.6407 - val_binary_crossentropy: 0.6407 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6588\n",
      "Epoch 10/10\n",
      "700/700 [==============================] - 3s 4ms/sample - loss: 0.6438 - binary_crossentropy: 0.6438 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.6531 - val_loss: 0.6405 - val_binary_crossentropy: 0.6405 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6588\n"
     ]
    }
   ],
   "source": [
    "prep_run()\n",
    "run_logdir = get_run_logdir(\"test_lstm_logs\")\n",
    "print(run_logdir)\n",
    "\n",
    "# can't use class weights for 3D array :(\n",
    "# class_weight = {0: 1.,\n",
    "#                 1: 50.}\n",
    "tb = TensorBoard(run_logdir)\n",
    "lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='binary_crossentropy',\n",
    "                                          patience=3, \n",
    "                                          verbose=1,\n",
    "                                          factor=0.5, \n",
    "                                          min_lr=0.00001)\n",
    "binary_model.compile(loss='binary_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['binary_crossentropy', 'Precision','Recall', 'accuracy'])\n",
    "\n",
    "history = binary_model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=32, epochs=10, callbacks=[tb, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 1ms/sample - loss: 0.6397 - binary_crossentropy: 0.6397 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.6588\n"
     ]
    }
   ],
   "source": [
    "scores = binary_model.evaluate(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_crossentropy 0.6396739101409912, Precision 0.6396739482879639, Recall 0.0, Accuracy 0.0\n"
     ]
    }
   ],
   "source": [
    "print('binary_crossentropy {}, Precision {}, Recall {}, Accuracy {}'.format(scores[0], scores[1], scores[2], scores[3]))\n",
    "# binary_crossentropy 0.6377848553657531, Precision 0.6377848386764526, Recall 0.0, Accuracy 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: (200, 100, 1) y_actual: (200, 100, 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.79     13176\n",
      "           1       0.00      0.00      0.00      6824\n",
      "\n",
      "    accuracy                           0.66     20000\n",
      "   macro avg       0.33      0.50      0.40     20000\n",
      "weighted avg       0.43      0.66      0.52     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/htahir/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(200, 100, 1)"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = binary_model.predict_classes(x_val[:,:,:])\n",
    "y_actual = y_val[:,:,:]\n",
    "\n",
    "print('y_pred: {} y_actual: {}'.format(y_pred.shape, y_actual.shape))\n",
    "print(classification_report(y_actual.flatten(), y_pred.flatten()))\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is not doing so well! Let's plot the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'],history.history['val_loss'],)\n",
    "# history.history.keys()\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, maybe the dataset isn't the best...but we cna retry it with a basic NN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test a feedforward NN on the binary dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't know if it's our dataset that's the issue...or the model. If this also sucks, our dataset might be an issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the model, compile, and run a simple feedforward NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./test_lstm_logs/run_2020_04_22-21_53_44\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (Flatten)              (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "hidden_1 (Dense)             (None, 32)                64032     \n",
      "_________________________________________________________________\n",
      "hidden_2 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 65,121\n",
      "Trainable params: 65,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "prep_run()\n",
    "run_logdir = get_run_logdir(\"test_lstm_logs\")\n",
    "print(run_logdir)\n",
    "\n",
    "# build simple OLS model\n",
    "\n",
    "ffwd_model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[n_steps,features], name='input'),\n",
    "#     keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1], name='input'),\n",
    "    keras.layers.Dense(32, activation='relu', name='hidden_1'),\n",
    "    keras.layers.Dense(32, activation='relu', name='hidden_2'),\n",
    "#     keras.layers.SimpleRNN(32, return_sequences=True),\n",
    "#     keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, name='output')\n",
    "])\n",
    "ffwd_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "700/700 [==============================] - 6s 8ms/sample - loss: 0.6431 - binary_crossentropy: 0.6431 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.6531 - val_loss: 0.6393 - val_binary_crossentropy: 0.6393 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6588\n",
      "Epoch 2/10\n",
      "700/700 [==============================] - 3s 4ms/sample - loss: 0.6419 - binary_crossentropy: 0.6419 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.6531 - val_loss: 0.6376 - val_binary_crossentropy: 0.6376 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6588\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - 3s 4ms/sample - loss: 0.6397 - binary_crossentropy: 0.6397 - Precision: 0.2500 - Recall: 4.1184e-05 - accuracy: 0.6531 - val_loss: 0.6333 - val_binary_crossentropy: 0.6333 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6588\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - 3s 5ms/sample - loss: 0.6344 - binary_crossentropy: 0.6344 - Precision: 0.4458 - Recall: 0.0015 - accuracy: 0.6530 - val_loss: 0.6274 - val_binary_crossentropy: 0.6274 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6588\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - 3s 4ms/sample - loss: 0.6286 - binary_crossentropy: 0.6286 - Precision: 0.4994 - Recall: 0.0349 - accuracy: 0.6531 - val_loss: 0.6191 - val_binary_crossentropy: 0.6191 - val_Precision: 0.4141 - val_Recall: 0.0060 - val_accuracy: 0.6579\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - 3s 5ms/sample - loss: 0.6244 - binary_crossentropy: 0.6244 - Precision: 0.4964 - Recall: 0.0619 - accuracy: 0.6528 - val_loss: 0.6180 - val_binary_crossentropy: 0.6180 - val_Precision: 0.3333 - val_Recall: 7.3271e-04 - val_accuracy: 0.6586\n",
      "Epoch 7/10\n",
      "700/700 [==============================] - 3s 4ms/sample - loss: 0.6214 - binary_crossentropy: 0.6214 - Precision: 0.5115 - Recall: 0.1084 - accuracy: 0.6548 - val_loss: 0.6134 - val_binary_crossentropy: 0.6134 - val_Precision: 0.5506 - val_Recall: 0.1133 - val_accuracy: 0.6659\n",
      "Epoch 8/10\n",
      "700/700 [==============================] - 3s 4ms/sample - loss: 0.6172 - binary_crossentropy: 0.6172 - Precision: 0.5360 - Recall: 0.1122 - accuracy: 0.6584 - val_loss: 0.6116 - val_binary_crossentropy: 0.6116 - val_Precision: 0.5504 - val_Recall: 0.1417 - val_accuracy: 0.6676\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - 3s 5ms/sample - loss: 0.6149 - binary_crossentropy: 0.6149 - Precision: 0.5309 - Recall: 0.1405 - accuracy: 0.6588 - val_loss: 0.6106 - val_binary_crossentropy: 0.6106 - val_Precision: 0.5343 - val_Recall: 0.1703 - val_accuracy: 0.6662\n",
      "Epoch 10/10\n",
      "700/700 [==============================] - 3s 4ms/sample - loss: 0.6145 - binary_crossentropy: 0.6145 - Precision: 0.5325 - Recall: 0.1369 - accuracy: 0.6589 - val_loss: 0.6110 - val_binary_crossentropy: 0.6110 - val_Precision: 0.5482 - val_Recall: 0.1575 - val_accuracy: 0.6683\n"
     ]
    }
   ],
   "source": [
    "tb = TensorBoard(run_logdir)\n",
    "lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='binary_crossentropy',\n",
    "                                          patience=3, \n",
    "                                          verbose=1,\n",
    "                                          factor=0.5, \n",
    "                                          min_lr=0.00001)\n",
    "ffwd_model.compile(loss='binary_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['binary_crossentropy', 'Precision','Recall', 'accuracy'])\n",
    "\n",
    "history = binary_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=10, callbacks=[tb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos %: 29.4 neg %: 70.6\n",
      "initial_bias:  [-0.87603547]\n"
     ]
    }
   ],
   "source": [
    "# we'll go back in and add bias initializer ot output layer:\n",
    "\n",
    "# find the bias in dataset classes:\n",
    "neg, pos = np.bincount(df_y3[:,0])\n",
    "total = df_y.shape[0]\n",
    "# total\n",
    "# # output counts of classes.\n",
    "print('pos %: {} neg %: {}'.format(pos/total*100,neg/total*100))\n",
    "\n",
    "# calculate bias to be used in output layer\n",
    "initial_bias = np.log([pos/neg])\n",
    "print('initial_bias: ',initial_bias)\n",
    "initial_bias = tf.keras.initializers.Constant(initial_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it may actually be the dataset....we may need to try real data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a real dataset to learn about LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use real data\n",
    "df = pd.read_excel('/Users/htahir/Documents/SCS_machine_learning/datasets/loans/Bank_Personal_Loan_Modelling.xlsx', 'Data')\n",
    "# also create a 3D array becasue keras likes those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 14 columns):\n",
      "ID                    5000 non-null int64\n",
      "Age                   5000 non-null int64\n",
      "Experience            5000 non-null int64\n",
      "Income                5000 non-null int64\n",
      "ZIP Code              5000 non-null int64\n",
      "Family                5000 non-null int64\n",
      "CCAvg                 5000 non-null float64\n",
      "Education             5000 non-null int64\n",
      "Mortgage              5000 non-null int64\n",
      "Personal Loan         5000 non-null int64\n",
      "Securities Account    5000 non-null int64\n",
      "CD Account            5000 non-null int64\n",
      "Online                5000 non-null int64\n",
      "CreditCard            5000 non-null int64\n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 547.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['ID', 'ZIP Code'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 749,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create our target values.\n",
    "df_y = df.pop('CreditCard')\n",
    "df_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                   0\n",
       "Experience            0\n",
       "Income                0\n",
       "Family                0\n",
       "CCAvg                 0\n",
       "Education             0\n",
       "Mortgage              0\n",
       "Personal Loan         0\n",
       "Securities Account    0\n",
       "CD Account            0\n",
       "Online                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditCard\n",
       "0              0\n",
       "1              0\n",
       "2              0\n",
       "3              0\n",
       "4              1\n",
       "...          ...\n",
       "4995           0\n",
       "4996           0\n",
       "4997           0\n",
       "4998           0\n",
       "4999           1\n",
       "\n",
       "[5000 rows x 1 columns]"
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For keras, we need to reformat our dataset to 3D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 11, 1), (5000, 1))"
      ]
     },
     "execution_count": 855,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y3 = np.array(df_y)\n",
    "df_y3 = df_y3[...,np.newaxis]\n",
    "\n",
    "df_3 = np.array(df)\n",
    "df_3 = df_3[...,np.newaxis]\n",
    "df_3.shape, df_y3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500, 11) (3500,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df, df_y, test_size=0.30, random_state=43)\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "# create val sets\n",
    "x_val = x_train[3000:]\n",
    "y_val = y_train[3000:]\n",
    "\n",
    "x_train = x_train[:3000]\n",
    "y_train = y_train[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (3000, 11, 1) (3000, 1)\n",
      "val:  (500, 11, 1) (500, 1)\n"
     ]
    }
   ],
   "source": [
    "# do the same for the 3D sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x3_train, x3_test, y3_train, y3_test = train_test_split(df_3, df_y3, test_size=0.30, random_state=43)\n",
    "\n",
    "# create val sets\n",
    "x3_val = x3_train[3000:]\n",
    "y3_val = y3_train[3000:]\n",
    "\n",
    "x3_train = x3_train[:3000]\n",
    "y3_train = y3_train[:3000]\n",
    "\n",
    "print('train: ', x3_train.shape, y3_train.shape)\n",
    "print('val: ', x3_val.shape, y3_val.shape, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11,)"
      ]
     },
     "execution_count": 824,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using simple NN on real dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build simple OLS model\n",
    "def build_ols_model(input, **kwargs):\n",
    "    model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[input], name='input'),\n",
    "#     keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1], name='input'),\n",
    "    keras.layers.Dense(32, activation='relu', name='hidden_1'),\n",
    "    keras.layers.Dense(32, activation='relu', name='hidden_2'),\n",
    "    keras.layers.Dense(1, activation='sigmoid',name='output')\n",
    "])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./test_lstm_logs/run_2020_04_22-22_40_44\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (Flatten)              (None, 11)                0         \n",
      "_________________________________________________________________\n",
      "hidden_1 (Dense)             (None, 32)                384       \n",
      "_________________________________________________________________\n",
      "hidden_2 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prep_run()\n",
    "run_logdir = get_run_logdir(\"test_lstm_logs\")\n",
    "print(run_logdir)\n",
    "\n",
    "loan_model = build_ols_model(x_train.shape[1])\n",
    "loan_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3000 samples, validate on 500 samples\n",
      "Epoch 1/20\n",
      "3000/3000 [==============================] - 1s 491us/sample - loss: 0.9015 - binary_crossentropy: 0.9015 - Precision: 0.2770 - Recall: 0.1339 - accuracy: 0.6430 - val_loss: 0.6660 - val_binary_crossentropy: 0.6660 - val_Precision: 0.3030 - val_Recall: 0.1316 - val_accuracy: 0.6440\n",
      "Epoch 2/20\n",
      "3000/3000 [==============================] - 0s 78us/sample - loss: 0.6873 - binary_crossentropy: 0.6873 - Precision: 0.3239 - Recall: 0.1305 - accuracy: 0.6647 - val_loss: 0.6377 - val_binary_crossentropy: 0.6377 - val_Precision: 0.3684 - val_Recall: 0.0461 - val_accuracy: 0.6860\n",
      "Epoch 3/20\n",
      "3000/3000 [==============================] - 0s 85us/sample - loss: 0.6590 - binary_crossentropy: 0.6590 - Precision: 0.2798 - Recall: 0.0692 - accuracy: 0.6743 - val_loss: 0.6358 - val_binary_crossentropy: 0.6358 - val_Precision: 0.3750 - val_Recall: 0.0197 - val_accuracy: 0.6920\n",
      "Epoch 4/20\n",
      "3000/3000 [==============================] - 0s 80us/sample - loss: 0.6486 - binary_crossentropy: 0.6486 - Precision: 0.3203 - Recall: 0.0840 - accuracy: 0.6787 - val_loss: 0.6501 - val_binary_crossentropy: 0.6501 - val_Precision: 0.3200 - val_Recall: 0.1053 - val_accuracy: 0.6600\n",
      "Epoch 5/20\n",
      "3000/3000 [==============================] - 0s 77us/sample - loss: 0.6404 - binary_crossentropy: 0.6404 - Precision: 0.3194 - Recall: 0.0522 - accuracy: 0.6890 - val_loss: 0.6207 - val_binary_crossentropy: 0.6207 - val_Precision: 0.3500 - val_Recall: 0.1382 - val_accuracy: 0.6600\n",
      "Epoch 6/20\n",
      "3000/3000 [==============================] - 0s 75us/sample - loss: 0.6380 - binary_crossentropy: 0.6380 - Precision: 0.3778 - Recall: 0.0965 - accuracy: 0.6880 - val_loss: 0.6270 - val_binary_crossentropy: 0.6270 - val_Precision: 0.4286 - val_Recall: 0.1382 - val_accuracy: 0.6820\n",
      "Epoch 7/20\n",
      "3000/3000 [==============================] - 0s 94us/sample - loss: 0.6437 - binary_crossentropy: 0.6437 - Precision: 0.3511 - Recall: 0.1044 - accuracy: 0.6803 - val_loss: 0.6003 - val_binary_crossentropy: 0.6003 - val_Precision: 0.5000 - val_Recall: 0.0855 - val_accuracy: 0.6960\n",
      "Epoch 8/20\n",
      "3000/3000 [==============================] - 0s 89us/sample - loss: 0.6400 - binary_crossentropy: 0.6400 - Precision: 0.4123 - Recall: 0.1067 - accuracy: 0.6930 - val_loss: 0.7360 - val_binary_crossentropy: 0.7360 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6960\n",
      "Epoch 9/20\n",
      "2304/3000 [======================>.......] - ETA: 0s - loss: 0.6250 - binary_crossentropy: 0.6250 - Precision: 0.3802 - Recall: 0.0702 - accuracy: 0.7031      \n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "3000/3000 [==============================] - 0s 77us/sample - loss: 0.6395 - binary_crossentropy: 0.6395 - Precision: 0.3561 - Recall: 0.0829 - accuracy: 0.6867 - val_loss: 0.6430 - val_binary_crossentropy: 0.6430 - val_Precision: 0.4167 - val_Recall: 0.1974 - val_accuracy: 0.6720\n",
      "Epoch 10/20\n",
      "3000/3000 [==============================] - 0s 75us/sample - loss: 0.6000 - binary_crossentropy: 0.6000 - Precision: 0.5534 - Recall: 0.0647 - accuracy: 0.7100 - val_loss: 0.6020 - val_binary_crossentropy: 0.6020 - val_Precision: 0.5385 - val_Recall: 0.1382 - val_accuracy: 0.7020\n",
      "Epoch 11/20\n",
      "3000/3000 [==============================] - 0s 85us/sample - loss: 0.6084 - binary_crossentropy: 0.6084 - Precision: 0.5190 - Recall: 0.0931 - accuracy: 0.7083 - val_loss: 0.5937 - val_binary_crossentropy: 0.5937 - val_Precision: 0.6429 - val_Recall: 0.0592 - val_accuracy: 0.7040\n",
      "Epoch 12/20\n",
      "3000/3000 [==============================] - 0s 77us/sample - loss: 0.5982 - binary_crossentropy: 0.5982 - Precision: 0.5408 - Recall: 0.0602 - accuracy: 0.7090 - val_loss: 0.5973 - val_binary_crossentropy: 0.5973 - val_Precision: 0.4583 - val_Recall: 0.0724 - val_accuracy: 0.6920\n",
      "Epoch 13/20\n",
      "3000/3000 [==============================] - 0s 73us/sample - loss: 0.6016 - binary_crossentropy: 0.6016 - Precision: 0.5662 - Recall: 0.0874 - accuracy: 0.7123 - val_loss: 0.6091 - val_binary_crossentropy: 0.6091 - val_Precision: 0.4783 - val_Recall: 0.1447 - val_accuracy: 0.6920\n",
      "Epoch 14/20\n",
      "3000/3000 [==============================] - 0s 83us/sample - loss: 0.6046 - binary_crossentropy: 0.6046 - Precision: 0.5208 - Recall: 0.0851 - accuracy: 0.7083 - val_loss: 0.5909 - val_binary_crossentropy: 0.5909 - val_Precision: 0.6047 - val_Recall: 0.1711 - val_accuracy: 0.7140\n",
      "Epoch 15/20\n",
      "3000/3000 [==============================] - 0s 78us/sample - loss: 0.5943 - binary_crossentropy: 0.5943 - Precision: 0.5448 - Recall: 0.0829 - accuracy: 0.7103 - val_loss: 0.5918 - val_binary_crossentropy: 0.5918 - val_Precision: 0.6786 - val_Recall: 0.1250 - val_accuracy: 0.7160\n",
      "Epoch 16/20\n",
      "3000/3000 [==============================] - 0s 78us/sample - loss: 0.5959 - binary_crossentropy: 0.5959 - Precision: 0.5440 - Recall: 0.0772 - accuracy: 0.7100 - val_loss: 0.6030 - val_binary_crossentropy: 0.6030 - val_Precision: 0.6458 - val_Recall: 0.2039 - val_accuracy: 0.7240\n",
      "Epoch 17/20\n",
      "3000/3000 [==============================] - 0s 88us/sample - loss: 0.6045 - binary_crossentropy: 0.6045 - Precision: 0.5084 - Recall: 0.1033 - accuracy: 0.7073 - val_loss: 0.6085 - val_binary_crossentropy: 0.6085 - val_Precision: 0.5682 - val_Recall: 0.1645 - val_accuracy: 0.7080\n",
      "Epoch 18/20\n",
      "2816/3000 [===========================>..] - ETA: 0s - loss: 0.5982 - binary_crossentropy: 0.5982 - Precision: 0.5748 - Recall: 0.0877 - accuracy: 0.7113\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "3000/3000 [==============================] - 0s 85us/sample - loss: 0.5967 - binary_crossentropy: 0.5967 - Precision: 0.5781 - Recall: 0.0840 - accuracy: 0.7130 - val_loss: 0.5828 - val_binary_crossentropy: 0.5828 - val_Precision: 0.9167 - val_Recall: 0.0724 - val_accuracy: 0.7160\n",
      "Epoch 19/20\n",
      "3000/3000 [==============================] - 0s 75us/sample - loss: 0.5859 - binary_crossentropy: 0.5859 - Precision: 0.6772 - Recall: 0.0976 - accuracy: 0.7213 - val_loss: 0.5900 - val_binary_crossentropy: 0.5900 - val_Precision: 0.6410 - val_Recall: 0.1645 - val_accuracy: 0.7180\n",
      "Epoch 20/20\n",
      "3000/3000 [==============================] - 0s 77us/sample - loss: 0.5852 - binary_crossentropy: 0.5852 - Precision: 0.6755 - Recall: 0.1158 - accuracy: 0.7240 - val_loss: 0.5843 - val_binary_crossentropy: 0.5843 - val_Precision: 0.8667 - val_Recall: 0.1711 - val_accuracy: 0.7400\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# class_weight = {0: 1.,\n",
    "#                 1: 50.}\n",
    "tb = TensorBoard(run_logdir)\n",
    "lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='binary_crossentropy',\n",
    "                                          patience=3, \n",
    "                                          verbose=1,\n",
    "                                          factor=0.5, \n",
    "                                          min_lr=0.00001)\n",
    "loan_model.compile(loss='binary_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['binary_crossentropy', 'Precision','Recall', 'accuracy'])\n",
    "\n",
    "history = loan_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=20, callbacks=[tb, lr])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That did okay. Now we try our LSTM model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LSTM model instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_LSTM(inputA, initial_bias_, **kwargs):\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.LSTM(100, input_shape=[None, inputA], return_sequences=True),\n",
    "        keras.layers.LSTM(100),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(1, activation='sigmoid', bias_initializer=initial_bias_)\n",
    "])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"binary_lstm_test\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_10 (LSTM)               (None, None, 100)         40800     \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "binary_model = simple_LSTM(1, initial_bias)\n",
    "binary_model._name='binary_lstm_test'\n",
    "binary_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3000 samples, validate on 500 samples\n",
      "Epoch 1/40\n",
      "3000/3000 [==============================] - 7s 2ms/sample - loss: 0.6119 - binary_crossentropy: 0.6119 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.7063 - val_loss: 0.6146 - val_binary_crossentropy: 0.6146 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6960\n",
      "Epoch 2/40\n",
      "3000/3000 [==============================] - 2s 732us/sample - loss: 0.6068 - binary_crossentropy: 0.6068 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.7063 - val_loss: 0.6155 - val_binary_crossentropy: 0.6155 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6960\n",
      "Epoch 3/40\n",
      "3000/3000 [==============================] - 2s 757us/sample - loss: 0.6071 - binary_crossentropy: 0.6071 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.7063 - val_loss: 0.6135 - val_binary_crossentropy: 0.6135 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6960\n",
      "Epoch 4/40\n",
      "3000/3000 [==============================] - 2s 817us/sample - loss: 0.6069 - binary_crossentropy: 0.6069 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.7063 - val_loss: 0.6154 - val_binary_crossentropy: 0.6154 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6960\n",
      "Epoch 5/40\n",
      "3000/3000 [==============================] - 2s 739us/sample - loss: 0.6064 - binary_crossentropy: 0.6064 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.7063 - val_loss: 0.6150 - val_binary_crossentropy: 0.6150 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6960\n",
      "Epoch 6/40\n",
      "3000/3000 [==============================] - 2s 759us/sample - loss: 0.6061 - binary_crossentropy: 0.6061 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.7063 - val_loss: 0.6134 - val_binary_crossentropy: 0.6134 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6960\n",
      "Epoch 7/40\n",
      "3000/3000 [==============================] - 2s 736us/sample - loss: 0.6056 - binary_crossentropy: 0.6056 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.7063 - val_loss: 0.6136 - val_binary_crossentropy: 0.6136 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6960\n",
      "Epoch 8/40\n",
      "3000/3000 [==============================] - 2s 760us/sample - loss: 0.6069 - binary_crossentropy: 0.6069 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.7063 - val_loss: 0.6138 - val_binary_crossentropy: 0.6138 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6960\n",
      "Epoch 9/40\n",
      "3000/3000 [==============================] - 2s 747us/sample - loss: 0.6044 - binary_crossentropy: 0.6044 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.7063 - val_loss: 0.6130 - val_binary_crossentropy: 0.6130 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6960\n",
      "Epoch 10/40\n",
      "3000/3000 [==============================] - 2s 723us/sample - loss: 0.6046 - binary_crossentropy: 0.6046 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.7063 - val_loss: 0.6120 - val_binary_crossentropy: 0.6120 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6960\n",
      "Epoch 11/40\n",
      "3000/3000 [==============================] - 2s 727us/sample - loss: 0.6049 - binary_crossentropy: 0.6049 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.7063 - val_loss: 0.6118 - val_binary_crossentropy: 0.6118 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6960\n",
      "Epoch 12/40\n",
      "3000/3000 [==============================] - 2s 731us/sample - loss: 0.6042 - binary_crossentropy: 0.6042 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.7063 - val_loss: 0.6102 - val_binary_crossentropy: 0.6102 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6960\n",
      "Epoch 13/40\n",
      "3000/3000 [==============================] - 2s 727us/sample - loss: 0.6033 - binary_crossentropy: 0.6033 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.7063 - val_loss: 0.6119 - val_binary_crossentropy: 0.6119 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6960\n",
      "Epoch 14/40\n",
      "3000/3000 [==============================] - 2s 767us/sample - loss: 0.6033 - binary_crossentropy: 0.6033 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.7063 - val_loss: 0.6085 - val_binary_crossentropy: 0.6085 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6960\n",
      "Epoch 15/40\n",
      "3000/3000 [==============================] - 2s 745us/sample - loss: 0.6018 - binary_crossentropy: 0.6018 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.7063 - val_loss: 0.6074 - val_binary_crossentropy: 0.6074 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6960\n",
      "Epoch 16/40\n",
      "3000/3000 [==============================] - 2s 717us/sample - loss: 0.6013 - binary_crossentropy: 0.6013 - Precision: 0.5714 - Recall: 0.0045 - accuracy: 0.7067 - val_loss: 0.6044 - val_binary_crossentropy: 0.6044 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6960\n",
      "Epoch 17/40\n",
      "3000/3000 [==============================] - 2s 753us/sample - loss: 0.6002 - binary_crossentropy: 0.6002 - Precision: 0.5484 - Recall: 0.0193 - accuracy: 0.7073 - val_loss: 0.6015 - val_binary_crossentropy: 0.6015 - val_Precision: 1.0000 - val_Recall: 0.0461 - val_accuracy: 0.7100\n",
      "Epoch 18/40\n",
      "3000/3000 [==============================] - 2s 752us/sample - loss: 0.6000 - binary_crossentropy: 0.6000 - Precision: 0.6579 - Recall: 0.0284 - accuracy: 0.7103 - val_loss: 0.6011 - val_binary_crossentropy: 0.6011 - val_Precision: 1.0000 - val_Recall: 0.0329 - val_accuracy: 0.7060\n",
      "Epoch 19/40\n",
      "3000/3000 [==============================] - 2s 737us/sample - loss: 0.5968 - binary_crossentropy: 0.5968 - Precision: 0.7119 - Recall: 0.0477 - accuracy: 0.7147 - val_loss: 0.5985 - val_binary_crossentropy: 0.5985 - val_Precision: 1.0000 - val_Recall: 0.0658 - val_accuracy: 0.7160\n",
      "Epoch 20/40\n",
      "3000/3000 [==============================] - 2s 734us/sample - loss: 0.5940 - binary_crossentropy: 0.5940 - Precision: 0.7596 - Recall: 0.0897 - accuracy: 0.7243 - val_loss: 0.5910 - val_binary_crossentropy: 0.5910 - val_Precision: 1.0000 - val_Recall: 0.0724 - val_accuracy: 0.7180\n",
      "Epoch 21/40\n",
      "3000/3000 [==============================] - 2s 729us/sample - loss: 0.5844 - binary_crossentropy: 0.5844 - Precision: 0.8487 - Recall: 0.1146 - accuracy: 0.7340 - val_loss: 0.5588 - val_binary_crossentropy: 0.5588 - val_Precision: 0.9667 - val_Recall: 0.1908 - val_accuracy: 0.7520\n",
      "Epoch 22/40\n",
      "3000/3000 [==============================] - 2s 720us/sample - loss: 0.5735 - binary_crossentropy: 0.5735 - Precision: 0.8397 - Recall: 0.1249 - accuracy: 0.7360 - val_loss: 0.5569 - val_binary_crossentropy: 0.5569 - val_Precision: 0.9630 - val_Recall: 0.1711 - val_accuracy: 0.7460\n",
      "Epoch 23/40\n",
      "3000/3000 [==============================] - 2s 730us/sample - loss: 0.5647 - binary_crossentropy: 0.5647 - Precision: 0.8511 - Recall: 0.1362 - accuracy: 0.7393 - val_loss: 0.5435 - val_binary_crossentropy: 0.5435 - val_Precision: 0.9655 - val_Recall: 0.1842 - val_accuracy: 0.7500\n",
      "Epoch 24/40\n",
      "3000/3000 [==============================] - 2s 728us/sample - loss: 0.5618 - binary_crossentropy: 0.5618 - Precision: 0.8731 - Recall: 0.1328 - accuracy: 0.7397 - val_loss: 0.5446 - val_binary_crossentropy: 0.5446 - val_Precision: 0.9677 - val_Recall: 0.1974 - val_accuracy: 0.7540\n",
      "Epoch 25/40\n",
      "3000/3000 [==============================] - 2s 753us/sample - loss: 0.5591 - binary_crossentropy: 0.5591 - Precision: 0.8511 - Recall: 0.1362 - accuracy: 0.7393 - val_loss: 0.5481 - val_binary_crossentropy: 0.5481 - val_Precision: 0.9375 - val_Recall: 0.1974 - val_accuracy: 0.7520\n",
      "Epoch 26/40\n",
      "3000/3000 [==============================] - 2s 755us/sample - loss: 0.5564 - binary_crossentropy: 0.5564 - Precision: 0.8741 - Recall: 0.1339 - accuracy: 0.7400 - val_loss: 0.5411 - val_binary_crossentropy: 0.5411 - val_Precision: 0.9375 - val_Recall: 0.1974 - val_accuracy: 0.7520\n",
      "Epoch 27/40\n",
      "3000/3000 [==============================] - 2s 732us/sample - loss: 0.5531 - binary_crossentropy: 0.5531 - Precision: 0.8741 - Recall: 0.1339 - accuracy: 0.7400 - val_loss: 0.5468 - val_binary_crossentropy: 0.5468 - val_Precision: 0.8824 - val_Recall: 0.1974 - val_accuracy: 0.7480\n",
      "Epoch 28/40\n",
      "3000/3000 [==============================] - 2s 696us/sample - loss: 0.5525 - binary_crossentropy: 0.5525 - Precision: 0.8435 - Recall: 0.1407 - accuracy: 0.7400 - val_loss: 0.5390 - val_binary_crossentropy: 0.5390 - val_Precision: 0.9375 - val_Recall: 0.1974 - val_accuracy: 0.7520\n",
      "Epoch 29/40\n",
      "3000/3000 [==============================] - 2s 702us/sample - loss: 0.5509 - binary_crossentropy: 0.5509 - Precision: 0.8803 - Recall: 0.1419 - accuracy: 0.7423 - val_loss: 0.5476 - val_binary_crossentropy: 0.5476 - val_Precision: 0.9375 - val_Recall: 0.1974 - val_accuracy: 0.7520\n",
      "Epoch 30/40\n",
      "3000/3000 [==============================] - 2s 716us/sample - loss: 0.5489 - binary_crossentropy: 0.5489 - Precision: 0.8611 - Recall: 0.1407 - accuracy: 0.7410 - val_loss: 0.5409 - val_binary_crossentropy: 0.5409 - val_Precision: 0.9375 - val_Recall: 0.1974 - val_accuracy: 0.7520\n",
      "Epoch 31/40\n",
      "3000/3000 [==============================] - 2s 746us/sample - loss: 0.5473 - binary_crossentropy: 0.5473 - Precision: 0.8621 - Recall: 0.1419 - accuracy: 0.7413 - val_loss: 0.5421 - val_binary_crossentropy: 0.5421 - val_Precision: 0.9375 - val_Recall: 0.1974 - val_accuracy: 0.7520\n",
      "Epoch 32/40\n",
      "3000/3000 [==============================] - 2s 709us/sample - loss: 0.5482 - binary_crossentropy: 0.5482 - Precision: 0.8403 - Recall: 0.1373 - accuracy: 0.7390 - val_loss: 0.5414 - val_binary_crossentropy: 0.5414 - val_Precision: 0.9091 - val_Recall: 0.1974 - val_accuracy: 0.7500\n",
      "Epoch 33/40\n",
      "3000/3000 [==============================] - 2s 702us/sample - loss: 0.5485 - binary_crossentropy: 0.5485 - Precision: 0.8431 - Recall: 0.1464 - accuracy: 0.7413 - val_loss: 0.5417 - val_binary_crossentropy: 0.5417 - val_Precision: 0.9091 - val_Recall: 0.1974 - val_accuracy: 0.7500\n",
      "Epoch 34/40\n",
      "3000/3000 [==============================] - 2s 722us/sample - loss: 0.5425 - binary_crossentropy: 0.5425 - Precision: 0.8643 - Recall: 0.1373 - accuracy: 0.7403 - val_loss: 0.5387 - val_binary_crossentropy: 0.5387 - val_Precision: 0.9375 - val_Recall: 0.1974 - val_accuracy: 0.7520\n",
      "Epoch 35/40\n",
      "3000/3000 [==============================] - 2s 675us/sample - loss: 0.5431 - binary_crossentropy: 0.5431 - Precision: 0.8611 - Recall: 0.1407 - accuracy: 0.7410 - val_loss: 0.5412 - val_binary_crossentropy: 0.5412 - val_Precision: 0.9091 - val_Recall: 0.1974 - val_accuracy: 0.7500\n",
      "Epoch 36/40\n",
      "3000/3000 [==============================] - 2s 735us/sample - loss: 0.5448 - binary_crossentropy: 0.5448 - Precision: 0.8446 - Recall: 0.1419 - accuracy: 0.7403 - val_loss: 0.5401 - val_binary_crossentropy: 0.5401 - val_Precision: 0.9333 - val_Recall: 0.1842 - val_accuracy: 0.7480\n",
      "Epoch 37/40\n",
      "3000/3000 [==============================] - 2s 744us/sample - loss: 0.5394 - binary_crossentropy: 0.5394 - Precision: 0.8552 - Recall: 0.1407 - accuracy: 0.7407 - val_loss: 0.5413 - val_binary_crossentropy: 0.5413 - val_Precision: 0.9375 - val_Recall: 0.1974 - val_accuracy: 0.7520\n",
      "Epoch 38/40\n",
      "3000/3000 [==============================] - 2s 740us/sample - loss: 0.5404 - binary_crossentropy: 0.5404 - Precision: 0.8621 - Recall: 0.1419 - accuracy: 0.7413 - val_loss: 0.5407 - val_binary_crossentropy: 0.5407 - val_Precision: 0.8571 - val_Recall: 0.1974 - val_accuracy: 0.7460\n",
      "Epoch 39/40\n",
      "3000/3000 [==============================] - 2s 718us/sample - loss: 0.5421 - binary_crossentropy: 0.5421 - Precision: 0.8571 - Recall: 0.1430 - accuracy: 0.7413 - val_loss: 0.5431 - val_binary_crossentropy: 0.5431 - val_Precision: 0.8824 - val_Recall: 0.1974 - val_accuracy: 0.7480\n",
      "Epoch 40/40\n",
      "2912/3000 [============================>.] - ETA: 0s - loss: 0.5375 - binary_crossentropy: 0.5375 - Precision: 0.8276 - Recall: 0.1422 - accuracy: 0.7428\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "3000/3000 [==============================] - 2s 728us/sample - loss: 0.5394 - binary_crossentropy: 0.5394 - Precision: 0.8344 - Recall: 0.1430 - accuracy: 0.7400 - val_loss: 0.5405 - val_binary_crossentropy: 0.5405 - val_Precision: 0.9091 - val_Recall: 0.1974 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# class_weight = {0: 1.,\n",
    "#                 1: 50.}\n",
    "tb = TensorBoard(run_logdir)\n",
    "lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='binary_crossentropy',\n",
    "                                          patience=3, \n",
    "                                          verbose=1,\n",
    "                                          factor=0.5, \n",
    "                                          min_lr=0.00001)\n",
    "binary_model.compile(loss='binary_crossentropy',\n",
    "                    optimizer=tf.keras.optimizers.Adam(lr=1e-3),\n",
    "                    metrics=['binary_crossentropy', 'Precision','Recall', 'accuracy'])\n",
    "\n",
    "history = binary_model.fit(x3_train, y3_train, validation_data=(x3_val, y3_val), epochs=40, callbacks=[tb, lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 246us/sample - loss: 0.5405 - binary_crossentropy: 0.5405 - Precision: 0.9091 - Recall: 0.1974 - accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "scores = binary_model.evaluate(x3_val, y3_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot classification report from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: (500, 1) y_actual: (500, 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.99      0.85       348\n",
      "           1       0.91      0.20      0.32       152\n",
      "\n",
      "    accuracy                           0.75       500\n",
      "   macro avg       0.82      0.59      0.59       500\n",
      "weighted avg       0.79      0.75      0.69       500\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500, 1)"
      ]
     },
     "execution_count": 941,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = binary_model.predict_classes(x3_val[:,:,:])\n",
    "y_actual = y3_val[:,:]\n",
    "\n",
    "print('y_pred: {} y_actual: {}'.format(y_pred.shape, y_actual.shape))\n",
    "print(classification_report(y_actual.flatten(), y_pred.flatten()))\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's really good a preoicting only one class. Let's keep optimizing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a stable LSTM on same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"stateful_binary_lstm_test\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_90 (LSTM)               (1, 11, 100)              40800     \n",
      "_________________________________________________________________\n",
      "lstm_91 (LSTM)               (1, 100)                  80400     \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (1, 100)                  0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (1, 1)                    101       \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# stateful LSTM\n",
    "def stateful_LSTM(inputA, initial_bias_, batch_size, lahead):\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.LSTM(100, input_shape=[lahead, inputA], stateful=True, batch_size=batch_size, return_sequences=True),\n",
    "        keras.layers.LSTM(100),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(1, activation='sigmoid', bias_initializer=initial_bias_)\n",
    "])    \n",
    "    return model\n",
    "\n",
    "tsteps = 2\n",
    "\n",
    "# The input sequence length that the LSTM is trained on for each output point\n",
    "lahead = 11\n",
    "\n",
    "# training parameters passed to \"model.fit(...)\"\n",
    "batch_size = 1\n",
    "epochs = 10\n",
    "\n",
    "binary_model = stateful_LSTM(1, initial_bias, batch_size, lahead)\n",
    "binary_model._name='stateful_binary_lstm_test'\n",
    "binary_model.summary()\n",
    "binary_model.compile(loss='binary_crossentropy',\n",
    "                    optimizer=tf.keras.optimizers.Adam(lr=1e-3),\n",
    "                    metrics=['binary_crossentropy', 'Precision','Recall', 'accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10\n",
      "Train on 3000 samples, validate on 500 samples\n",
      "3000/3000 [==============================] - 37s 12ms/sample - loss: 0.6125 - binary_crossentropy: 0.6125 - Precision: 0.3611 - Recall: 0.0148 - accuracy: 0.7030 - val_loss: 0.6158 - val_binary_crossentropy: 0.6158 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6960\n",
      "Epoch 2 / 10\n",
      "Train on 3000 samples, validate on 500 samples\n",
      "3000/3000 [==============================] - 33s 11ms/sample - loss: 0.6108 - binary_crossentropy: 0.6108 - Precision: 0.3750 - Recall: 0.0068 - accuracy: 0.7050 - val_loss: 0.6147 - val_binary_crossentropy: 0.6147 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6960\n",
      "Epoch 3 / 10\n",
      "Train on 3000 samples, validate on 500 samples\n",
      "3000/3000 [==============================] - 34s 11ms/sample - loss: 0.6080 - binary_crossentropy: 0.6080 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.7063 - val_loss: 0.6158 - val_binary_crossentropy: 0.6158 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6960\n",
      "Epoch 4 / 10\n",
      "Train on 3000 samples, validate on 500 samples\n",
      "3000/3000 [==============================] - 33s 11ms/sample - loss: 0.6069 - binary_crossentropy: 0.6069 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.7063 - val_loss: 0.6152 - val_binary_crossentropy: 0.6152 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6960\n",
      "Epoch 5 / 10\n",
      "Train on 3000 samples, validate on 500 samples\n",
      "3000/3000 [==============================] - 32s 11ms/sample - loss: 0.6065 - binary_crossentropy: 0.6065 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.7063 - val_loss: 0.6150 - val_binary_crossentropy: 0.6150 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6960\n",
      "Epoch 6 / 10\n",
      "Train on 3000 samples, validate on 500 samples\n",
      "3000/3000 [==============================] - 31s 10ms/sample - loss: 0.6059 - binary_crossentropy: 0.6059 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.7063 - val_loss: 0.6145 - val_binary_crossentropy: 0.6145 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6960\n",
      "Epoch 7 / 10\n",
      "Train on 3000 samples, validate on 500 samples\n",
      "3000/3000 [==============================] - 32s 11ms/sample - loss: 0.6057 - binary_crossentropy: 0.6057 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.7063 - val_loss: 0.6146 - val_binary_crossentropy: 0.6146 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6960\n",
      "Epoch 8 / 10\n",
      "Train on 3000 samples, validate on 500 samples\n",
      "3000/3000 [==============================] - 32s 11ms/sample - loss: 0.6057 - binary_crossentropy: 0.6057 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.7063 - val_loss: 0.6146 - val_binary_crossentropy: 0.6146 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6960\n",
      "Epoch 9 / 10\n",
      "Train on 3000 samples, validate on 500 samples\n",
      "3000/3000 [==============================] - 32s 11ms/sample - loss: 0.6057 - binary_crossentropy: 0.6057 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.7063 - val_loss: 0.6146 - val_binary_crossentropy: 0.6146 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6960\n",
      "Epoch 10 / 10\n",
      "Train on 3000 samples, validate on 500 samples\n",
      "3000/3000 [==============================] - 32s 11ms/sample - loss: 0.6056 - binary_crossentropy: 0.6056 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.7063 - val_loss: 0.6146 - val_binary_crossentropy: 0.6146 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.6960\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    print('Epoch', i + 1, '/', epochs)\n",
    "    # Note that the last state for sample i in a batch will\n",
    "    # be used as initial state for sample i in the next batch.\n",
    "    # Thus we are simultaneously training on batch_size series with\n",
    "    # lower resolution than the original series contained in data_input.\n",
    "    # Each of these series are offset by one step and can be\n",
    "    # extracted with data_input[i::batch_size].\n",
    "    binary_model.fit(x3_train, y3_train, \n",
    "                       validation_data=(x3_val, y3_val),\n",
    "                       batch_size=batch_size,\n",
    "                       epochs=1,\n",
    "                       verbose=1,\n",
    "                       shuffle=False)\n",
    "    binary_model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: (500, 1) y_actual: (500, 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82       348\n",
      "           1       0.00      0.00      0.00       152\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.35      0.50      0.41       500\n",
      "weighted avg       0.48      0.70      0.57       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/htahir/anaconda3/envs/tensorflow_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500, 1)"
      ]
     },
     "execution_count": 976,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = binary_model.predict_classes(x3_val[:,:,:], batch_size=batch_size)\n",
    "y_actual = y3_val[:,:]\n",
    "\n",
    "print('y_pred: {} y_actual: {}'.format(y_pred.shape, y_actual.shape))\n",
    "print(classification_report(y_actual.flatten(), y_pred.flatten()))\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 11, 1)"
      ]
     },
     "execution_count": 973,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform our dataset for keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500000 entries, 0 to 499999\n",
      "Data columns (total 9 columns):\n",
      "timestamp        500000 non-null object\n",
      "visitorid        500000 non-null int64\n",
      "event            500000 non-null object\n",
      "itemid           500000 non-null int64\n",
      "transactionid    4185 non-null float64\n",
      "categoryid       455357 non-null float64\n",
      "parentid         455354 non-null float64\n",
      "sessionid        500000 non-null object\n",
      "date             500000 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(3), int64(2), object(3)\n",
      "memory usage: 34.3+ MB\n"
     ]
    }
   ],
   "source": [
    "pwd = '/Users/htahir/Documents/SCS_machine_learning/Final_Project/'\n",
    "\n",
    "# load our clean dataset:\n",
    "\n",
    "df = pd.read_csv(pwd+'ecommerce_merged_data.csv', nrows=500000,infer_datetime_format=True, parse_dates=[8])\n",
    "# df = df.query('visitorid in (552148, 189384)').copy()\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the Keras model is to predict conversion vs non-conversion of a user based on their historical buying behaviour. We will not train the model on exactly WHAT item the user is buying (because there are literally over a 100,000 of them). However, we'll train on on the parent categories of an item a visitor has bought from historically.\n",
    "\n",
    "Let's load our clean dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>visitorid</th>\n",
       "      <th>event</th>\n",
       "      <th>itemid</th>\n",
       "      <th>transactionid</th>\n",
       "      <th>categoryid</th>\n",
       "      <th>parentid</th>\n",
       "      <th>sessionid</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-06-02 01:02:12</td>\n",
       "      <td>257597</td>\n",
       "      <td>view</td>\n",
       "      <td>355908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1173.0</td>\n",
       "      <td>805.0</td>\n",
       "      <td>2015-06-02_257597</td>\n",
       "      <td>2015-06-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-06-02 01:50:14</td>\n",
       "      <td>992329</td>\n",
       "      <td>view</td>\n",
       "      <td>248676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1231.0</td>\n",
       "      <td>901.0</td>\n",
       "      <td>2015-06-02_992329</td>\n",
       "      <td>2015-06-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-06-02 01:13:19</td>\n",
       "      <td>111016</td>\n",
       "      <td>view</td>\n",
       "      <td>318965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-06-02_111016</td>\n",
       "      <td>2015-06-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-06-02 01:12:35</td>\n",
       "      <td>483717</td>\n",
       "      <td>view</td>\n",
       "      <td>253185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>914.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>2015-06-02_483717</td>\n",
       "      <td>2015-06-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-06-02 01:02:17</td>\n",
       "      <td>951259</td>\n",
       "      <td>view</td>\n",
       "      <td>367447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>491.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>2015-06-02_951259</td>\n",
       "      <td>2015-06-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp  visitorid event  itemid  transactionid  categoryid  \\\n",
       "0  2015-06-02 01:02:12     257597  view  355908            NaN      1173.0   \n",
       "1  2015-06-02 01:50:14     992329  view  248676            NaN      1231.0   \n",
       "2  2015-06-02 01:13:19     111016  view  318965            NaN         NaN   \n",
       "3  2015-06-02 01:12:35     483717  view  253185            NaN       914.0   \n",
       "4  2015-06-02 01:02:17     951259  view  367447            NaN       491.0   \n",
       "\n",
       "   parentid          sessionid       date  \n",
       "0     805.0  2015-06-02_257597 2015-06-02  \n",
       "1     901.0  2015-06-02_992329 2015-06-02  \n",
       "2       NaN  2015-06-02_111016 2015-06-02  \n",
       "3     226.0  2015-06-02_483717 2015-06-02  \n",
       "4     679.0  2015-06-02_951259 2015-06-02  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to build a transformer to quickly clean up our dataset, dropping any unwaved columns and changing data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom transformer to drop any useless data\n",
    "\n",
    "class DropColumn(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def transform(self, X, y=None):\n",
    "        df = X.drop(columns=self.cols)\n",
    "        return df\n",
    "    \n",
    "class DropNulls(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, drop_nulls=True):\n",
    "        self.drop_nulls = drop_nulls\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def transform(self, X, y=None):\n",
    "        if self.drop_nulls==True:\n",
    "            df = X.dropna(inplace=False)\n",
    "            df = df.reset_index(inplace=False, drop=True)\n",
    "            return df\n",
    "        else:\n",
    "            pass\n",
    "        return df\n",
    "    \n",
    "class ChangeColType(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols, newType):\n",
    "        self.cols = cols\n",
    "        self.newType = newType\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def transform(self, X, y=None):\n",
    "        for col in self.cols:\n",
    "            X[col] = X[col].astype(self.newType)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45682 entries, 0 to 45681\n",
      "Data columns (total 6 columns):\n",
      "visitorid     45682 non-null int64\n",
      "event         45682 non-null object\n",
      "itemid        45682 non-null int64\n",
      "categoryid    45682 non-null int64\n",
      "parentid      45682 non-null int64\n",
      "date          45682 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(4), object(1)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "CleanRawData = make_pipeline(\n",
    "    DropColumn(['transactionid', 'sessionid', 'timestamp']),\n",
    "    DropNulls(),\n",
    "    ChangeColType(['categoryid', 'parentid'],int)\n",
    ")\n",
    "df = CleanRawData.transform(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineer our dataset for Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to do some quick feature engineering before we start reshaping our dataset for a neural network. This will allow us to provide the model some additional information.  \n",
    "\n",
    "We're going to add weekday as a feature, as ther eis a good chance of a wekly buying patttern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a transformer to extract weekday as a feature\n",
    "\n",
    "class WeekdayExtractor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        weekday = X.progress_apply(lambda x: 'weekday_'+ str(x.weekday()))\n",
    "        return weekday.rename('weekday').to_frame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa48eab3b7e47b5a1a73357c188f770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=500000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500000 entries, 0 to 499999\n",
      "Data columns (total 16 columns):\n",
      "timestamp        -500000 non-null object\n",
      "visitorid        -500000 non-null int64\n",
      "event            -500000 non-null object\n",
      "itemid           -500000 non-null int64\n",
      "transactionid    -995815 non-null float64\n",
      "categoryid       -544643 non-null float64\n",
      "parentid         -544646 non-null float64\n",
      "sessionid        -500000 non-null object\n",
      "date             -500000 non-null datetime64[ns]\n",
      "x0_weekday_0     -500000 non-null Sparse[float64, 0.0]\n",
      "x0_weekday_1     -500000 non-null Sparse[float64, 0.0]\n",
      "x0_weekday_2     -500000 non-null Sparse[float64, 0.0]\n",
      "x0_weekday_3     -500000 non-null Sparse[float64, 0.0]\n",
      "x0_weekday_4     -500000 non-null Sparse[float64, 0.0]\n",
      "x0_weekday_5     -500000 non-null Sparse[float64, 0.0]\n",
      "x0_weekday_6     -500000 non-null Sparse[float64, 0.0]\n",
      "dtypes: Sparse[float64, 0.0](7), datetime64[ns](1), float64(3), int64(2), object(3)\n",
      "memory usage: 40.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# pipeline to extract weekday\n",
    "wkday_pipeline = Pipeline(steps=[\n",
    "    ('wkday', WeekdayExtractor()),\n",
    "    ('onehot', OneHotEncoder())\n",
    "])\n",
    "\n",
    "transformed = wkday_pipeline.fit_transform(df['date'])\n",
    "ohe_df = pd.DataFrame.sparse.from_spmatrix(transformed, \n",
    "                                           columns=wkday_pipeline['onehot'].get_feature_names())\n",
    "\n",
    "df = pd.concat([df, ohe_df], axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258583,)"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.visitorid.unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our keras model needs the dataset to be in a 3D array of shape (visitors, num visits/timesteps, features).\n",
    "\n",
    "The way our dataset is set up, we can't just split the \"events\" data into train and test. We have to preseve the history of each user (i.e. users must not be split across train and test).\n",
    "\n",
    "So here is the plan:\n",
    "\n",
    "1. Create a daily-level dataframe of featuers per visitor:  \n",
    "    a. Pivot entire dataset on daily visitor level so that parentIDs become columns with view counts and add to cart counts per each parentID (we'll make separate DFs for each event type).  \n",
    "    b. To avoid differing numbers of parentID columns in current and any future data, we're going to join it to an empty dataframe that contains column of every single parentID in our dataset).  \n",
    "    c. Combine our views DF and addtoCart DF to create a final daily record per user.\n",
    "2. Create timestep arrays: \n",
    "    a. find max timesteps (this will be the length of our timestep array).  \n",
    "    b. create a list per user containing lists of features per timestep.  \n",
    "    c. Combine the lists to create our final array with a row for every visitor's timestep sequence.\n",
    "    d. Split out into train/test.\n",
    "3. Preprocess our training data.  \n",
    "    a. Combine every feature vector into one input array and pad it to same length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a daily-level dataframe of features per visitor:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find some sample users who converted, to avoid running the entire dataset while we work on trasnforming it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create our features array, we'll create 3 aggregated DFs on visitor and date level (one for each event: view, add to cart, purchase). One will count # views per categoryid per user daily, the second will count add to cart, the third will count purchases per visitor per day, which we'll convert to 0/1. In our case, we don't care what the user purchased, just that they made a purchase, and that's what we want our model to predict.\n",
    "\n",
    "We'll also create a fourth dataframe that is empty and contains a column for every parent ID in our dataset. This will be merged individually with the views and add to cart dataframes to ensure all our input data is of equal length (and that we never miss a categoryID regardless of if our current dataset has it). So now we ahve two arrays, both of equal number of columns. \n",
    "\n",
    "Now we join them together to create a DF twice as wide (with a column for every category's view and addtocart values separately). This will give us daly-level activity for every single user.\n",
    "\n",
    "The custom transformer below does all this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500000 entries, 0 to 499999\n",
      "Data columns (total 16 columns):\n",
      "timestamp        -500000 non-null object\n",
      "visitorid        -500000 non-null int64\n",
      "event            -500000 non-null object\n",
      "itemid           -500000 non-null int64\n",
      "transactionid    -995815 non-null float64\n",
      "categoryid       -544643 non-null float64\n",
      "parentid         -544646 non-null float64\n",
      "sessionid        -500000 non-null object\n",
      "date             -500000 non-null datetime64[ns]\n",
      "x0_weekday_0     -500000 non-null Sparse[float64, 0.0]\n",
      "x0_weekday_1     -500000 non-null Sparse[float64, 0.0]\n",
      "x0_weekday_2     -500000 non-null Sparse[float64, 0.0]\n",
      "x0_weekday_3     -500000 non-null Sparse[float64, 0.0]\n",
      "x0_weekday_4     -500000 non-null Sparse[float64, 0.0]\n",
      "x0_weekday_5     -500000 non-null Sparse[float64, 0.0]\n",
      "x0_weekday_6     -500000 non-null Sparse[float64, 0.0]\n",
      "dtypes: Sparse[float64, 0.0](7), datetime64[ns](1), float64(3), int64(2), object(3)\n",
      "memory usage: 40.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReshapeDataset(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # create an empty df with all category vals\n",
    "        self.cat_df = pd.DataFrame(columns=X.parentid.unique().tolist())\n",
    "        return self\n",
    "    \n",
    "#     def get_bias(self, col):\n",
    "#         self.neg, self.pos = np.bincount(col, minlength=0)\n",
    "#         self.bias = np.log(self.pos/self.neg)\n",
    "#         print(self.bias)\n",
    "#         self.bias = tf.keras.initializers.Constant(self.bias)\n",
    "#         return self.bias\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        # create 3 dfs for views, adds, purch\n",
    "        \n",
    "        # views\n",
    "        # removing sample visitorid in (552148, 189384) \n",
    "        print('Creating views pivot table...')\n",
    "        self.df_sample = X.query('event == \"view\" ').copy()\n",
    "        self.df_views = pd.pivot_table(self.df_sample, index=['date','visitorid',\n",
    "                                                              'x0_weekday_0','x0_weekday_1',\n",
    "                                                              'x0_weekday_2','x0_weekday_3',\n",
    "                                                              'x0_weekday_4','x0_weekday_5', \n",
    "                                                              'x0_weekday_6'\n",
    "                                                             ], \n",
    "                                columns=['parentid'], values='itemid',aggfunc='count', fill_value=0)\n",
    "        self.df_views = self.df_views.reset_index()\n",
    "        print('views df shape: ',self.df_views.shape)\n",
    "        \n",
    "        # add to cart\n",
    "        print('Creating add-to-cart pivot table...')\n",
    "        self.df_sample2 = X.query('event == \"addtocart\" ').copy()\n",
    "        self.df_adds = pd.pivot_table(self.df_sample2, index=['date','visitorid'], \n",
    "                                columns=['parentid'], values='itemid',aggfunc='count', fill_value=0)\n",
    "        self.df_adds = self.df_adds.reset_index()\n",
    "        print('adds df shape: ',self.df_adds.shape)\n",
    "\n",
    "        # purchases\n",
    "        print('Creating transactions pivot table...')\n",
    "        self.df_sample3 = X.query('event == \"transaction\" ').copy()\n",
    "        self.df_convert = pd.pivot_table(self.df_sample3, index=[ 'date','visitorid'], \n",
    "                                columns=['event'], values='itemid',aggfunc='count', fill_value=0)\n",
    "        self.df_convert = self.df_convert.reset_index()\n",
    "        \n",
    "        # join views and cart to category df \n",
    "        print('Merging parentID dataframe to views and add-to-cart separately...')\n",
    "        self.df_fullview = self.df_views.merge(self.cat_df, how='outer', on=None)\n",
    "        self.df_fulladds = pd.merge(self.df_adds, self.cat_df, how='outer', on=None)\n",
    "        \n",
    "        # merge both views and cart together\n",
    "        print('...and merging both of them together.')\n",
    "        self.full_df = self.df_fullview.merge(self.df_fulladds, \n",
    "                            how='outer', on=['date','visitorid'], \n",
    "                            suffixes=('_views', '_adds'))\n",
    "        \n",
    "        print('Creating target vector...')\n",
    "        # create our target vector by changing column values to binary\n",
    "        self.df_convert['transaction'] = np.where(self.df_convert['transaction']>0,1,0)\n",
    "        \n",
    "        # use this to find bias value\n",
    "#         print('Calculating bias...')\n",
    "#         self.initial_bias = self.get_bias(self.df_convert['transaction'])\n",
    "        \n",
    "        # merge target DF with the main features DF to make it easier \n",
    "        # to create our final input and target arrays.\n",
    "        self.full_df = self.full_df.merge(self.df_convert, how=\"outer\", on=[\"visitorid\", \"date\"])\n",
    "        self.full_df.fillna(0, inplace=True)\n",
    "        \n",
    "        print('Returning results. Proces complete.')\n",
    "        return self.full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating views pivot table...\n",
      "views df shape:  (252415, 272)\n",
      "Creating add-to-cart pivot table...\n",
      "adds df shape:  (7561, 209)\n",
      "Creating transactions pivot table...\n",
      "Merging parentID dataframe to views and add-to-cart separately...\n",
      "...and merging both of them together.\n",
      "Creating target vector...\n",
      "Returning results. Proces complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(253119, 538)"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = ReshapeDataset().fit_transform(df)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>visitorid</th>\n",
       "      <th>x0_weekday_0</th>\n",
       "      <th>x0_weekday_1</th>\n",
       "      <th>x0_weekday_2</th>\n",
       "      <th>x0_weekday_3</th>\n",
       "      <th>8_views</th>\n",
       "      <th>9_views</th>\n",
       "      <th>14_views</th>\n",
       "      <th>20_views</th>\n",
       "      <th>...</th>\n",
       "      <th>336_adds</th>\n",
       "      <th>732_adds</th>\n",
       "      <th>1669_adds</th>\n",
       "      <th>1374_adds</th>\n",
       "      <th>275_adds</th>\n",
       "      <th>1632_adds</th>\n",
       "      <th>265_adds</th>\n",
       "      <th>140_adds</th>\n",
       "      <th>1591_adds</th>\n",
       "      <th>transaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>4078</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>10946</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>27647</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>50966</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 493 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  visitorid  x0_weekday_0  x0_weekday_1  x0_weekday_2  \\\n",
       "0 2015-06-01         17           1.0           0.0           0.0   \n",
       "1 2015-06-01       4078           1.0           0.0           0.0   \n",
       "2 2015-06-01      10946           1.0           0.0           0.0   \n",
       "3 2015-06-01      27647           1.0           0.0           0.0   \n",
       "4 2015-06-01      50966           1.0           0.0           0.0   \n",
       "\n",
       "   x0_weekday_3  8_views  9_views  14_views  20_views  ...  336_adds  \\\n",
       "0           0.0      0.0      0.0       0.0       0.0  ...         0   \n",
       "1           0.0      0.0      0.0       0.0       0.0  ...         0   \n",
       "2           0.0      0.0      0.0       0.0       0.0  ...         0   \n",
       "3           0.0      0.0      0.0       0.0       0.0  ...         0   \n",
       "4           0.0      0.0      0.0       0.0       0.0  ...         0   \n",
       "\n",
       "   732_adds  1669_adds  1374_adds  275_adds  1632_adds  265_adds  140_adds  \\\n",
       "0         0          0          0         0          0         0         0   \n",
       "1         0          0          0         0          0         0         0   \n",
       "2         0          0          0         0          0         0         0   \n",
       "3         0          0          0         0          0         0         0   \n",
       "4         0          0          0         0          0         0         0   \n",
       "\n",
       "   1591_adds  transaction  \n",
       "0          0          0.0  \n",
       "1          0          0.0  \n",
       "2          0          0.0  \n",
       "3          0          0.0  \n",
       "4          0          0.0  \n",
       "\n",
       "[5 rows x 493 columns]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()\n",
    "# dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[dataset['visitorid']==189384]\n",
    "# data2 = dataset.reset_index(drop=True, inplace=False)\n",
    "# data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(522686, 2118)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full_dataset = dataset.to_numpy()\n",
    "# full_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_to_multiple_csv_files(data, name_prefix, header=None, n_parts=10):\n",
    "#     ecommerce_dir = os.path.join(\"datasets\", \"ecommerce\")\n",
    "#     os.makedirs(ecommerce_dir, exist_ok=True)\n",
    "#     path_format = os.path.join(ecommerce_dir, \"ecommerce_{}_{:02d}.csv\")\n",
    "\n",
    "#     filepaths = []\n",
    "#     m = len(data)\n",
    "#     for file_idx, row_indices in tqdm_notebook(enumerate(np.array_split(np.arange(m), n_parts)), desc=\"Creating data files:\"):\n",
    "#         part_csv = path_format.format(name_prefix, file_idx)\n",
    "#         filepaths.append(part_csv)\n",
    "#         with open(part_csv, \"wt\", encoding=\"utf-8\") as f:\n",
    "#             if header is not None:\n",
    "#                 f.write(header)\n",
    "#                 f.write(\"\\n\")\n",
    "#             for row_idx in row_indices:\n",
    "#                 f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
    "#                 f.write(\"\\n\")\n",
    "#     return filepaths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split out data set into train and test\n",
    "\n",
    "# train, test = train_test_split(full_dataset, test_size=0.3, random_state=42)\n",
    "# train, validation = train_test_split(train, test_size=0.3, random_state=42)\n",
    "\n",
    "# header_cols = dataset.columns.tolist()\n",
    "# header_cols = ','.join(header_cols)\n",
    "# train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print('Saving train set...')\n",
    "# train_filepaths = save_to_multiple_csv_files(train, \"train\", header_cols, n_parts=20)\n",
    "# print('Saving validation set...')\n",
    "# valid_filepaths = save_to_multiple_csv_files(validation, \"valid\", header_cols, n_parts=10)\n",
    "# print('Saving test set...')\n",
    "# test_filepaths = save_to_multiple_csv_files(test, \"test\", header_cols, n_parts=10)\n",
    "\n",
    "# train_filepaths[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find max timesteps\n",
    "# timesteps = dataset.groupby('visitorid')['date'].count().max()\n",
    "# print(timesteps, \" timesteps\")\n",
    "# timesteps = 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reload the data one file at a time and use each file to create a list of lists per user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_inputs = 9 # X_train.shape[-1]\n",
    "\n",
    "# @tf.function\n",
    "# def preprocess(line):\n",
    "#     defs = [0] * n_inputs + [tf.constant([], dtype=tf.int32)]\n",
    "#     fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "#     x = tf.stack(fields[:-1])\n",
    "#     y = tf.stack(fields[-1:])\n",
    "#     return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(9,), dtype=int32, numpy=array([ 1,  0,  0,  0,  0,  0,  0,  2, 14], dtype=int32)>,\n",
       " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(b'1,  0,  0,  0,  0,  0,  0,  2, 14,  0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create timestep array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll take that full dataset with every parentID, and reshape it into a list of lists of lists:\n",
    "\n",
    "- outer list: contains a row per user\n",
    "- each row: contains a list per timestep\n",
    "- timestep list: contains a list of features for that timestep\n",
    "\n",
    "While creating the features array, we'll also handle the target array, which wil have the same form of being a nested list of lists (except that it will only have one \"feature\" per timestep per user - the class).\n",
    "\n",
    "In the end, we'll have two lists: one for features, one for targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateInputArray(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # find max timesteps\n",
    "        self.max_timesteps = X.groupby('visitorid')['date'].count().max()\n",
    "        print(self.max_timesteps, \" timesteps\")\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        self.users = X.visitorid.unique()\n",
    "        self.user_list = [] \n",
    "        self.target_list = []\n",
    "        \n",
    "        for i in tqdm_notebook(self.users, desc=\"creating features/targets array\"):\n",
    "            self.temp_df = X[X.visitorid == i].copy()\n",
    "            self.t = self.temp_df['transaction'].astype(int).values.tolist()\n",
    "            self.target_list.append(self.t)\n",
    "            self.temp_df.drop(columns=['visitorid', 'date'], inplace=True)\n",
    "            self.record = self.temp_df.values.tolist()\n",
    "            self.user_list.append(self.record)\n",
    "        \n",
    "        print('sequence sample of first visitor:')\n",
    "        print(\"feature array: \", self.user_list[1][0][0:10])\n",
    "        print(\"targets: \",self.target_list[0])\n",
    "        \n",
    "        return self.user_list, self.target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26  timesteps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36a5bbdfe2f40e586c7f827685c2ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='creating features/targets array', max=226574.0, style=Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sequence sample of first visitor:\n",
      "feature array:  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "targets:  [0]\n"
     ]
    }
   ],
   "source": [
    "features, targets = CreateInputArray().fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done saving.\n"
     ]
    }
   ],
   "source": [
    "# save backup\n",
    "# df_fullview.to_csv('full_views.csv')\n",
    "# df_fulladds.to_csv('full_adds.csv')\n",
    "# print('Done saving.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our dataset at a level where we can split it into train/test withouot splitting a user betwen the two, we'll do that first, and then transform our train set into a time series for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X and Y:  (226574,) (226574,)\n",
      "Splitting out train/test/val.\n",
      "X_train and y_train shapes:\n",
      "(118950,) (118950,)\n",
      "input sample:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "X_val and y_val shapes:\n",
      "(39651,) (39651,)\n",
      "input sample:  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "X_test and y_test shapes:\n",
      "(67973,) (67973,)\n",
      "input sample:  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "X = np.array(features)\n",
    "y = np.array(targets)\n",
    "print(\"X and Y: \" , X.shape, y.shape)\n",
    "\n",
    "# split out data set into train and test\n",
    "print('Splitting out train/test/val.')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "print('X_train and y_train shapes:')\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('input sample: ', X_train[0][0][:10])\n",
    "\n",
    "print('X_val and y_val shapes:')\n",
    "print(X_val.shape, y_val.shape)\n",
    "print('input sample: ', X_val[0][0][:10])\n",
    "\n",
    "print('X_test and y_test shapes:')\n",
    "print(X_test.shape, y_test.shape)\n",
    "print('input sample: ', X_val[0][0][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess our training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our training data ready to be preprocessed.  \n",
    "Here we decide that for the sake of keeping this a bit more time-efficient, we'll be front-padding all timesteps for users who have fewer than the max num of timesteps. Ideally, we'd properly map the timestep with the day of the period, but that might have to be a latter iteration!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "#### Testing with a fake dataset. Skip to next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0]\n",
      "  [1]]\n",
      "\n",
      " [[0]\n",
      "  [0]]\n",
      "\n",
      " [[0]\n",
      "  [1]]]\n",
      "  Owner  Cat  Age\n",
      "0   Bob    1   10\n",
      "1  Jane    1    3\n",
      "2   Kat    0    2\n",
      "3   Bob    0    3\n",
      "sequence list:\n",
      "[[[1, 10], [0, 3]], [[1, 3]], [[0, 2]]]\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.DataFrame({'Owner': ['Bob', 'Jane', 'Kat', 'Bob'],\n",
    "                        'Cat':[1, 1, 0, 0], \n",
    "                        'Age':[10,3, 2, 3]})\n",
    "test_targets = np.random.randint(2, size=(3, 2, 1))\n",
    "print(test_targets)\n",
    "print(test_df.head())\n",
    "users = test_df.Owner.unique()\n",
    "user_list = [] \n",
    "for i in users:\n",
    "    temp_df = test_df[test_df.Owner == i].copy()\n",
    "#     print(temp_df.head())\n",
    "    temp_df.drop(columns='Owner', inplace=True)\n",
    "    record = temp_df.values.tolist()\n",
    "#     print(record)\n",
    "    user_list.append(record)\n",
    "print('sequence list:')\n",
    "print(user_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1 10]\n",
      "  [ 0  3]]\n",
      "\n",
      " [[ 1  3]\n",
      "  [ 0  0]]\n",
      "\n",
      " [[ 0  2]\n",
      "  [ 0  0]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 2, 2)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nulayer = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "#     sequences, maxlen=None, dtype='int32', padding='pre', truncating='pre',\n",
    "#     value=0.0\n",
    "# )_df.head()\n",
    "\n",
    "padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(user_list,\n",
    "                                                              padding='post')\n",
    "\n",
    "print(padded_inputs)\n",
    "\n",
    "padded_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ True  True]\n",
      "  [False  True]]\n",
      "\n",
      " [[ True  True]\n",
      "  [False False]]\n",
      "\n",
      " [[False  True]\n",
      "  [False False]]], shape=(3, 2, 2), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "embedding = keras.layers.Embedding(input_dim=5000, output_dim=16, mask_zero=True)\n",
    "masked_output = embedding(padded_inputs)\n",
    "\n",
    "print(masked_output._keras_mask)\n",
    "# print(masked_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ True  True]\n",
      "  [ True False]\n",
      "  [ True False]]], shape=(1, 3, 2), dtype=bool)\n",
      "tf.Tensor(\n",
      "[[[[ 1. 10.]\n",
      "   [ 0.  3.]]\n",
      "\n",
      "  [[ 1.  3.]\n",
      "   [ 0.  0.]]\n",
      "\n",
      "  [[ 0.  2.]\n",
      "   [ 0.  0.]]]], shape=(1, 3, 2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "masking_layer = keras.layers.Masking()\n",
    "# Simulate the embedding lookup by expanding the 2D input to 3D,\n",
    "# with embedding dimension of 10.\n",
    "unmasked_embedding = tf.cast(\n",
    "    tf.tile(tf.expand_dims(padded_inputs, axis=0), [1, 1, 1, 1]),\n",
    "    tf.float32)\n",
    "unmasked_embedding\n",
    "masked_embedding = masking_layer(unmasked_embedding)\n",
    "print(masked_embedding._keras_mask)\n",
    "print(masked_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3\n",
      "<tensorflow.python.ops.init_ops_v2.Constant object at 0x1a6fa58b70>\n"
     ]
    }
   ],
   "source": [
    "# test bias\n",
    "classA, classB = np.bincount(test_targets)\n",
    "print(classA, classB)\n",
    "test_bias = np.log(classA/classB)\n",
    "test_bias = tf.keras.initializers.Constant(test_bias)\n",
    "print(test_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masking_LSTM(inputA, initial_bias_=0.0, **kwargs):\n",
    "\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Masking(input_shape=[None, inputA], mask_value=0),\n",
    "        keras.layers.LSTM(10, return_sequences=True),\n",
    "        keras.layers.LSTM(10, return_sequences=True),\n",
    "#         keras.layers.Dropout(0.3),\n",
    "        keras.layers.TimeDistributed(keras.layers.Dense(1, activation='sigmoid', bias_initializer=initial_bias_))\n",
    "])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 2)\n",
      "[[[0.99999833]\n",
      "  [0.9824194 ]]\n",
      "\n",
      " [[0.98029053]\n",
      "  [0.5       ]]\n",
      "\n",
      " [[0.9359648 ]\n",
      "  [0.5       ]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a = np.array([[[0,0],[0,0],[2,0],[2,1],[1,0],[0,1]],[[0,0],[0,0],[0,0],[0,0],[0,0],[0,0]],\n",
    "                [[2,1],[1,1],[1,2],[2,3],[2,0],[1,10]]])\n",
    "print(a.shape)\n",
    "inputs = tf.keras.Input(shape=(None,2))\n",
    "mask = tf.keras.layers.Masking(mask_value=0)(inputs)\n",
    "out = tf.keras.layers.TimeDistributed(Dense(1,activation='sigmoid'))(mask)\n",
    "model = tf.keras.Model(inputs=inputs,outputs=out)\n",
    "q = model.predict(padded_inputs)\n",
    "print (q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 2, 2), (3, 2, 1))"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_inputs.shape, test_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_masking_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_1 (Masking)          (None, None, 2)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, None, 10)          520       \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, None, 10)          840       \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, None, 1)           11        \n",
      "=================================================================\n",
      "Total params: 1,371\n",
      "Trainable params: 1,371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 2 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 9s 5s/sample - loss: 0.4949 - accuracy: 0.6667 - binary_crossentropy: 0.6599 - val_loss: 0.1417 - val_accuracy: 1.0000 - val_binary_crossentropy: 0.2833\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 9ms/sample - loss: 0.4940 - accuracy: 0.6667 - binary_crossentropy: 0.6587 - val_loss: 0.1421 - val_accuracy: 1.0000 - val_binary_crossentropy: 0.2841\n"
     ]
    }
   ],
   "source": [
    "test_masking_model = masking_LSTM(2, test_bias)\n",
    "test_masking_model._name='test_masking_model'\n",
    "print(test_masking_model.summary())\n",
    "\n",
    "test_masking_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", \n",
    "                           metrics=[\"accuracy\", \"binary_crossentropy\"])\n",
    "history = test_masking_model.fit(padded_inputs, test_targets, validation_split=0.25, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"binary_lstm_test\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking (Masking)            (None, None, 2)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, None, 20)          1840      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 20)          3280      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, None, 20)          3280      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 20)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, None, 1)           21        \n",
      "=================================================================\n",
      "Total params: 8,421\n",
      "Trainable params: 8,421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "./test_lstm_logs/run_2020_04_26-00_41_02\n",
      "Train on 2 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 14s 7s/sample - loss: 0.4835 - binary_crossentropy: 0.6447 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.6667 - val_loss: 0.2124 - val_binary_crossentropy: 0.4247 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/2\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.129816). Check your callbacks.\n",
      "2/2 [==============================] - 0s 79ms/sample - loss: 0.4828 - binary_crossentropy: 0.6437 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.6667 - val_loss: 0.2124 - val_binary_crossentropy: 0.4247 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping our training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a transformer to pad our sequences using Keras's pad_sequences() function. The fit_transform() function will later allow us to ensure our validation and test sets are all padded to the same legnth as our training data.\n",
    "\n",
    "We'll also create a transformer to adjust the dimension of the targets array, as keras needs it to be 3-dimensional to predict a class per timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = {}\n",
    "class PadSequences(BaseEstimator, TransformerMixin):\n",
    "    global timesteps\n",
    "    def __init__(self, padding='pre'):\n",
    "        self.padding = padding\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        df = X\n",
    "#         t = len(df)\n",
    "        t = max([len(df[i]) for i in range(len(df))])\n",
    "        step = {'steps':t}\n",
    "        timesteps.update(step)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        df = tf.keras.preprocessing.sequence.pad_sequences(X,padding=self.padding, maxlen=timesteps['steps'])\n",
    "        return df\n",
    "    \n",
    "    def fit_transform(self, X, **kwargs):\n",
    "        return self.fit(X, y).transform(X)\n",
    "\n",
    "class ExpandDims(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, expandAxis):\n",
    "        self.expandAxis = expandAxis\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = tf.expand_dims(X, axis=self.expandAxis)\n",
    "        return X\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((118950, 26, 536), TensorShape([118950, 26, 1]))"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = PadSequences('pre').fit_transform(X_train)\n",
    "outputPipeline = make_pipeline(\n",
    "    PadSequences('pre'),\n",
    "    ExpandDims(2)\n",
    ")\n",
    "y_train = outputPipeline.transform(y_train)\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val shapes:  (39651, 26, 536) (39651, 26, 1)\n",
      "test shapes:  (67973, 26, 536) (67973, 26, 1)\n"
     ]
    }
   ],
   "source": [
    "X_val = PadSequences('pre').transform(X_val)\n",
    "y_val = outputPipeline.transform(y_val)\n",
    "print('val shapes: ',X_val.shape, y_val.shape)\n",
    "\n",
    "X_test = PadSequences('pre').transform(X_test)\n",
    "y_test = outputPipeline.transform(y_test)\n",
    "print('test shapes: ',X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! Both input and output arrays are of the same length and dimension per user. We'll use a masking layer as the input layer of our model to ensure the model knows we've padded our inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training RNN on ecommerce sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many steps per epoch?\n",
    "BATCH_SIZE = 10000\n",
    "resampled_steps_per_epoch = np.round(X_train.shape[0]/BATCH_SIZE)\n",
    "resampled_steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).cache().shuffle(BATCH_SIZE)\n",
    "train_ds = train_ds.batch(BATCH_SIZE).prefetch(2)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).cache().shuffle(BATCH_SIZE).repeat()\n",
    "val_ds = val_ds.batch(BATCH_SIZE).prefetch(2)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).cache()\n",
    "test_ds = test_ds.batch(BATCH_SIZE).prefetch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 26, 536)\n",
      "(10000, 26, 1)\n"
     ]
    }
   ],
   "source": [
    "# checking shape of our tf dataset\n",
    "train_ds\n",
    "for features, labels in train_ds.take(1):\n",
    "    print(features.shape)\n",
    "    print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, before we run the mode, we'll calculate the bias of classes in X_train. This might be used in our model's output layer (where we'll use this bias to tell the moel our data is imbalanced in favour of one class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.85748525509324\n",
      "class 0: 3068855 class 1: 23845\n"
     ]
    }
   ],
   "source": [
    "# recalculating initial bias\n",
    "neg, pos = np.bincount(X_train[:,:,0].flatten(), minlength=0)\n",
    "initial_bias = np.log(pos/neg)\n",
    "print(initial_bias)\n",
    "print('class 0: {} class 1: {}'.format(neg,pos))\n",
    "initial_bias = tf.keras.initializers.Constant(initial_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masking_LSTM(inputA, initial_bias_, **kwargs):\n",
    "\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Masking(input_shape=[None,inputA], mask_value=0, name=\"masking_layer\"),\n",
    "        keras.layers.BatchNormalization(momentum=0.999),\n",
    "        keras.layers.LSTM(100, return_sequences=True, kernel_initializer=\"he_normal\", kernel_regularizer=keras.regularizers.l2(0.01), name=\"lstm_1\"),\n",
    "        keras.layers.LeakyReLU(),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.LSTM(100, return_sequences=True, kernel_initializer=\"he_normal\", kernel_regularizer=keras.regularizers.l2(0.01),name=\"lstm_2\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.TimeDistributed(keras.layers.Dense(1, activation='sigmoid', bias_initializer=initial_bias_))\n",
    "])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM_masking_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_layer (Masking)      (None, None, 536)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, None, 536)         2144      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 100)         254800    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, None, 100)         0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 100)         0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, None, 100)         80400     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 100)         0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, None, 1)           101       \n",
      "=================================================================\n",
      "Total params: 337,445\n",
      "Trainable params: 336,373\n",
      "Non-trainable params: 1,072\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "test_masking_model = masking_LSTM(X_train.shape[-1],initial_bias)\n",
    "test_masking_model._name='LSTM_masking_model'\n",
    "print(test_masking_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.01**(epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(lr0=0.001, s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./test_lstm_logs/run_2020_05_02-17_47_58\n",
      "Train for 12 steps, validate for 4 steps\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 219s 18s/step - loss: 8.9386 - accuracy: 0.9905 - binary_crossentropy: 0.0530 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - val_loss: 7.8117 - val_accuracy: 0.9907 - val_binary_crossentropy: 0.0527 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 203s 17s/step - loss: 7.0137 - accuracy: 0.9905 - binary_crossentropy: 0.0528 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - val_loss: 6.1516 - val_accuracy: 0.9907 - val_binary_crossentropy: 0.0526 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 209s 17s/step - loss: 5.5466 - accuracy: 0.9905 - binary_crossentropy: 0.0527 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - val_loss: 4.8937 - val_accuracy: 0.9907 - val_binary_crossentropy: 0.0525 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 201s 17s/step - loss: 4.4347 - accuracy: 0.9905 - binary_crossentropy: 0.0525 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - val_loss: 3.9381 - val_accuracy: 0.9907 - val_binary_crossentropy: 0.0525 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 191s 16s/step - loss: 3.5863 - accuracy: 0.9905 - binary_crossentropy: 0.0523 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - val_loss: 3.2041 - val_accuracy: 0.9907 - val_binary_crossentropy: 0.0524 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 193s 16s/step - loss: 2.9307 - accuracy: 0.9905 - binary_crossentropy: 0.0522 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - val_loss: 2.6321 - val_accuracy: 0.9907 - val_binary_crossentropy: 0.0524 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 206s 17s/step - loss: 2.4163 - accuracy: 0.9905 - binary_crossentropy: 0.0521 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - val_loss: 2.1796 - val_accuracy: 0.9907 - val_binary_crossentropy: 0.0524 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 218s 18s/step - loss: 2.0069 - accuracy: 0.9905 - binary_crossentropy: 0.0520 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - val_loss: 1.8165 - val_accuracy: 0.9907 - val_binary_crossentropy: 0.0523 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 208s 17s/step - loss: 1.6764 - accuracy: 0.9905 - binary_crossentropy: 0.0519 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - val_loss: 1.5214 - val_accuracy: 0.9907 - val_binary_crossentropy: 0.0523 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 199s 17s/step - loss: 1.4065 - accuracy: 0.9905 - binary_crossentropy: 0.0517 - Precision: 1.0000 - Recall: 0.0024 - val_loss: 1.2790 - val_accuracy: 0.9907 - val_binary_crossentropy: 0.0522 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 204s 17s/step - loss: 1.1838 - accuracy: 0.9905 - binary_crossentropy: 0.0517 - Precision: 1.0000 - Recall: 0.0055 - val_loss: 1.0779 - val_accuracy: 0.9907 - val_binary_crossentropy: 0.0522 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00\n",
      "Epoch 12/20\n",
      " 2/12 [====>.........................] - ETA: 4:07 - loss: 1.0702 - accuracy: 0.9908 - binary_crossentropy: 0.0501 - Precision: 1.0000 - Recall: 0.0237"
     ]
    }
   ],
   "source": [
    "prep_run()\n",
    "run_logdir = get_run_logdir(\"test_lstm_logs\")\n",
    "print(run_logdir)\n",
    "\n",
    "tb = TensorBoard(run_logdir)\n",
    "\n",
    "red_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='binary_crossentropy',\n",
    "                                          patience=3, \n",
    "                                          verbose=1,\n",
    "                                          factor=0.005, \n",
    "                                          min_lr=0.00001)\n",
    "lr_sched = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='binary_crossentropy', \n",
    "                                      patience=3, restore_best_weights=True)\n",
    "\n",
    "test_masking_model.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(clipvalue=1.5, lr=0.001, beta_1=0.9, beta_2=0.999), \n",
    "                           metrics=[\"accuracy\", \"binary_crossentropy\", \"Precision\", \"Recall\"])\n",
    "history = test_masking_model.fit(train_ds, validation_data=val_ds, \n",
    "                                 epochs=20, callbacks=[tb, red_lr, es]) # no lr_sched\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(loss, val_loss):\n",
    "    plt.plot(np.arange(len(loss)) + 0.5, loss, \"b.-\", label=\"Training loss\")\n",
    "    plt.plot(np.arange(len(val_loss)) + 1, val_loss, \"r.-\", label=\"Validation loss\")\n",
    "    plt.gca().xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
    "    plt.axis([1, 20, 0, 0.05])\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True)\n",
    "\n",
    "plot_learning_curves(history.history['loss'],history.history['val_loss'])\n",
    "# plt.plot(history.history['loss'], label='train')\n",
    "# plt.plot(history.history['val_loss'], label='test')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39651/39651 [==============================] - 123s 3ms/sample - loss: 0.0026 - accuracy: 0.9907 - binary_crossentropy: 0.0596 - Precision: 0.0000e+00 - Recall: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# ?test_masking_model.evaluate\n",
    "# print('Evaluating...')\n",
    "scores = test_masking_model.evaluate(X_val[:,:,:], y_val[:,:,:])\n",
    "# print(\"Metrics: accuracy, binary_crossentropy, Precision, Recall: \",scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = test_masking_model.predict_classes(X_val[:3,:,:])\n",
    "y_pred[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: (4785, 4, 1) y_actual: (4785, 4, 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19087\n",
      "           1       1.00      0.75      0.86        53\n",
      "\n",
      "    accuracy                           1.00     19140\n",
      "   macro avg       1.00      0.88      0.93     19140\n",
      "weighted avg       1.00      1.00      1.00     19140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = test_masking_model.predict_classes(X_val[:,:,:])\n",
    "y_actual = y_val[:,:,:]\n",
    "\n",
    "print('y_pred: {} y_actual: {}'.format(y_pred.shape, y_actual.shape))\n",
    "print(classification_report(tf.reshape(y_actual,[-1]), tf.reshape(y_pred,[-1])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing RNN on ecommerce sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
